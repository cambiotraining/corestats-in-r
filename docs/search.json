[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform core data analysis techniques appropriately confidently using R.6 lecture-practicals6 lecture-practicalsOngoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey “mindlessly use stats program” course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented arbitrary dataset e.g.Know data analysis techniques availableKnow ones allowableBe able carry understand results","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Simple Hypothesis TestingCategorical Predictor VariablesContinuous PredictorsMultiple Predictor VariablesLinear ModelsErrors, Power Multiple Comparisons","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder copy working directory. data accessible via <working-directory-name>/data/raw.","code":""},{},{"path":"cs1-intro.html","id":"cs1-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"cs1-intro.html","id":"objectives","chapter":"2 Introduction","heading":"2.1 Objectives","text":"Aim: carry basic one two sample statistical tests.end section practical participants able achieve following listed tests:Understand purpose test isPerform test RInterpret test outputUnderstand assumptions/conditions test appropriateCheck assumptionsThe tests covered practical :One-sample tests\nOne sample t-test\nOne-sample Wilcoxon signed-rank test\nOne sample t-testOne-sample Wilcoxon signed-rank testTwo-sample tests\nStudent’s t-test\nMann-Whitney U test\nPaired two-sample t-test\nWilcoxon signed-rank test\nStudent’s t-testMann-Whitney U testPaired two-sample t-testWilcoxon signed-rank test","code":""},{"path":"cs1-intro.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"practical focus underlying mathematical theory tests although demonstrators happy answer questions.\ntest section explaining purpose, section explaining perform test R, section explaining results output screen, section covering assumptions required perform test.","code":""},{},{"path":"introduction.html","id":"introduction","chapter":"3 Introduction","heading":"3 Introduction","text":"practical document divided various sections. section explanatory text help understand going ’re trying achieve.\nmay list commands relevant section displayed boxes like :Conditional operatorsTo set filtering conditions, use following relational operators:> greater >= greater equal < less <= less equal == equal != different %% contained combine conditions, use following logical operators:& | ","code":""},{"path":"introduction.html","id":"cs1-datasets","chapter":"3 Introduction","heading":"3.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"cs1-one-sample-tests.html","id":"cs1-one-sample-tests","chapter":"4 One-sample tests","heading":"4 One-sample tests","text":"","code":""},{"path":"cs1-one-sample-tests.html","id":"objectives-1","chapter":"4 One-sample tests","heading":"4.1 Objectives","text":"QuestionsWhen perform one-sample test?one-sample tests assumptions?interpret present results tests?ObjectivesSet hypothesis single sample continuous dataBe able summarise visualise data RUnderstand assess underlying assumptions testsPerform one-sample t-test Wilcoxon signed-rank test RKnow test appropriate whenBe able interpret report results","code":""},{"path":"cs1-one-sample-tests.html","id":"purpose-and-aim","chapter":"4 One-sample tests","heading":"4.2 Purpose and aim","text":"tests used single sample continuous data. used find sample came parent distribution given mean (median). essentially boils finding sample mean (median) “close enough” hypothesised parent population mean (median).\n, figure , use tests see probability sample ten points comes distribution plotted .e. population mean 20 mm.","code":""},{"path":"cs1-one-sample-tests.html","id":"choosing-a-test","chapter":"4 One-sample tests","heading":"4.3 Choosing a test","text":"two tests going look situation; one-sample t-test, one-sample Wilcoxon signed rank test. tests work sort data ’re considering , different assumptions.data normally distributed, one-sample t-test appropriate. data aren’t normally distributed, distribution symmetric, sample size small one-sample Wilcoxon signed rank test appropriate.statistical test consider five tasks. come back , pay extra close attention.Setting hypothesisSummarise visualisation dataAssessment assumptionsImplementation statistical testInterpreting output presentation resultsWe won’t always carry exactly order, always consider five tasks every test.","code":""},{},{"path":"cs1-one-sample-t-test.html","id":"cs1-one-sample-t-test","chapter":"5 1-sample t-test","heading":"5 1-sample t-test","text":"","code":""},{"path":"cs1-one-sample-t-test.html","id":"section-commands","chapter":"5 1-sample t-test","heading":"5.1 Section commands","text":"New commands used section:","code":""},{"path":"cs1-one-sample-t-test.html","id":"data-and-hypotheses","chapter":"5 1-sample t-test","heading":"5.2 Data and hypotheses","text":"example, suppose measure body lengths male guppies (mm) collected Guanapo River Trinidad. want test whether data support hypothesis mean body actually 20 mm. form following null alternative hypotheses:\\(H_0\\): mean body length equal 20mm (\\(\\mu =\\) 20).\\(H_1\\): mean body length equal 20mm (\\(\\mu \\neq\\) 20).use one-sample, two-tailed t-test see reject null hypothesis .use one-sample test one sample.use two-tailed t-test want know data suggest true (population) mean different 20 mm either direction rather just see greater less 20 mm (case use one-tailed test).’re using t-test don’t know better yet ’m telling . ’ll look precise assumptions/requirements need moment.Make sure downloaded data (see: Datasets) placed data/raw folder within working directory.read data create vector containing data.first line reads data R creates object called data frame. data frame contains single column numbers called “Guanapo” (name river). situations, statistical analyses, data stored data frame exactly ’d want. However, one sample tests actually need data stored vector. , second line extracts values Guanapo column fishlengthDF data frame creates simple vector numbers called fishlength. step necessary one-sample tests look complex datasets, won’t need second step .","code":"\n# import the data\nfishlengthDF <- read.csv(\"data/raw/CS1-onesample.csv\")\n\n# create a vector containing the data\nfishlength <- fishlengthDF$Guanapo"},{"path":"cs1-one-sample-t-test.html","id":"summarise-and-visualise","chapter":"5 1-sample t-test","heading":"5.3 Summarise and visualise","text":"Summarise data visualise :data appear contain obvious errors, whilst mean median less 20 (18.3 18.8 respectively) absolutely certain sample mean sufficiently different value “statistically significant,” although may anticipate result.","code":"\nsummary(fishlength)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    11.2    17.5    18.8    18.3    19.7    23.3\nboxplot(fishlength, main = \"Male guppies\", ylab = \"Length (mm)\")"},{"path":"cs1-one-sample-t-test.html","id":"implement-the-test","chapter":"5 1-sample t-test","heading":"5.4 Implement the test","text":"Perform one-sample, two-tailed t-test:first argument must numerical vector data values.second argument must number mean tested null hypothesis.third argument gives type alternative hypothesis must one two.sided, greater less.","code":"\nt.test(fishlength, mu = 20, alternative = \"two.sided\")## \n##  One Sample t-test\n## \n## data:  fishlength\n## t = -3.5492, df = 28, p-value = 0.001387\n## alternative hypothesis: true mean is not equal to 20\n## 95 percent confidence interval:\n##  17.31341 19.27969\n## sample estimates:\n## mean of x \n##  18.29655"},{"path":"cs1-one-sample-t-test.html","id":"interpreting-the-output-and-report-results","chapter":"5 1-sample t-test","heading":"5.5 Interpreting the output and report results","text":"output now see console window:1st line gives name test 2nd line reminds dataset calledThe 3rd line contains three key outputs test:\ncalculated t-value -3.5492 (’ll need reporting)\n28 degrees freedom (’ll need reporting)\np-value 0.001387.\ncalculated t-value -3.5492 (’ll need reporting)28 degrees freedom (’ll need reporting)p-value 0.001387.4th line simply states alternative hypothesisThe 5th 6th lines give 95th confidence interval (don’t need know )7th, 8th 9th lines give sample mean (18.29655).p-value 3rd line ’re interested . gives probability us getting sample null hypothesis actually true.:high p-value means high probability observing sample null hypothesis probably true whereasa low p-value means low probability observing sample null hypothesis probably true.important realise p-value just indication absolute certainty interpretation.People, however like definite answers pick artificial probability threshold (called significance level) order able say something decisive. standard significance level 0.05 since p-value smaller choose say “unlikely particular sample null hypothesis true.” Consequently, can reject null hypothesis state :one-sample t-test indicated mean body length male guppies (\\(\\mu\\) = 18.29mm) differs significantly 20 mm (t = -3.55, df = 28, p = 0.0014).sentence adequate concluding statement test write paper report. Note included (brackets) information actual mean value group(\\(\\mu\\) = 18.29mm), test statistic (t = -3.55), degrees freedom (df = 28), p-value (p = 0.0014). journals required report whether p-value less critical value (e.g. p < 0.05) always recommend reporting actual p-value obtained.Please feel free ask demonstrator aspect section unclear form core classical hypothesis testing logic applies rest tests.","code":"## \n##  One Sample t-test\n## \n## data:  fishlength\n## t = -3.5492, df = 28, p-value = 0.001387\n## alternative hypothesis: true mean is not equal to 20\n## 95 percent confidence interval:\n##  17.31341 19.27969\n## sample estimates:\n## mean of x \n##  18.29655"},{"path":"cs1-one-sample-t-test.html","id":"assumptions","chapter":"5 1-sample t-test","heading":"5.6 Assumptions","text":"order use t-test analysis (results strictly valid) make two assumptions:parent distribution sample taken normally distributed (sample data normally distributed ).worth noting though t-test actually pretty robust situations sample data normal. sufficiently large sample sizes (guess good mine, conventionally means 30 data points), can use t-test without worrying whether underlying population normally distributed .data point sample independent others. general something can tested instead considered sampling procedure. example, taking repeated measurements individual generate data independent.second point know nothing ignore (issue needs considered experimental design), whereas first assumption can checked.\nthree ways checking normality:increasing order rigour, haveHistogramQuantile-quantile plotShapiro-Wilk test","code":""},{"path":"cs1-one-sample-t-test.html","id":"histogram-of-the-data","chapter":"5 1-sample t-test","heading":"5.6.1 Histogram of the data","text":"Plot histogram data, gives:distribution appears uni-modal symmetric, isn’t obviously non-normal. However, lot distributions simple properties aren’t normal, isn’t exactly rigorous. Thankfully , rigorous tests.NB. even looking distribution assess assumption normality already going far beyond anyone else ever . Nevertheless, continue.","code":"\nhist(fishlength, breaks = 15)"},{"path":"cs1-one-sample-t-test.html","id":"q-q-plot-of-the-data","chapter":"5 1-sample t-test","heading":"5.6.2 Q-Q plot of the data","text":"Q-Q plot short quantile-quantile plot. diagnostic plot (sometimes called) way comparing two distributions. Q-Q plots work won’t explained ask demonstrator really want know going .Construct Q-Q Plot quantiles data quantiles normal distribution:important know data normally distributed points lie (close ) diagonal line graph.case, points lie quite close line part sample quantiles (points) either end sample distribution either smaller (line left) larger (line right) expected supposed normally distributed. suggests sample distribution bit spread expected came normal distribution.important recognise isn’t simple unambiguous answer interpreting types graph, terms whether assumption normality well met instead often boils matter experience.rare situation indeed assumptions necessary test met unequivocally certain degree personal interpretation always needed. ask whether data normal “enough” confident validity test.four examples QQ plots different types distributions:two graphs relate 200 data points drawn normal distribution. Even can see points lie perfectly diagonal line QQ plot, certain amount deviation top bottom graph can happen just chance (draw different set point graph look slightly different).two graphs relate 200 data points drawn uniform distribution. Uniform distributions condensed normal distributions, reflected QQ plot pronounced S-shaped pattern (colloquially known snaking).two graphs relate 200 data points drawn t distribution. t distributions spread normal distributions, reflected QQ plot pronounced S-shaped pattern , time snaking reflection observed uniform distribution.two graphs relate 200 data points drawn exponential distribution. Exponential distributions symmetric skewed compared normal distributions. significant right-skew distribution reflected QQ plot points curve away diagonal line ends (left-skew points line ends).four cases worth noting deviations ends plot.","code":"\n# plot the Q-Q plot\nqqnorm(fishlength)\n\n# and add a comparison line\nqqline(fishlength)"},{"path":"cs1-one-sample-t-test.html","id":"shapiro-wilk-test","chapter":"5 1-sample t-test","heading":"5.6.3 Shapiro-Wilk test","text":"one number formal statistical test assess whether given sample numbers come normal distribution. calculates probability getting sample data underlying distribution fact normal. easy carry R.Perform Shapiro-Wilk test data:1st line gives name test 2nd line reminds dataset calledThe 3rd line contains two key outputs test:\ncalculated w-value 0.9494 (don’t need know )\np-value 0.1764\ncalculated w-value 0.9494 (don’t need know )p-value 0.1764As p-value bigger 0.05 (say) can say insufficient evidence reject null hypothesis sample came normal distribution.important recognise Shapiro-Wilk test without limitations. rather sensitive sample size considered. general, small sample sizes, test relaxed normality (nearly datasets considered normal), whereas large sample sizes test can overly strict, can fail recognise datasets nearly normal indeed.","code":"\nshapiro.test(fishlength)## \n##  Shapiro-Wilk normality test\n## \n## data:  fishlength\n## W = 0.94938, p-value = 0.1764"},{"path":"cs1-one-sample-t-test.html","id":"assumptions-overview","chapter":"5 1-sample t-test","heading":"5.6.4 Assumptions overview","text":"terms assessing assumptions test always worth considering several methods, graphical analytic, just relying single method.fishlength example, graphical Q-Q plot analysis especially conclusive suggestion snaking plots, Shapiro-Wilk test gave non-significant p-value (0.1764). Putting two together, along original histogram recognition 30 data points dataset personally happy assumptions t-test met well enough trust result t-test, may …case consider alternative test less stringent assumptions (less powerful): one-sample Wilcoxon signed rank test.","code":""},{"path":"cs1-one-sample-t-test.html","id":"exercise","chapter":"5 1-sample t-test","heading":"5.7 Exercise","text":"Exercise 5.1  following data dissolving times (seconds) drug agitated gastric juice:42.7, 43.4, 44.6, 45.1, 45.6, 45.9, 46.8, 47.6Do results provide evidence suggest dissolving time drug different 45 seconds?Write null alternative hypotheses.Summarise visualise data perform appropriate one-sample t-test.\ncan say dissolving time? (sentence use report )\ncan say dissolving time? (sentence use report )Check assumptions test.\ntest valid?\ntest valid?Hypotheses\n\\(H_0\\) : mean = 45s\\(H_1\\) : mean \\(\\neq\\) 45sCreate data, summarise visualiseThere 8 data points, default histogram looks bit rubbish / uninformative. Thankfully box-plot bit useful . can see:don’t appear major errors data entry aren’t huge outliersThe median value box-plot (thick black line) pretty close 45 wouldn’t surprised mean data isn’t significantly different 45. can confirm looking mean median values calculated using summary command earlier.data appear symmetric, whilst can’t tell ’re normal ’re least massively skewed.Carry t-testA one-sample t-test indicated mean dissolving time drug significantly different 45s (t=0.366 , df=7 , p=0.725),Explore Assumptions\nNormality:Shapiro test p-value 0.964 (given bigger 0.05) suggests data normal enough.qq-plot isn’t perfect, deviation points away line since points aren’t accelerating away line , since 8 points, can claim, slight reservations, assumption normality appears adequately well met.Overall, somewhat confident assumption normality well-enough met t-test appropriate method analysing data. Note ridiculous number caveats slightly political/slippery language ’m using. intentional reflects ambiguous nature assumption checking. important approach statistics need embrace.reality, found situation also try non-parametric test data (Wilcoxon-signed Rank test) see whether get conclusion whether median dissolving time differs 45s. Technically, don’t know Wilcoxon test yet haven’t done section handout. Anyway, get conclusion confidence result test goes considerably; doesn’t matter well assumption met , get result. hand get completely different conclusion carrying non-parametric test bets ; now little confidence test result don’t know one believe (case assumptions test bit unclear). example Wilcoxon test also gives us non-significant result good.","code":"\ndissolving<-c(42.7 , 43.4 , 44.6 , 45.1 , 45.6 , 45.9 , 46.8 , 47.6)\nsummary(dissolving)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   42.70   44.30   45.35   45.21   46.12   47.60\nhist(dissolving)\nboxplot(dissolving)\nt.test(dissolving , mu=45 , alternative = \"two.sided\")## \n##  One Sample t-test\n## \n## data:  dissolving\n## t = 0.36647, df = 7, p-value = 0.7248\n## alternative hypothesis: true mean is not equal to 45\n## 95 percent confidence interval:\n##  43.84137 46.58363\n## sample estimates:\n## mean of x \n##   45.2125\nshapiro.test(dissolving)## \n##  Shapiro-Wilk normality test\n## \n## data:  dissolving\n## W = 0.98023, p-value = 0.9641\nqqnorm(dissolving)\nqqline(dissolving)"},{},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"cs1-onesample-wilcoxon-signed-rank","chapter":"6 Wilcoxon signed-rank test","heading":"6 Wilcoxon signed-rank test","text":"test also considers single sample, however test (contrast one sample t-test) don’t assume parent distribution normally distributed. still need parent distribution (consequently sample) symmetric though. test look see median parent distributions differs significantly given hypothesised value (contrast t-test looks mean).","code":""},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"section-commands-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.1 Section commands","text":"New commands used section:, use fishlength dataset. one-sample Wilcoxon signed-rank test allows see median body length different specified value. want test whether data support hypothesis median body actually 20 mm. following null alternative hypotheses similar used one sample t-test:\\(H_0\\): median body length equal 20 mm (\\(\\mu =\\) 20).\\(H_1\\): median body length equal 20 mm (\\(\\mu \\neq\\) 20).use one-sample, two-tailed Wilcoxon signed-rank test see reject null hypothesis .","code":""},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"summarise-and-visualise-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.2 Summarise and visualise","text":"previous section, nothing really changed now (’re good start practical!)","code":""},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"implement-the-test-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.3 Implement the test","text":"Perform one-sample, two-tailed Wilcoxon signed-rank test:syntax identical one-sample t-test carried earlier.first argument must numerical vector data values.second argument must number median tested null hypothesis.third argument gives type alternative hypothesis must one two.sided, greater less.","code":"\nwilcox.test(fishlength, mu = 20, alternative = \"two.sided\")"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"interpreting-the-output-and-report-results-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.4 Interpreting the output and report results","text":"output now see console windowThe first two lines give warning (error) message regarding implementation test. can safely ignored case p-value small, essentially, ’s letting know data values identical . supposed happen dealing continuous data test, practice ’s something need worry .3rd line gives name test 4th line reminds dataset calledThe 5th line contains two key outputs test:\ncalculated statistic 67.5 (’ll need reporting)\np-value 0.001222.\ncalculated statistic 67.5 (’ll need reporting)p-value 0.001222.6th line simply states alternative hypothesisAgain, p-value ’re interested . gives probability us getting sample null hypothesis actually true.\n, case since p-value less 0.05 can reject null hypothesis state :one-sample Wilcoxon signed-rank test indicated median body length male guppies (\\(\\mu\\) = 18.8 mm) differs significantly 20 mm (V = 67.5, n = 29, p = 0.0012).sentence adequate concluding statement test write paper report. Note included (brackets) information median value group (\\(\\mu\\) = 18.8 mm), test statistic (V = 67.5), number observations (n = 29), p-value (p = 0.0012).","code":"## Warning in wilcox.test.default(fishlength, mu = 20, alternative = \"two.sided\"):\n## cannot compute exact p-value with ties## \n##  Wilcoxon signed rank test with continuity correction\n## \n## data:  fishlength\n## V = 67.5, p-value = 0.001222\n## alternative hypothesis: true location is not equal to 20"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"assumptions-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.5 Assumptions","text":"order use one-sample Wilcoxon rank-sum test analysis (results strictly valid) make two assumptions:parent distribution sample symmetricEach data point sample independent others. t-test common feature nearly statistical tests. Lack independence data really tough deal (impossible) large part proper experimental design ensuring .Whilst formal statistical tests symmetry opt simple visual inspection using boxplot histogram.Plot histogram boxplot data:get following plots:can see whilst distribution isn’t perfectly symmetric, neither heavily skewed left right can make call distribution symmetric enough us happy results test.","code":"\nhist(fishlength, breaks = 10)\n\nboxplot(fishlength)"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"exercise-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.6 Exercise","text":"Exercise 6.1  Performing Wilcoxon signed-rank test:Analyse drug dataset using one-sample Wilcoxon signed-rank testDiscuss (virtual) neighbour two tests feel best suited data.matter case?Hypotheses\n\\(H_0\\) : median = 45s\\(H_1\\) : median \\(\\neq\\) 45sWilcoxon signed-rank testA one-sample Wilcoxon-signed rank test indicated median dissolving time drug significantly different 45 s (V=22, n=8 , p=0.64)Assumptions\nbox-plot previous exercise already know data symmetric enough test valid.Discussion\nterms choosing two test can see meet respective assumptions tests valid. case tests also agree terms conclusions .e. average dissolving time (either mean median) doesn’t differ significantly proposed value 45 s.one answer doesn’t matter test use.Another answer pick test measures quantity ’re interested .e. care medians use Wilcoxon test, whereas care means use t-test.final answer , since test valid prefer use test greater power. t-tests always power Wilcoxon tests (long ’re valid) report one. (’ll talk last session power effectively capacity test detect significant difference - power better).","code":"\nwilcox.test(dissolving , mu=45 , alternative = \"two.sided\")## \n##  Wilcoxon signed rank exact test\n## \n## data:  dissolving\n## V = 22, p-value = 0.6406\n## alternative hypothesis: true location is not equal to 45"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"key-points","chapter":"6 Wilcoxon signed-rank test","heading":"6.7 Key points","text":"One-sample tests used single sample continuous dataWe can summarise data using summary() function visualise boxplot()t-test assumes data normally distributed independent otherThe Wilcoxon signed-rank test assume normal distribution, require independent samplesThe t.test() compares mean parent distribution differs hypothesised value, whereas wilcox.test() compares median.good way assessing assumptions visually check looking distribution hist() quantile-quantile plots qqnorm() qqline()","code":""},{},{"path":"cs1-two-sample.html","id":"cs1-two-sample","chapter":"7 Two-sample tests","heading":"7 Two-sample tests","text":"","code":""},{"path":"cs1-two-sample.html","id":"objectives-2","chapter":"7 Two-sample tests","heading":"7.1 Objectives","text":"QuestionsWhen perform two-sample test?two-sample tests assumptions?interpret present results tests?ObjectivesSet hypothesis two-sample continuous dataDetermine correct data format perform two-sample test RSummarise visualise dataCheck underlying assumptions (normality, homogeneity variance)able choose appropriate two-sample test run RBe able interpret report results","code":""},{"path":"cs1-two-sample.html","id":"purpose-and-aim-1","chapter":"7 Two-sample tests","heading":"7.2 Purpose and aim","text":"tests used two samples continuous data trying find samples came parent distribution . essentially boils finding difference means two samples.","code":""},{"path":"cs1-two-sample.html","id":"two-sample-choosing-a-test","chapter":"7 Two-sample tests","heading":"7.3 Choosing a test","text":"five key tests can used deal two samples. Choosing test use depends upon key assumptions satisfied sample data effectively boils answering four questions samples:samples normally distributed? (Yes/)big samples? (<30 data points >30 data points)samples paired? (Yes/)samples variance? (Yes/)two sets tests consider depending answers questions 1 2. data normally distributed big samples need look parametric tests. data normally distributed sample size small, need look non-parametric tests (see Figure 7.1. Questions 3 4 help pick specific test use, summarised Figure 7.2.\nFigure 7.1: Category test\n\nFigure 7.2: test use\nTesting whether sample comes normal distribution covered One-sample tests. need visualise data /use Shapiro-Wilk test.size sample makes things easier. maths (specifically due something called central limit theorem even going attempt touch upon ) large samples can use tests assume normality parent population (Student’s t-test, Welch’s t-test paired t-test) even parent populations certainly normal. really want understand exactly works, rigorous mathematics. , moment ’m going say ’s OK take facts faith just trust .Paired samples mean every data point one sample matching data point sample linked inextricable way. typical example involve group 20 test subjects measured experiment. Providing experiment didn’t anything fatal test subjects data consist two samples; 20 pre-experiment measurements 20 post-experiment measurements. However, test subjects used pre-experiment data point can matched exactly one post-experiment data points. sense two samples said “paired.”couple tests (Bartlett’s test Levene’s test) can used see two samples come distributions variance. covered later section.Resampling techniques aren’t covered course require mixture statistical understanding programming skill. Ask demonstrator (Google 😉) want know .","code":""},{"path":"cs1-two-sample.html","id":"tidy-data","chapter":"7 Two-sample tests","heading":"7.4 Tidy data","text":"two samples data can stored one three formats R:two separate vectors,stacked data frame,unstacked data frame/list.Two separate vectors case (hopefully) obvious.using data frame different options organise data. best way formatting data R using tidy data format.Tidy data following properties:variable columnEach observation rowEach value cellStacked form (long format data) data arranged way variable (thing measured) column. consider dataset containing meerkat weights (g) two different countries stacked format data look like:unstacked (wide format) form variable (measured thing) present one column. example, let’s say measured meerkat weight two countries period years. organise data way year measured values split country:tidy data easiest way analyses R strongly encourage start adopting format standard data collection processing.","code":""},{},{"path":"cs1-students-t-test.html","id":"cs1-students-t-test","chapter":"8 Student’s t-test","heading":"8 Student’s t-test","text":"test assume sample data sets normally distributed equal variance. test see means two samples differ significantly .language used section slightly different used section 4. Although language used section 4 technically correct, sentences somewhat onerous read. ’ve opted easier reading style expense technical accuracy. Please feel free re-write section (leisure).","code":""},{"path":"cs1-students-t-test.html","id":"section-commands-2","chapter":"8 Student’s t-test","heading":"8.1 Section commands","text":"New commands used section:","code":""},{"path":"cs1-students-t-test.html","id":"data-and-hypotheses-1","chapter":"8 Student’s t-test","heading":"8.2 Data and hypotheses","text":"example, suppose now measure body lengths male guppies (mm) collected two rivers Trinidad; Aripo Guanapo. want test whether mean body length differs samples. form following null alternative hypotheses:\\(H_0\\): mean body length differ two groups (\\(\\mu = \\mu G\\))\\(H_1\\): mean body length differ two groups (\\(\\mu \\neq \\mu G\\))use two-sample, two-tailed t-test see can reject null hypothesis.use two-sample test now two samples.use two-tailed t-test want know data suggest true (population) means different one another rather one mean specifically bigger smaller .’re using Student’s t-test sample sizes big ’re assuming parent populations equal variance (can check later).data stored stacked format file data/raw/CS1-twosample.csv.Read R:","code":"\nrivers <- read.csv(\"data/raw/CS1-twosample.csv\")"},{"path":"cs1-students-t-test.html","id":"cs1-students-sumvisual","chapter":"8 Student’s t-test","heading":"8.3 Summarise and visualise","text":"Let’s summarise data…visualise :boxplot appear suggest two samples different means, moreover guppies Guanapo may smaller guppies Aripo. isn’t immediately obvious two populations don’t equal variances though, plough .","code":"\naggregate(length ~ river, data = rivers, summary)##     river length.Min. length.1st Qu. length.Median length.Mean length.3rd Qu.\n## 1   Aripo    17.50000       19.10000      20.10000    20.33077       21.30000\n## 2 Guanapo    11.20000       17.50000      18.80000    18.29655       19.70000\n##   length.Max.\n## 1    26.40000\n## 2    23.30000\nboxplot(length ~ river, data = rivers,\n        main = \"Male guppies\",\n        ylab = \"Length (mm)\")"},{"path":"cs1-students-t-test.html","id":"implement-test","chapter":"8 Student’s t-test","heading":"8.4 Implement test","text":"Perform two-sample, two-tailed, t-test:case, data stacked format:first argument must formula format: variables ~ categoryThe second argument must name data frameThe third argument gives type alternative hypothesis must one two.sided, greater lessThe fourth argument says whether variance two samples can assumed equal (Student’s t-test) unequal (Welch’s t-test)next section shows can perform exactly test data different (unstacked) format. potentially somewhat redundant (thorough depending point view). Probably best just anyway just case gain extra insight repetition (works rowers…)Convert data unstacked format repeat t test:","code":"\nt.test(length ~ river, data = rivers,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n# create a new object that contains the unstacked data\nuns_rivers <- unstack(rivers)\n\n# have a look at the data\nuns_rivers\n# perform the t-test\nt.test(uns_rivers$Guanapo, uns_rivers$Aripo,\n       alternative = \"two.sided\",\n       var.equal = TRUE)"},{"path":"cs1-students-t-test.html","id":"interpret-output-and-report-results","chapter":"8 Student’s t-test","heading":"8.5 Interpret output and report results","text":"Let’s look results t-test performed original (stacked) data frame:1st line gives name test 2nd line reminds dataset called, variables used.3rd line contains three key outputs test:\ncalculated t-value 3.8433 (need reporting)\n66 degrees freedom (need reporting)\np-value 0.0002754.\ncalculated t-value 3.8433 (need reporting)66 degrees freedom (need reporting)p-value 0.0002754.4th line simply states alternative hypothesis terms difference two sample means (testing two sample means different equivalent testing whether difference means equal zero).5th 6th lines give 95th confidence interval (don’t need know ).7th, 8th 9th lines give sample means group (20.33077 Aripo 18.29655 Guanapo) found earlier., p-value 3rd line ’re interested . Since p-value small (much smaller standard significance level) choose say “unlikely two samples came parent distribution can reject null hypothesis” state :Student’s t-test indicated mean body length male guppies Guanapo river (18.29 mm) differs significantly mean body length male guppies Aripo river (20.33 mm) (t = 3.8433, df = 66, p = 0.0003).Now ’s conversation starter.","code":"## \n##  Two Sample t-test\n## \n## data:  length by river\n## t = 3.8433, df = 66, p-value = 0.0002754\n## alternative hypothesis: true difference in means between group Aripo and group Guanapo is not equal to 0\n## 95 percent confidence interval:\n##  0.9774482 3.0909868\n## sample estimates:\n##   mean in group Aripo mean in group Guanapo \n##              20.33077              18.29655"},{"path":"cs1-students-t-test.html","id":"assumptions-2","chapter":"8 Student’s t-test","heading":"8.6 Assumptions","text":"order use Student’s t-test (results strictly valid) make three assumptions:parent distributions samples taken normally distributed (lead sample data normally distributed ).data point samples independent others.parent distributions variance.example first assumption can ignored sample sizes large enough (maths, Aripo containing 2 Guanapo 2 samples). samples smaller use tests previous section.second point can nothing unless know data collected, ignore .third point regarding equality variance can tested using either Bartlett’s test (samples normally distributed) Levene’s test (samples normally distributed).\ngets bit trickier. Although don’t care samples normally distributed t-test valid (sample size big enough compensate), need know normally distributed order decide variance test use.perform Shapiro-Wilk test samples separately:can see whilst Guanapo data probably normally distributed (p = 0.1764 > 0.05), Aripo data unlikely normally distributed (p = 0.02802 < 0.05). Remember p-value gives probability observing sample parent population actually normally distributed.\nShapiro-Wilk test quite sensitive sample size. means large sample even small deviations normality cause sample fail test, whereas smaller samples allowed pass much larger deviations. Aripo data nearly 40 points compared Guanapo data much easier Aripo sample fail compared Guanapo data.","code":"\nshapiro.test(uns_rivers$Aripo)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_rivers$Aripo\n## W = 0.93596, p-value = 0.02802\nshapiro.test(uns_rivers$Guanapo)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_rivers$Guanapo\n## W = 0.94938, p-value = 0.1764"},{"path":"cs1-students-t-test.html","id":"exercise-2","chapter":"8 Student’s t-test","heading":"8.7 Exercise","text":"Exercise 8.1  Q-Q plots rivers dataCreate Q-Q plots two samples discuss neighbour see light results Shapiro-Wilk test.Q-Q plots mirror found Shapiro-Wilk tests: data Aripo pretty normally distributed, whereas assumption normality Guanapo data less certain.Remember statistical tests provide answers, merely suggest patterns. Human interpretation still crucial aspect .Nevertheless, Shapiro-Wilk test shown data normal enough order test equality variance use Levene’s test.\nLevene’s test included default R packages may require installation additional package called car (Companion Applied Regression).install car package, run following command console:Alternatively, go Tools > Install packages… > Packages, type car press InstallWe can now perform Levene’s test:Ignore warning might get coercion factors (test needs create grouped variables work R versions 4.x onwards read data factors).key bit information 3rd line text Pr(>F). p-value (0.1876) test. tells us probability observing two samples come distributions variance. probability greater arbitrary significance level 0.05 can somewhat confident necessary assumptions carrying Student’s t-test two samples valid. (woohoo!)information :wanted carry Bartlett’s test (.e. data sufficiently normally distributed) command :relevant p-value given 3rd line.","code":"\npar(mfrow=c(1,2))\nqqnorm(uns_rivers$Aripo, main = \"Aripo\")\nqqline(uns_rivers$Aripo, col = \"red\")\n\nqqnorm(uns_rivers$Guanapo, main = \"Guanapo\")\nqqline(uns_rivers$Guanapo, col = \"red\")\ninstall.packages(\"car\")\nleveneTest(length ~ river, data = rivers)## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  1  1.7732 0.1876\n##       66\nbartlett.test(length ~ river, data = rivers)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  length by river\n## Bartlett's K-squared = 4.4734, df = 1, p-value = 0.03443"},{"path":"cs1-students-t-test.html","id":"exercise-3","chapter":"8 Student’s t-test","heading":"8.8 Exercise","text":"Exercise 8.2  Serum cholesterol concentrations turtlesUsing following data, test null hypothesis male female turtles mean serum cholesterol concentrations.\nTable 8.1: Serum cholesterol (mg/100 ml\nWrite null alternative hypothesesChoose representation data (stacked unstacked) create csv fileImport data RSummarise visualise dataCheck assumptions (normality variance) using appropriate tests plotsPerform two-sample t-testWrite sentence summarises results found1. Hypotheses\\(H_0\\) : male mean \\(=\\) female mean\\(H_1\\) : male mean \\(\\neq\\) female mean2-4. Import Data, Summarise visualiseI’d always recommend storing data tidy, stacked format (fact can’t think situation want store data untidy, unstacked format!) example manually input data Excel following layout, saving data CSV file reading :Let’s summarise data…visualise data:always use plot summary assess three things:look like ’ve loaded data correctly?\ntwo groups extreme values plots seem match dataset, ’m happy haven’t done anything massively wrong .\ntwo groups extreme values plots seem match dataset, ’m happy haven’t done anything massively wrong .think difference two groups?\nneed result formal test make sense given data, ’s important develop sense think going happen . Whilst ranges two groups suggests Female serum levels might higher males look things closely realise isn’t case. boxplot shows median values two groups virtually identical backed summary statistics calculated: medians 224.1, means fairly close (225.7 vs 224.2). Based , fact 13 observations total surprised test came back showing difference groups.\nneed result formal test make sense given data, ’s important develop sense think going happen . Whilst ranges two groups suggests Female serum levels might higher males look things closely realise isn’t case. boxplot shows median values two groups virtually identical backed summary statistics calculated: medians 224.1, means fairly close (225.7 vs 224.2). Based , fact 13 observations total surprised test came back showing difference groups.think assumptions?\nNormality looks bit worrying: whilst Male group appears nice symmetric (might normal), Female group appears quite skewed (since median much closer bottom top). ’ll look carefully formal checks decided whether think data normal enough us use t-test.\nHomogeneity variance. stage spread data within group looks similar, potential skew Female group ’ll want check assumptions carefully.\nNormality looks bit worrying: whilst Male group appears nice symmetric (might normal), Female group appears quite skewed (since median much closer bottom top). ’ll look carefully formal checks decided whether think data normal enough us use t-test.Homogeneity variance. stage spread data within group looks similar, potential skew Female group ’ll want check assumptions carefully.5. Check AssumptionsNormalityLet’s look normality groups separately. several ways getting serum values Males Females separately. ’ll use unstacking method, use Shapiro-Wilk followed qqplots.p-values Shapiro-Wilk tests non-significant suggests data normal enough. bit surprising given saw boxplot two bits information can use reassure us.p-value Female group smaller Male group (suggesting Female group closer non-normal Male group) makes sense.Shapiro-Wilk test generally quite relaxed normality small sample sizes (notoriously strict large sample sizes). group 6 data points , data actually really, really skewed distribution. Given Female group 6 data points , ’s surprising Shapiro-Wilk test came back saying everything OK.results Q-Q plots echo ’ve already seen Shapiro-Wilk analyses. Male group doesn’t look bad whereas Female group looks somewhat dodgy.Overall, assumption normality data doesn’t appear well met , bear mind data points group might just seeing pattern data due random chance rather underlying populations actually normally distributed. Personally, though ’d edge towards non-normal .Homogeneity VarianceIt’s clear whether data normal , isn’t clear test use . sensible approach hope agree (fingers crossed!)Bartlett’s test gives us:Levene’s test gives us:good news Levene Bartlett agree homogeneity variance two groups (thank goodness!).Overall, means ’re sure normality, homogeneity variance pretty good.6. Carry two-sample t-testBecause result Bartlett test know can carry two-sample Student’s t-test (opposed two-sample Welch’s t-test, ’re confused, see Figure 7.2)p-value 0.544, test tells insufficient evidence suggest means two groups different. suitable summary sentence :Student’s two-sample t-test indicated mean serum cholesterol level differ significantly Male Female turtles (t = 0.627, df = 11, p = 0.544).DiscussionIn reality, ambiguous normality assumption assessment, dataset actually carry two different tests; two-sample t-test equal variance Mann-Whitney U test. agreed wouldn’t matter much one reported (’d personally report short sentence say ’m wasn’t clear whether assumption normality met), acceptable report just one.","code":"\nturtle <- read.csv(\"data/examples/cs1-turtle.csv\")\n\nturtle##    serum    sex\n## 1  220.1   Male\n## 2  218.6   Male\n## 3  229.6   Male\n## 4  228.8   Male\n## 5  222.0   Male\n## 6  224.1   Male\n## 7  226.5   Male\n## 8  223.4 Female\n## 9  221.5 Female\n## 10 230.2 Female\n## 11 224.3 Female\n## 12 223.8 Female\n## 13 230.8 Female\naggregate(serum ~ sex , data = turtle, summary)##      sex serum.Min. serum.1st Qu. serum.Median serum.Mean serum.3rd Qu.\n## 1 Female   221.5000      223.5000     224.0500   225.6667      228.7250\n## 2   Male   218.6000      221.0500     224.1000   224.2429      227.6500\n##   serum.Max.\n## 1   230.8000\n## 2   229.6000\nboxplot(serum ~ sex , data = turtle)\nuns_turtle <- unstack(turtle, serum ~ sex)\nshapiro.test(uns_turtle$Male)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_turtle$Male\n## W = 0.94392, p-value = 0.6743\nshapiro.test(uns_turtle$Female)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_turtle$Female\n## W = 0.84178, p-value = 0.1349\npar(mfrow=c(1,2))\nqqnorm(uns_turtle$Male, main = \"Male\")\nqqline(uns_turtle$Male, col = \"red\")\nqqnorm(uns_turtle$Female, main = \"Female\")\nqqline(uns_turtle$Female, col = \"red\")\nbartlett.test(serum ~ sex, turtle)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  serum by sex\n## Bartlett's K-squared = 0.045377, df = 1, p-value = 0.8313\n# load if needed\n# library(car)\n\nleveneTest(serum ~ sex, turtle)## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  1  0.2434 0.6315\n##       11\nt.test(serum ~ sex , turtle,\n       alternative=\"two.sided\",\n       var.equal=TRUE)## \n##  Two Sample t-test\n## \n## data:  serum by sex\n## t = 0.62681, df = 11, p-value = 0.5436\n## alternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n## 95 percent confidence interval:\n##  -3.575759  6.423378\n## sample estimates:\n## mean in group Female   mean in group Male \n##             225.6667             224.2429"},{},{"path":"cs1-mannwhitney-u-test.html","id":"cs1-mannwhitney-u-test","chapter":"9 Mann-Whitney U test","heading":"9 Mann-Whitney U test","text":"test also compares two samples, however test (contrast Student’s t-test) don’t assume parent distributions normally distributed. order compare medians two groups still need parent distributions (consequently samples) shape variance. test look see medians two parent distributions differ significantly .","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"section-commands-3","chapter":"9 Mann-Whitney U test","heading":"9.1 Section commands","text":"new commands used section.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"data-and-hypotheses-2","chapter":"9 Mann-Whitney U test","heading":"9.2 Data and hypotheses","text":", use rivers dataset. want test whether median body length male guppies differs samples. form following null alternative hypotheses:\\(H_0\\): difference median body length two groups 0 (\\(\\mu - \\mu G = 0\\))\\(H_1\\): difference median body length two groups 0 (\\(\\mu - \\mu G \\neq 0\\))use two-tailed Mann-Whitney U test see can reject null hypothesis.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"summarise-and-visualise-2","chapter":"9 Mann-Whitney U test","heading":"9.3 Summarise and visualise","text":"previous section.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"implement-test-1","chapter":"9 Mann-Whitney U test","heading":"9.4 Implement test","text":"Perform two-tailed, Mann-Whitney U test:case, data tidy format:first argument must formula format: variable ~ categoryThe second argument must name data frameThe third argument gives type alternative hypothesis must one two.sided, greater less","code":"\nwilcox.test(length ~ river, data = rivers,\n            alternative = \"two.sided\")## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  length by river\n## W = 841, p-value = 0.0006464\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"cs1-mannwhitney-u-test.html","id":"interpret-output-and-report-results-1","chapter":"9 Mann-Whitney U test","heading":"9.5 Interpret output and report results","text":"may get warning message console stating compute exact p-value ties. just means data points exactly value affects internal mathematics slightly. However, given p-value small, something need worry .warning message:1st line gives name test 2nd line reminds dataset called, variables usedThe 3rd line contains two key outputs test:\ncalculated W-value 841 (’ll use reporting)\np-value 0.0006464.\ncalculated W-value 841 (’ll use reporting)p-value 0.0006464.4th line simply states alternative hypothesis terms difference two sample medians difference one distribution shifted relative .Given p-value less 0.05 can reject null hypothesis confidence level.\n, p-value 3rd line ’re interested . Since p-value small (much smaller standard significance level) choose say “unlikely two samples came parent distribution can reject null hypothesis.”put completely, can state :Mann-Whitney test indicated median body length male guppies Guanapo river (18.8 mm) differs significantly median body length male guppies Aripo river (20.1 mm) (W = 841, p = 0.0006).","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"assumptions-3","chapter":"9 Mann-Whitney U test","heading":"9.6 Assumptions","text":"checked previously.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"exercise-4","chapter":"9 Mann-Whitney U test","heading":"9.7 Exercise","text":"Exercise 9.1  Analyse turtle dataset using Mann Whitney test.follow process Student’s t-test.Hypotheses\\(H_0\\) : male median \\(=\\) female median\\(H_1\\) : male median \\(\\neq\\) female medianSummarise visualiseThis .AssumptionsWe’ve already checked variances two groups similar, ’re OK . Whilst Mann-Whitney test doesn’t require normality symmetry distributions require distributions shape. example, just handful data points group, ’s quite hard make call one way another. advice case say unless ’s obvious distributions different can just allow assumption pass, ’re going see obvious differences distribution shape considerably data points .Carry Mann-Whitney testThis gives us exactly conclusion got two-sample t-test .e. isn’t significant difference two groups.Mann-Whitney test indicated wasn’t significant difference median Serum Cholesterol levels male female turtles (W = 26, p = 0.534)","code":"\nwilcox.test(serum ~ sex, data = turtle,\n            alternative = \"two.sided\")## \n##  Wilcoxon rank sum exact test\n## \n## data:  serum by sex\n## W = 26, p-value = 0.5338\n## alternative hypothesis: true location shift is not equal to 0"},{},{"path":"cs1-paired-two-sample-t-test.html","id":"cs1-paired-two-sample-t-test","chapter":"10 Paired two-sample t-test","heading":"10 Paired two-sample t-test","text":"paired t-test used two samples continuous data can paired (examples sort data weights individuals diet). test applicable number paired points within samples large (>30) , number points small, test also works parent distributions normally distributed.","code":""},{"path":"cs1-paired-two-sample-t-test.html","id":"section-commands-4","chapter":"10 Paired two-sample t-test","heading":"10.1 Section commands","text":"new commands section.","code":""},{"path":"cs1-paired-two-sample-t-test.html","id":"data-and-hypotheses-3","chapter":"10 Paired two-sample t-test","heading":"10.2 Data and hypotheses","text":"example, suppose measure cortisol levels 20 adult females (nmol/l) first thing morning evening. want test whether cortisol levels differs two measurement times. initially form following null alternative hypotheses:\\(H_0\\): difference cortisol level times (\\(\\mu M = \\mu E\\))\\(H_1\\): difference cortisol levels times (\\(\\mu M \\neq \\mu E\\))use two-sample, two-tailed paired t-test see can reject null hypothesis.use two-sample test now two samplesWe use two-tailed t-test want know data suggest true (population) means different one another rather one mean specifically bigger smaller otherWe use paired test data point first sample can linked another data point second sample connecting factorWe’re using t-test ’re assuming parent populations normal equal variance (’ll check bit)data stored unstacked format file “CS1-twopaired.csv.”\nRead R:","code":"\ncortisol <- read.csv(\"data/raw/CS1-twopaired.csv\")"},{"path":"cs1-paired-two-sample-t-test.html","id":"summarise-and-visualise-3","chapter":"10 Paired two-sample t-test","heading":"10.3 Summarise and visualise","text":"box plot capture cortisol level individual subject changed though. can explore individual changes morning evening creating boxplot differences two times measurement.differences cortisol levels appear much less zero, (meaning evening cortisol levels appear much lower morning ones). expect test give pretty significant result.","code":"\nsummary(cortisol)##     morning         evening     \n##  Min.   :146.1   Min.   : 60.1  \n##  1st Qu.:266.6   1st Qu.:137.8  \n##  Median :320.5   Median :188.9  \n##  Mean   :313.5   Mean   :197.4  \n##  3rd Qu.:359.7   3rd Qu.:260.8  \n##  Max.   :432.5   Max.   :379.3\nboxplot(cortisol, ylab = \"Level (nmol/l)\")\n# calculate the difference between evening and morning values\nchangeCor <- cortisol$evening - cortisol$morning\n\nboxplot(changeCor, ylab = \"Change in cortisol (nmol/l)\")"},{"path":"cs1-paired-two-sample-t-test.html","id":"implement-test-2","chapter":"10 Paired two-sample t-test","heading":"10.4 Implement test","text":"Perform two-sample, two-tailed, paired t-test:first two arguments must vectors containing numerical data samplesThe third argument gives type alternative hypothesis must one two.sided, greater lessThe fourth argument says data paired","code":"\nt.test(cortisol$evening, cortisol$morning,\n       alternative = \"two.sided\", paired = TRUE)"},{"path":"cs1-paired-two-sample-t-test.html","id":"interpret-output-and-report-results-2","chapter":"10 Paired two-sample t-test","heading":"10.5 Interpret output and report results","text":"perspective value interested 3rd line (p-value = 5.288e10-5). Given substantially less 0.05 can reject null hypothesis state:two-tailed, paired t-test indicated cortisol level adult females differed significantly morning (313.5 nmol/l) evening (197.4 nmol/l) (t = -5.1833, df = 19, p = 5.3x10-5).","code":"## \n##  Paired t-test\n## \n## data:  cortisol$evening and cortisol$morning\n## t = -5.1833, df = 19, p-value = 5.288e-05\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -162.96038  -69.20962\n## sample estimates:\n## mean of the differences \n##                -116.085"},{"path":"cs1-paired-two-sample-t-test.html","id":"assumptions-4","chapter":"10 Paired two-sample t-test","heading":"10.6 Assumptions","text":"exercise!","code":""},{"path":"cs1-paired-two-sample-t-test.html","id":"exercise-5","chapter":"10 Paired two-sample t-test","heading":"10.7 Exercise","text":"Exercise 10.1  Checking assumptionsCheck assumptions necessary paired t-test.\npaired t-test appropriate test?paired test really just one-sample test disguise. actually don’t care much distributions individual groups. Instead care properties differences. paired t-test valid dataset, need differences morning evening values normally distributed.Let’s check Shapiro-Wilk Q-Q plots using changeCor variable created earlier.Shapiro-Wilk test says data normal enough whilst Q-Q plot mostly fine, suggestion snaking bottom left. ’m actually OK suggestion snaking actually due single point (last point left). cover point thumb (finger choice) remaining points Q-Q plot look pretty damn good, suggestion snaking actually driven single point (can happen chance). ’m actually happy assumption normality well met case. single point check useful thing remember assessing diagnostic plots., yep, paired t-test appropriate dataset.","code":"\nshapiro.test(changeCor)## \n##  Shapiro-Wilk normality test\n## \n## data:  changeCor\n## W = 0.92362, p-value = 0.1164\nqqnorm(changeCor)\nqqline(changeCor, col = \"red\")"},{},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"cs1-twosample-wilcoxon-signed-rank","chapter":"11 Wilcoxon signed-rank test","heading":"11 Wilcoxon signed-rank test","text":"Wilcoxon signed-rank test alternative paired t-test. require data drawn normal distributions, require distribution differences symmetric. ’re effectively testing see median differences two samples differs significantly zero.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"section-commands-5","chapter":"11 Wilcoxon signed-rank test","heading":"11.1 Section commands","text":"new commands section.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"data-and-hypotheses-4","chapter":"11 Wilcoxon signed-rank test","heading":"11.2 Data and hypotheses","text":"Using cortisol dataset form following null alternative hypotheses:\\(H_0\\): median difference cortisol levels two groups 0 (\\(\\mu M = \\mu E\\))\\(H_1\\): median difference cortisol levels two groups 0 (\\(\\mu M \\neq \\mu E\\))use two-tailed Wilcoxon signed-rank test see can reject null hypothesis.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"summarise-and-visualise-4","chapter":"11 Wilcoxon signed-rank test","heading":"11.3 Summarise and visualise","text":"Already implemented previously.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"implement-test-3","chapter":"11 Wilcoxon signed-rank test","heading":"11.4 Implement test","text":"Perform two-tailed, Wilcoxon signed-rank test:first two arguments must two samples numerical vector formatThe second argument gives type alternative hypothesis must one two.sided, greater lessThe third argument indicates test paired","code":"\nwilcox.test(cortisol$morning, cortisol$evening,\n            alternative = \"two.sided\", paired = TRUE)"},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"interpret-output-and-report-results-3","chapter":"11 Wilcoxon signed-rank test","heading":"11.5 Interpret output and report results","text":"p value given 3rd line (p-value = 0.0001678). Given less 0.05 can still reject null hypothesis.two-tailed, Wilcoxon signed-rank test indicated median cortisol level adult females differed significantly morning (320.5 nmol/l) evening (188.9 nmol/l) (V = 197, p = 0.00017).","code":"## \n##  Wilcoxon signed rank exact test\n## \n## data:  cortisol$morning and cortisol$evening\n## V = 197, p-value = 0.0001678\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"assumptions-5","chapter":"11 Wilcoxon signed-rank test","heading":"11.6 Assumptions","text":"checked previously.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"exercise-6","chapter":"11 Wilcoxon signed-rank test","heading":"11.7 Exercise","text":"Exercise 11.1  Deer legsUsing following data, test null hypothesis fore hind legs deer length.\nTable 11.1: Deer leg length (cm)\nresults provide evidence suggest fore- hind-leg length differ deer?Write null alternative hypothesesChoose representation data (stacked unstacked) create csv fileImport data RSummarise visualise dataPerform two-sample paired t-testPerform Wilcoxon signed-rank testNow check assumptions (normality variance) using appropriate testsDiscuss (virtual) neighbour test appropriate?Write sentence summarise results found1. Hypotheses\\(H_0\\) : foreleg average (mean median) \\(=\\) hindleg average (mean median)\\(H_1\\) : foreleg average \\(\\neq\\) hindleg average2-4. Import Data, Summarise visualiseI always recommend storing data stacked format even example, even though case might seem easier store data unstacked format (pretty much time even sensible option). example manually input data excel following layout:ordering data important ; first hindleg row corresponds first foreleg row, second second . indicate use id column, observation unique ID.Let’s look data see can see.looks though might difference legs, hindlegs longer forelegs. However, representation obscures fact paired data. really need look difference leg length deer:gives us much clearer picture. looks though hindlegs 4 cm longer forelegs, average. also suggests leg differences might normally distributed (data look bit skewed).5. Perform two-sample t-testThe paired t-test assumes data stored exactly entered (.e. first hindleg row matches first foreleg row). apparently see significant difference.6. Perform paired Wilcoxon testThe paired Wilcoxon test makes assumptions order data paired t-test. significant difference.7. Check assumptionsWe need consider distribution difference leg lengths rather individual distributions.Shapiro-Wilk test Q-Q plot suggest difference data aren’t normally distributed, rules paired t-test. therefore consider paired Wilcoxon test next. Remember test requires distribution differences symmetric, whereas box-plot suggested data much skewed.8. ConclusionsSo, frustratingly, neither tests appropriate dataset. differences fore- hind leg lengths neither normal enough paired t-test symmetric enough Wilcoxon test don’t enough data just use t-test (’d need 30 points ). situation? Well answer aren’t actually traditional statistical tests valid dataset stands!two options available someone:try transforming raw data (take logs, square root, reciprocals) hope one leads modified dataset satisfies assumptions one tests ’ve covered, oruse permutation test approach (work beyond scope course).reason included example first practical purely illustrate simple dataset apparently clear message (leg lengths differ within deer) can intractable. don’t need complex datasets go beyond capabilities classical statistics.Jeremy Clarkson put :bombshell, ’s time end. Goodnight!","code":"\ndeer <- read.csv(\"data/examples/cs1-deer.csv\")\naggregate(length ~ leg, data = deer, summary)##       leg length.Min. length.1st Qu. length.Median length.Mean length.3rd Qu.\n## 1 foreleg      136.00         138.25        142.00      141.40         144.50\n## 2 hindleg      140.00         142.00        144.00      144.70         147.50\n##   length.Max.\n## 1      147.00\n## 2      150.00\nboxplot(length ~ leg, data = deer)\nuns_deer <- unstack(deer, length ~ leg)\ndeerDiff <- uns_deer$hindleg - uns_deer$foreleg\nsummary(deerDiff)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    -3.0     2.5     4.5     3.3     5.0     6.0\nboxplot(deerDiff)\nt.test(length ~ leg, data = deer, paired = TRUE)## \n##  Paired t-test\n## \n## data:  length by leg\n## t = -3.4138, df = 9, p-value = 0.007703\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -5.486752 -1.113248\n## sample estimates:\n## mean of the differences \n##                    -3.3\nwilcox.test(length ~ leg, data = deer, paired = TRUE)## Warning in wilcox.test.default(x = c(138L, 136L, 147L, 139L, 143L, 141L, :\n## cannot compute exact p-value with ties## \n##  Wilcoxon signed rank test with continuity correction\n## \n## data:  length by leg\n## V = 4, p-value = 0.01859\n## alternative hypothesis: true location shift is not equal to 0\nshapiro.test(deerDiff)## \n##  Shapiro-Wilk normality test\n## \n## data:  deerDiff\n## W = 0.81366, p-value = 0.02123\nqqnorm(deerDiff)\nqqline(deerDiff, col = \"red\")"},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"key-points-1","chapter":"11 Wilcoxon signed-rank test","heading":"11.8 Key points","text":"use two-sample tests see two samples continuous data come parent distributionThis essentially boils testing mean median differs two samplesThere 5 key two-sample tests: Student’s t-test, Welch’s t-test, Mann-Whitney U test, paired t-test Wilcoxon signed-rank testWhich one use depends normality distribution, sample size, paired unpaired data variance samplesParametric tests used data normally distributed sample size largeNon-parametric tests used data normally distributed sample size smallEquality variance determines test appropriateYou can ask 3 questions determine test:\ndata paired?\nneed parametric non-parametric test\ncan assume equality variance?\ndata paired?need parametric non-parametric testcan assume equality variance?","code":""},{},{"path":"cs2-intro.html","id":"cs2-intro","chapter":"12 Introduction","heading":"12 Introduction","text":"","code":""},{"path":"cs2-intro.html","id":"objectives-3","chapter":"12 Introduction","heading":"12.1 Objectives","text":"Aim: introduce R commands analysing single categorical predictors.end practical participants able perform following statistical analyses:One-way Analysis Variance (ANOVA)Kruskal-Wallis testFor , participants able :Perform test RInterpret outputCheck assumptions testCarry post-hoc test appropriateThe tests covered practical :One-way ANOVAKruskall-Wallis test","code":""},{"path":"cs2-intro.html","id":"background-1","chapter":"12 Introduction","heading":"12.2 Background","text":"practical focuses implementation various statistical tests relating categorical predictors. boil ANOVA Kruskal-Wallis (non-parametric alternative).\n, focus underlying theory tests (although demonstrators happy answer questions may ).test section :explains purpose test,explains visualise data,explains perform test R,explains interpret output report results, andexplains assess assumptions required perform test.","code":""},{},{"path":"introduction-1.html","id":"introduction-1","chapter":"13 Introduction","heading":"13 Introduction","text":"practical introducing can compare data different groups.","code":""},{"path":"introduction-1.html","id":"cs2-datasets","chapter":"13 Introduction","heading":"13.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"cs2-anova.html","id":"cs2-anova","chapter":"14 ANOVA","heading":"14 ANOVA","text":"","code":""},{"path":"cs2-anova.html","id":"objectives-4","chapter":"14 ANOVA","heading":"14.1 Objectives","text":"QuestionsHow ……ObjectivesBe able …Use…","code":""},{"path":"cs2-anova.html","id":"purpose-and-aim-2","chapter":"14 ANOVA","heading":"14.2 Purpose and aim","text":"Analysis variance ANOVA test can used multiple samples continuous data. Whilst possible use ANOVA two samples, generally used three groups. used find samples came parent distributions mean. can thought generalisation two-sample Student’s t-test.","code":""},{"path":"cs2-anova.html","id":"section-commands-6","chapter":"14 ANOVA","heading":"14.3 Section commands","text":"New commands used section.","code":""},{"path":"cs2-anova.html","id":"data-and-hypotheses-5","chapter":"14 ANOVA","heading":"14.4 Data and hypotheses","text":"example, suppose measure feeding rate oyster catchers (shellfish per hour) three sites characterised degree shelter wind, imaginatively called exposed (E), partially sheltered (P) sheltered (S). want test whether data support hypothesis feeding rates don’t differ locations. form following null alternative hypotheses:\\(H_0\\): mean feeding rates three sites \\(\\mu E = \\mu P = \\mu S\\)\\(H_1\\): mean feeding rates equal.use one-way ANOVA test check .use one-way ANOVA test one predictor variable (categorical variable location).’re using ANOVA two groups don’t know better yet respect exact assumptions.data stored file CS2-oystercatcher.csv.","code":""},{"path":"cs2-anova.html","id":"summarise-and-visualise-5","chapter":"14 ANOVA","heading":"14.5 Summarise and visualise","text":"First read data.Next summarise data visualise . quick peek first rows data head() can see data organised.data stacked format. first column contains information feeding rates called feeding. second column categorical data type site called site.Looking data, appears noticeable difference feeding rates three sites. probably expect reasonably significant statistical result .","code":"\noystercatcher <- read.csv(\"data/raw/CS2-oystercatcher.csv\")\nhead(oystercatcher)##   feeding    site\n## 1    14.2 Exposed\n## 2    16.5 Exposed\n## 3     9.3 Exposed\n## 4    15.1 Exposed\n## 5    13.4 Exposed\n## 6    18.4 Partial\naggregate(feeding ~ site, data = oystercatcher, summary)##        site feeding.Min. feeding.1st Qu. feeding.Median feeding.Mean\n## 1   Exposed         9.30           13.40          14.20        13.70\n## 2   Partial        13.00           16.50          17.40        17.14\n## 3 Sheltered        21.50           22.20          24.10        23.64\n##   feeding.3rd Qu. feeding.Max.\n## 1           15.10        16.50\n## 2           18.40        20.40\n## 3           25.10        25.30\nboxplot(feeding ~ site, data = oystercatcher)"},{"path":"cs2-anova.html","id":"implement-test-4","chapter":"14 ANOVA","heading":"14.6 Implement test","text":"Perform ANOVA test data:first line fits linear model data (.e. finds means three groups calculates load intermediary data need statistical analysis) stores information R object (’ve called lm_oystercatchers, can call like). second line actually carries ANOVA analysis.first argument must formula format: response ~ predictorIf data stored stacked format, second argument must name data frameThe anova() command takes linear model object main argument","code":"\nlm_oystercatcher <- lm(feeding ~ site, data = oystercatcher)\n\nanova(lm_oystercatcher)"},{"path":"cs2-anova.html","id":"interpret-output-and-report-results-4","chapter":"14 ANOVA","heading":"14.7 Interpret output and report results","text":"output now see console window:1st line just tells ANOVA testThe 2nd line tells response variable (case feeding)3rd, 4th 5th lines ANOVA table contain useful values:\nDf column contains degrees freedom values row, 2 12 (’ll need reporting)\nF value column contains F statistic, 21.508 (’ll need reporting).\np-value 0.0001077 number directly Pr(>F) 4th line.\nvalues table (Sum Sq Mean Sq) columns used calculate F statistic don’t need know .\nDf column contains degrees freedom values row, 2 12 (’ll need reporting)F value column contains F statistic, 21.508 (’ll need reporting).p-value 0.0001077 number directly Pr(>F) 4th line.values table (Sum Sq Mean Sq) columns used calculate F statistic don’t need know .6th line symbolic codes represent big (small) p-value ; , p-value smaller 0.001 *** symbol next (). Whereas p-value 0.01 0.05 simply * character next , etc. Thankfully can cope actual numbers don’t need short-hand code determine reporting experiments (please tell ’s true…!), p-value ’re interested shows us probability getting samples null hypothesis actually true.Since p-value small (much smaller standard significance level 0.05) can say “unlikely three samples came parent distribution” can reject null hypothesis state :one-way ANOVA showed mean feeding rate oystercatchers differed significantly locations (F = 21.51, df = 2, 12, p = 0.00011).Note included (brackets) information test statistic (F = 21.51), degrees freedom (df = 2, 12), p-value (p = 0.00011).","code":"## Analysis of Variance Table\n## \n## Response: feeding\n##           Df  Sum Sq Mean Sq F value    Pr(>F)    \n## site       2 254.812 127.406  21.508 0.0001077 ***\n## Residuals 12  71.084   5.924                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"cs2-anova.html","id":"assumptions-6","chapter":"14 ANOVA","heading":"14.8 Assumptions","text":"use ANOVA test, make three assumptions:parent distributions samples taken normally distributedEach data point samples independent othersThe parent distributions varianceIn similar way two-sample tests consider normality equality variance assumptions using tests graphical inspection (ignore independence assumption).1. NormalityUnstack data perform Shapiro-Wilk test group separately.output now see console window:can see three groups appear normally distributed good.ANOVA however, considering group turn often considered quite excessive , cases, sufficient consider normality combined set residuals data. ’ll explain residuals properly next session effectively difference data point group mean. residuals can obtained directly linear model fitted earlier.Extract residuals data check normality:, can see combined residuals three groups appear normally distributed (expected given normally distributed individually!)2. Equality VarianceWe now test equality variance using Bartlett’s test (since ’ve just found individual groups normally distributed).Perform Bartlett’s test data:relevant p-value given 3rd line. see group appear variance.3. Graphical Interpretation Diagnostic PlotsR provides convenient set graphs allow us assess assumptions graphically. simply ask R plot lm object created, can see diagnostic plots.Create standard set diagnostic plots:second line creates three diagnostic plots (actually tries create four plots can’t dataset ’ll also see warning text output screen (something hat values). ’ll go next session ’s easier explain).example, two plots (top-left bottom-left) show effectively thing: distribution data group look like. allow informal check equality variance assumption.\ntop-left graph want data symmetric 0 horizontal line spread (please ignore red line; unhelpful addition graphs).\nbottom-left graph, look red line want approximately horizontal.\ntop-left graph want data symmetric 0 horizontal line spread (please ignore red line; unhelpful addition graphs).bottom-left graph, look red line want approximately horizontal.top-right graph familiar Q-Q plot used previously assess normality, looks combined residuals groups (much way looked Shapiro-Wilk test combined residuals).can see graphs much line ’ve just looked using test, reassuring. groups appear spread data, whilst QQ-plot isn’t perfect, appears assumption normality allright.stage, point nearly always stick graphical method assessing assumptions test. Assumptions rarely either completely met met always degree personal assessment.Whilst formal statistical tests (like Shapiro) technically fine, can often create false sense things absolutely right wrong spite fact still probabilistic statistical tests. exercises using approaches whilst gain confidence experience interpreting graphical output whilst absolutely fine use future strongly recommend don’t rely solely statistical tests isolation.","code":"\nuns_oyster <- unstack(oystercatcher)\n\nshapiro.test(uns_oyster$Exposed)\nshapiro.test(uns_oyster$Partial)\nshapiro.test(uns_oyster$Sheltered)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_oyster$Exposed\n## W = 0.9151, p-value = 0.4988## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_oyster$Partial\n## W = 0.96913, p-value = 0.8697## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_oyster$Sheltered\n## W = 0.88532, p-value = 0.3341\nresid_oyster <- residuals(lm_oystercatcher)\n\nshapiro.test(resid_oyster)## \n##  Shapiro-Wilk normality test\n## \n## data:  resid_oyster\n## W = 0.93592, p-value = 0.3338\nbartlett.test(feeding ~ site, data = oystercatcher)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  feeding by site\n## Bartlett's K-squared = 0.90632, df = 2, p-value = 0.6356\n# create a neat 2x2 window\npar(mfrow = c(2,2))\n# create the diagnostic plots\nplot(lm_oystercatcher)\n# and return the window back to normal\npar(mfrow = c(1,1))## hat values (leverages) are all = 0.2\n##  and there are no factor predictors; no plot no. 5"},{"path":"cs2-anova.html","id":"post-hoc-testing","chapter":"14 ANOVA","heading":"14.9 Post-hoc testing","text":"One drawback using ANOVA test tests see means , get significant result using ANOVA can say means , rather anything pairs groups differ. example, consider following boxplot three samples.group random sample 20 points normal distribution variance 1. Groups 1 2 come parent population mean 0 whereas group 3 come parent population mean 2. data clearly satisfy assumptions ANOVA test.1. Read data plot2. Test significant difference group meansHere p-value 2.39x10-7 test conclusively rejected hypothesis means equal.However, due sample means different, rather just one groups different others. order drill investigate use new test called Tukey’s range test (Tukey’s honest significant difference test – always makes think terrible cowboy/western dialogue). compare groups pairwise fashion reports whether significant difference exists.3. Performing Tukey’s test dataThe first argument repeats ANOVA using different function ‘aov().’ store output function R object called aov_tukey.\nNote TukeyHSD() function takes output aov() function argument raw data.bottom three lines contain information want. final column (entitled p adj) p-value ’re looking . null hypothesis case difference mean two groups. can see first line shows isn’t significant difference sample1 sample2 2nd 3rd lines show significant difference sample1 sample3, well sample2 sample3. matches expected based boxplot.4. AssumptionsWhen use Tukey’s range test matter debate (strangely enough lot statistical analysis techniques currently matters opinion rather mathematical fact – explain little whole field appears bloody confusing!)people claim perform Tukey’s range test (post-hoc tests) preceding ANOVA test showed significant difference groups ANOVA test shown significant differences groups stop .people say rubbish can hell like, like long tell people .background rather involved one reasons debate prevent -called data-dredging p-hacking. scientists/analysts fixated getting “significant” result perform huge variety statistical techniques find one shows data significant (particular problem psychological studies – point fingers though, working hard sort stuff . Kudos!).Whether use post-hoc testing depend experimental design questions ’re attempting answer.Tukey’s range test, decide use , requires three assumptions ANOVA test:Normality distributionsEquality variance groupsIndependence observations","code":"\ntukey <- read.csv(\"data/raw/CS2-tukey.csv\")\nboxplot(response ~ group, data = tukey)\nlm_tukey <- lm(response ~ group, data = tukey)\n\nanova(lm_tukey)## Analysis of Variance Table\n## \n## Response: response\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## group      2 33.850 16.9250   20.16 2.392e-07 ***\n## Residuals 57 47.854  0.8395                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\naov_tukey <- aov(response ~ group, data = tukey)\n\nTukeyHSD(aov_tukey)##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = response ~ group, data = tukey)\n## \n## $group\n##                      diff        lwr      upr     p adj\n## sample2-sample1 0.3037563 -0.3934982 1.001011 0.5498005\n## sample3-sample1 1.7233591  1.0261047 2.420614 0.0000005\n## sample3-sample2 1.4196028  0.7223484 2.116857 0.0000246"},{"path":"cs2-anova.html","id":"exercise-7","chapter":"14 ANOVA","heading":"14.10 Exercise","text":"Exercise 14.1  Juvenile lobster weightJuvenile lobsters aquaculture grown three different diets (fresh mussels, semi-dry pellets dry flakes). nine weeks, wet weight :evidence diet affects growth rate lobsters?Write null alternative hypothesesImport data R\ndata stored file data/raw/CS2-lobsters.csv\ndata stored file data/raw/CS2-lobsters.csvSummarise visualise dataCheck assumptions using appropriate tests graphical analysesPerform ANOVA testWrite sentence summarise results foundPerform post-hoc test report findings1. Hypotheses\\(H_0\\) : means equal\\(H_1\\) : means equal2-3. Import Data, summarise visualiseThe data stored .csv file stacked format columns called weight diet.Let’s look data see can see.always use plot summary assess three things:load data properly?see three groups reasonable values. aren’t data points obviously wrong (negative, zero massively big) right number groups. looks didn’t anything obviously wrong.expect result statistical test?Whilst Mussels group look higher two groups, Pellets Flakes appear almost identical terms average values, ’s quite bit overlap Mussels group. non-significant result likely answer, surprised see significant p-value - especially given small sample size .think assumptions?groups appear mainly symmetric (although Pellets bit weird) ’re immediately massively worried lack normality. , Flakes Mussels appear similar variances ’s bit hard decide ’s going Pellets. ’s hard say ’s going assumptions ’ll wait see tests say.4. Explore AssumptionsNormalityWe’ll really thorough consider normality group separately jointly using Shapiro-Wilk test, well looking Q-Q plot. reality, examples , ’ll use Q-Q plot.’ll need unstack data use Shapiro-Wilk test individual groups:Flakes Mussels fine, , suspected earlier, Pellets appears marginally significant Normality test result.Let’s look Shapiro-Wilk test data together:hand says everything fine. Let’s look Q-Q-plot:, ’ve used extra argument normal diagnostic plots call. default option plot 4 diagnostic plots, can tell R plot specific one. (want know look plot.lm help documentation using ?plot.lm). ’ve asked R plot Q-Q plot = 2 argument.Q-Q plot looks OK, perfect, good enough us confidence normality data.Overall, ’d happy assumption normality adequately well met . suggested lack normality Pellets just significant take account 5 data points group. lot points group, Q-Q plot considerably worse wouldn’t confident.Equality VarianceWe’ll consider Bartlett test ’ll look diagnostic plots .code, ’ve used trick argument plot two diagnostic plots relate equality variance (residuals vs fitted scale-location).three methods agree isn’t issues equality variance:Bartlett test p-value large non-significantthe spread points three groups residuals vs fitted graph roughly samethe red line scale-location graph pretty horizontalOverall, assumption pretty well met.5. Carry one-way ANOVAWith assumptions normality equality variance met can confident one-way ANOVA appropriate test.6. ResultA one-way ANOVA test indicated mean weight juvenile lobsters differ significantly diets (F = 1.64, df = 2,15, p = 0.23).7. Post-hoc testing TukeyHere can see actually, significant difference pairs groups dataset.want reiterate carrying post-hoc test getting non-significant result ANOVA something think carefully depends research question .research question :diet affect lobster weight? effect diet lobster weight?got non-significant result ANOVA test just stopped answer. Going digging “significant” results running tests main factor contributes towards lack reproducibility research.hand research question :specific diets better worse lobster weight others?probably just skipped one-way ANOVA test entirely just jumped straight Tukey’s range test, important point result one-way ANOVA test doesn’t preclude carrying Tukey test.","code":"\nlobsters <- read.csv(\"data/raw/CS2-lobsters.csv\")##    weight    diet\n## 1   151.6 Mussels\n## 2   132.1 Mussels\n## 3   104.2 Mussels\n## 4   153.5 Mussels\n## 5   132.0 Mussels\n## 6   119.0 Mussels\n## 7   161.9 Mussels\n## 8   117.7 Pellets\n## 9   110.8 Pellets\n## 10  128.6 Pellets\n## 11  110.1 Pellets\n## 12  175.2 Pellets\n## 13  101.8  Flakes\n## 14  102.9  Flakes\n## 15   90.4  Flakes\n## 16  132.8  Flakes\n## 17  129.3  Flakes\n## 18  129.4  Flakes\naggregate(weight ~ diet, data = lobsters, summary)##      diet weight.Min. weight.1st Qu. weight.Median weight.Mean weight.3rd Qu.\n## 1  Flakes     90.4000       102.0750      116.1000    114.4333       129.3750\n## 2 Mussels    104.2000       125.5000      132.1000    136.3286       152.5500\n## 3 Pellets    110.1000       110.8000      117.7000    128.4800       128.6000\n##   weight.Max.\n## 1    132.8000\n## 2    161.9000\n## 3    175.2000\nboxplot(weight ~ diet, data = lobsters)\nlobst_uns <- unstack(lobsters, weight ~ diet)\nshapiro.test(lobst_uns$Flakes)## \n##  Shapiro-Wilk normality test\n## \n## data:  lobst_uns$Flakes\n## W = 0.84368, p-value = 0.1398\nshapiro.test(lobst_uns$Mussels)## \n##  Shapiro-Wilk normality test\n## \n## data:  lobst_uns$Mussels\n## W = 0.94784, p-value = 0.71\nshapiro.test(lobst_uns$Pellets)## \n##  Shapiro-Wilk normality test\n## \n## data:  lobst_uns$Pellets\n## W = 0.76706, p-value = 0.0425\nresid_lobst <- residuals(lm(weight ~ diet, data = lobsters))\nshapiro.test(resid_lobst)## \n##  Shapiro-Wilk normality test\n## \n## data:  resid_lobst\n## W = 0.94779, p-value = 0.3914\nplot(lm(weight ~ diet , data = lobsters),\n     which = 2)\nbartlett.test(weight ~ diet, data = lobsters)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  weight by diet\n## Bartlett's K-squared = 0.71273, df = 2, p-value = 0.7002\nplot(lm(weight ~ diet, data = lobsters),\n     which = c(1,3))\nanova(lm(weight ~ diet, data = lobsters))## Analysis of Variance Table\n## \n## Response: weight\n##           Df Sum Sq Mean Sq F value Pr(>F)\n## diet       2 1567.2  783.61  1.6432 0.2263\n## Residuals 15 7153.1  476.87\nTukeyHSD(aov(weight ~ diet, data = lobsters))##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = weight ~ diet, data = lobsters)\n## \n## $diet\n##                      diff        lwr      upr     p adj\n## Mussels-Flakes  21.895238  -9.661957 53.45243 0.2024851\n## Pellets-Flakes  14.046667 -20.300196 48.39353 0.5508657\n## Pellets-Mussels -7.848571 -41.061560 25.36442 0.8148766"},{"path":"cs2-anova.html","id":"key-points-2","chapter":"14 ANOVA","heading":"14.11 Key points","text":"Point 1Point 2Point 3","code":""},{},{"path":"kruskal-wallis-test.html","id":"kruskal-wallis-test","chapter":"15 Kruskal-Wallis test","heading":"15 Kruskal-Wallis test","text":"","code":""},{"path":"kruskal-wallis-test.html","id":"objectives-5","chapter":"15 Kruskal-Wallis test","heading":"15.1 Objectives","text":"QuestionsHow ……ObjectivesBe able …Use…","code":""},{"path":"kruskal-wallis-test.html","id":"purpose-and-aim-3","chapter":"15 Kruskal-Wallis test","heading":"15.2 Purpose and aim","text":"Kruskal-Wallis one-way analysis variance test analogue ANOVA can used assumption normality met. way extension Mann-Whitney test two groups.","code":""},{"path":"kruskal-wallis-test.html","id":"section-commands-7","chapter":"15 Kruskal-Wallis test","heading":"15.3 Section commands","text":"New commands used section:","code":""},{"path":"kruskal-wallis-test.html","id":"data-and-hypotheses-6","chapter":"15 Kruskal-Wallis test","heading":"15.4 Data and hypotheses","text":"example, suppose behavioural ecologist records rate spider monkeys behaved aggressively towards one another function closely related two monkeys . familiarity two monkeys involved interaction classified high, low none. want test data support hypothesis aggression rates differ according strength relatedness. form following null alternative hypotheses:\\(H_0\\): median aggression rates types familiarity \\(H_1\\): median aggression rates equalWe use Kruskal-Wallis test check .data stored file data/raw/CS2-spidermonkey.csv.First read data :","code":"\nspidermonkey <- read.csv(\"data/raw/CS2-spidermonkey.csv\")"},{"path":"kruskal-wallis-test.html","id":"summarise-and-visualise-6","chapter":"15 Kruskal-Wallis test","heading":"15.5 Summarise and visualise","text":"data appear show significant difference aggression rates three types familiarity. probably expect reasonably significant result .","code":"\n# look at the data format\nhead(spidermonkey)##   aggression familiarity\n## 1        0.2        high\n## 2        0.1        high\n## 3        0.4        high\n## 4        0.8        high\n## 5        0.3        high\n## 6        0.5        high\n# summarise the data\naggregate(aggression ~ familiarity, data = spidermonkey, summary)##   familiarity aggression.Min. aggression.1st Qu. aggression.Median\n## 1        high       0.1000000          0.2000000         0.3000000\n## 2         low       0.3000000          0.4500000         0.5000000\n## 3        none       0.9000000          1.1500000         1.2000000\n##   aggression.Mean aggression.3rd Qu. aggression.Max.\n## 1       0.3571429          0.4500000       0.8000000\n## 2       0.6285714          0.7500000       1.2000000\n## 3       1.2571429          1.4000000       1.6000000\n# create boxplot\nboxplot(aggression ~ familiarity, data = spidermonkey)"},{"path":"kruskal-wallis-test.html","id":"implement-test-5","chapter":"15 Kruskal-Wallis test","heading":"15.6 Implement test","text":"Perform Kruskal-Wallis test data:first argument must formula format: variable ~ categoryIf data stored stacked format, second argument must name data frame","code":"\nkruskal.test(aggression ~ familiarity, data = spidermonkey)"},{"path":"kruskal-wallis-test.html","id":"interpret-output-and-report-results-5","chapter":"15 Kruskal-Wallis test","heading":"15.7 Interpret output and report results","text":"output now see console window:p-value given 3rd line. shows us probability getting samples null hypothesis actually true.Since p-value small (much smaller standard significance level 0.05) can say “unlikely three samples came parent distribution can reject null hypothesis” state :one-way Kruskal-Wallis rank sum test showed aggression rates spidermonkeys depends upon degree familiarity (KW = 13.597, df = 2, p = 0.0011).","code":"## \n##  Kruskal-Wallis rank sum test\n## \n## data:  aggression by familiarity\n## Kruskal-Wallis chi-squared = 13.597, df = 2, p-value = 0.001115"},{"path":"kruskal-wallis-test.html","id":"assumptions-7","chapter":"15 Kruskal-Wallis test","heading":"15.8 Assumptions","text":"use Kruskal-Wallis test make three assumptions:parent distributions samples drawn shape (’re normal use one-way ANOVA)data point samples independent othersThe parent distributions varianceIndependence ’ll ignore usual. Similar shape best assessed earlier visualisation data. means need check equality variance.Equality varianceWe test equality variance using Levene’s test (since can’t assume normal parent distributions rules Bartlett’s test).Levene’s test included default R packages may require installation additional package called car (Companion Applied Regression).install car package, run following command console:Alternatively, go Tools > Install packages… > Packages, type car press InstallRemember load library library(car).Perform Levene’s test data:relevant p-value given 3rd line (Pr(>F) = 0.893). quite large see group appear variance.also warning group coerced factor. need worry - Levene’s test needs compare different groups aggression encoded numeric value, converts categorical one running test.","code":"\ninstall.packages(\"car\")\nleveneTest(aggression ~ familiarity, data = spidermonkey)## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\n## factor.## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  2  0.1139  0.893\n##       18"},{"path":"kruskal-wallis-test.html","id":"post-hoc-testing-1","chapter":"15 Kruskal-Wallis test","heading":"15.9 Post-hoc testing","text":"equivalent Tukey’s range test non-normal data Dunn’s test.\nDunn’s test also included default R packages may require installation additional package called dunn.test.install dunn.test package, run following command console:Alternatively, go Tools > Install packages… > Packages, type dunn.test press InstallRemember load library library(dunn.test).Test significant difference group medians:Note Dunn’s test requires us enter two arguments, first vector values second vector containing category labels (.e. factor).give following output:can see dunn.test() function also performs Kruskal-Wallis test data, results reported initially.comparison pairs groups reported table bottom. cell table two rows. bottom row contains p-values want. table shows isn’t significant difference high low groups, p-value (0.0799) high. two comparisons high familiarity familiarity groups low groups significant though.","code":"\ninstall.packages(\"dunn.test\")\ndunn.test(spidermonkey$aggression, spidermonkey$familiarity)##   Kruskal-Wallis rank sum test\n## \n## data: x and group\n## Kruskal-Wallis chi-squared = 13.5972, df = 2, p-value = 0\n## \n## \n##                            Comparison of x by group                            \n##                                 (No adjustment)                                \n## Col Mean-|\n## Row Mean |       high        low\n## ---------+----------------------\n##      low |  -1.405820\n##          |     0.0799\n##          |\n##     none |  -3.655132  -2.249312\n##          |    0.0001*    0.0122*\n## \n## alpha = 0.05\n## Reject Ho if p <= alpha/2"},{"path":"kruskal-wallis-test.html","id":"exercise-8","chapter":"15 Kruskal-Wallis test","heading":"15.10 Exercise","text":"Exercise 15.1  Kruskal-Wallis Dunn’s test lobster dataPerform Kruskal-Wallis test post-hoc test lobster data set.1. Hypotheses\\(H_0\\) : medians equal\\(H_1\\) : medians equal2. Import data, summarise visualiseAll done previously.3. AssumptionsFrom , since data normal enough definitely similar enough Kruskal-Wallis test equality variance assessment diagnostic plots. completeness though look Levene’s testGiven p-value high, agrees previous assessment equality variance assumption well met. Rock .4. Kruskal-Wallis testA Kruskal-Wallis test indicated median weight juvenile lobsters differ significantly diets (KW = 3.26, df = 2, p = 0.20).5. Dunn’s testAlthough rather unneccessary, since detect significant differences diets, can perform non-parametric equivalent Tukey’s range test: Dunn’s test., ’ve used optional argument called altp dunn.test() call. default option reports p-values divided 2. assessment significance requires compare p-value 0.025 rather 0.05. Using argument altp = TRUE means Dunn’s test reports actual p-values.Either way, can see none comparisons significant ().","code":"\nleveneTest(weight ~ diet, data = lobsters)## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  2  0.0028 0.9972\n##       15\nkruskal.test(weight ~ diet, data = lobsters)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  weight by diet\n## Kruskal-Wallis chi-squared = 3.2565, df = 2, p-value = 0.1963\ndunn.test(lobsters$weight, lobsters$diet, altp = TRUE)##   Kruskal-Wallis rank sum test\n## \n## data: x and group\n## Kruskal-Wallis chi-squared = 3.2565, df = 2, p-value = 0.2\n## \n## \n##                            Comparison of x by group                            \n##                                 (No adjustment)                                \n## Col Mean-|\n## Row Mean |     Flakes    Mussels\n## ---------+----------------------\n##  Mussels |  -1.787664\n##          |     0.0738\n##          |\n##  Pellets |  -0.670245   1.005415\n##          |     0.5027     0.3147\n## \n## alpha = 0.05\n## Reject Ho if p <= alpha"},{"path":"kruskal-wallis-test.html","id":"key-points-3","chapter":"15 Kruskal-Wallis test","heading":"15.11 Key points","text":"Point 1Point 2Point 3","code":""},{},{"path":"cs3-intro.html","id":"cs3-intro","chapter":"16 Introduction","heading":"16 Introduction","text":"","code":""},{"path":"cs3-intro.html","id":"objectives-6","chapter":"16 Introduction","heading":"16.1 Objectives","text":"Aim: introduce R commands analysing simple linear modelsBy end practical participants able perform following statistical analyses:Simple Linear RegressionCorrelationFor , participants able :Perform test RInterpret outputCheck assumptions test","code":""},{"path":"cs3-intro.html","id":"background-2","chapter":"16 Introduction","heading":"16.2 Background","text":"practical focuses implementation various statistical tests relating simple linear regression correlation., focus underlying theory tests (although demonstrators happy answer questions may ).test section :explains purpose test,explains visualise data,explains perform test R,explains interpret output report results, andexplains assess assumptions required perform test.","code":""},{},{"path":"introduction-2.html","id":"introduction-2","chapter":"17 Introduction","heading":"17 Introduction","text":"practical introducing can compare data different continuous variables.","code":""},{"path":"introduction-2.html","id":"cs3-datasets","chapter":"17 Introduction","heading":"17.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"correlation-coefficients.html","id":"correlation-coefficients","chapter":"18 Correlation coefficients","heading":"18 Correlation coefficients","text":"","code":""},{"path":"correlation-coefficients.html","id":"objectives-7","chapter":"18 Correlation coefficients","heading":"18.1 Objectives","text":"QuestionsWhat correlation coefficients?kind correlation coefficients use ?ObjectivesBe able calculate correlation coefficients RUse visual tools explore correlations variablesKnow limitations correlation coefficients","code":""},{"path":"correlation-coefficients.html","id":"purpose-and-aim-4","chapter":"18 Correlation coefficients","heading":"18.2 Purpose and aim","text":"Correlation refers relationship two variables (datasets) one another. Two datasets said correlated independent one another. Correlations can useful can indicate predictive relationship may exist. However just two datasets correlated mean causally related.","code":""},{"path":"correlation-coefficients.html","id":"section-commands-8","chapter":"18 Correlation coefficients","heading":"18.3 Section commands","text":"New commands used section:","code":""},{"path":"correlation-coefficients.html","id":"data-and-hypotheses-7","chapter":"18 Correlation coefficients","heading":"18.4 Data and hypotheses","text":"use USArrests dataset example. rather bleak dataset contains statistics arrests per 100,000 residents assault, murder robbery 50 US states 1973, alongside proportion population lived urban areas time. USArrests unstacked data frame 50 observations four variables: Murder, Assault, UrbanPop Robbery.data stored file data/raw/CS3-usarrests.csv.First read data:syntax reading data frame little different. want use first column .csv file specify names rows dataset rather include information inside dataset . using row.names = 1 argument tells R use 1st column file row names. need functions using require matrix input (basically data frame containing numbers).","code":"\nUSArrests <- read.csv(\"data/raw/CS3-usarrests.csv\", row.names = 1)\n\n# have a look at the data\nhead(USArrests)##            Murder Assault UrbanPop Robbery\n## Alabama      13.2     236       58    21.2\n## Alaska       10.0     263       48    44.5\n## Arizona       8.1     294       80    31.0\n## Arkansas      8.8     190       50    19.5\n## California    9.0     276       91    40.6\n## Colorado      7.9     204       78    38.7"},{"path":"correlation-coefficients.html","id":"pearsons-product-moment-correlation-coefficient","chapter":"18 Correlation coefficients","heading":"18.5 Pearson’s product moment correlation coefficient","text":"Pearson’s r (quantity also known) measure linear correlation two variables. value -1 +1, +1 means perfect positive correlation, -1 means perfect negative correlation 0 means correlation .","code":""},{"path":"correlation-coefficients.html","id":"summarise-and-visualise-7","chapter":"18 Correlation coefficients","heading":"18.6 Summarise and visualise","text":"Run command:first argument matrix data frameThe argument lower.panel tells R add redundant reflected lower set plots, diagonalFrom visual inspection scatter plots can see appears slight positive correlation pairs variables, although may weak case (Murder UrbanPop example).","code":"\npairs(USArrests, lower.panel = NULL)"},{"path":"correlation-coefficients.html","id":"implement-test-6","chapter":"18 Correlation coefficients","heading":"18.7 Implement test","text":"Let’s test possible correlations variables:first argument matrix data frameThe argument method tells R correlation coefficient use (pearson (default), kendall, spearman)","code":"\ncor(USArrests, method = \"pearson\")"},{"path":"correlation-coefficients.html","id":"interpret-output-and-report-results-6","chapter":"18 Correlation coefficients","heading":"18.8 Interpret output and report results","text":"give following output:matrix gives correlation coefficient pair variables data frame. matrix symmetric (?) diagonal values 1 (?). correlated variables Murder Assault r value 0.801. appears agree well set scatter plots produced earlier.","code":"##              Murder   Assault   UrbanPop   Robbery\n## Murder   1.00000000 0.8018733 0.06957262 0.5635788\n## Assault  0.80187331 1.0000000 0.25887170 0.6652412\n## UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\n## Robbery  0.56357883 0.6652412 0.41134124 1.0000000"},{"path":"correlation-coefficients.html","id":"exercise-9","chapter":"18 Correlation coefficients","heading":"18.9 Exercise","text":"Exercise 18.1  State data correlationWe use data file data/raw/CS3-statedata.csv dataset exercise. rather benign dataset contains information general properties US state, population (1975), per capita income (1974), illiteracy proportion (1970), life expectancy (1969), murder rate per 100,000 people (’s getting away ), percentage population high-school graduates, average number days minimum temperature freezing 1931 1960, state area square miles. dataset contains 50 rows 8 columns, column names: Population, Income, Illiteracy, Life.Exp, Murder, HS.Grad, Frost Area.Load data (remembering tell R first column CSV file used specify row names dataset) use pairs command visually identify 3 different pairs variables appear bethe positively correlatedthe negatively correlatednot correlated allCalculate Pearson’s r variable pairs see well able identify correlation visually.1. Read data2. Look pair-wise comparisons3. Create correlation matrixThe positively correlated variables Murder IlliteracyThe negatively correlated variables Murder LifeExpThe uncorrelated variables Area Population","code":"\nUSAstate <- read.csv(\"data/raw/CS3-statedata.csv\",\n                     row.names = 1)\n\n# have a look at the data\nhead(USAstate)##            Population Income Illiteracy LifeExp Murder HSGrad Frost   Area\n## Alabama          3615   3624        2.1   69.05   15.1   41.3    20  50708\n## Alaska            365   6315        1.5   69.31   11.3   66.7   152 566432\n## Arizona          2212   4530        1.8   70.55    7.8   58.1    15 113417\n## Arkansas         2110   3378        1.9   70.66   10.1   39.9    65  51945\n## California      21198   5114        1.1   71.71   10.3   62.6    20 156361\n## Colorado         2541   4884        0.7   72.06    6.8   63.9   166 103766\npairs(USAstate, lower.panel = NULL)\ncor(USAstate, method = \"pearson\")##             Population     Income  Illiteracy     LifeExp     Murder\n## Population  1.00000000  0.2082276  0.10762237 -0.06805195  0.3436428\n## Income      0.20822756  1.0000000 -0.43707519  0.34025534 -0.2300776\n## Illiteracy  0.10762237 -0.4370752  1.00000000 -0.58847793  0.7029752\n## LifeExp    -0.06805195  0.3402553 -0.58847793  1.00000000 -0.7808458\n## Murder      0.34364275 -0.2300776  0.70297520 -0.78084575  1.0000000\n## HSGrad     -0.09848975  0.6199323 -0.65718861  0.58221620 -0.4879710\n## Frost      -0.33215245  0.2262822 -0.67194697  0.26206801 -0.5388834\n## Area        0.02254384  0.3633154  0.07726113 -0.10733194  0.2283902\n##                 HSGrad      Frost        Area\n## Population -0.09848975 -0.3321525  0.02254384\n## Income      0.61993232  0.2262822  0.36331544\n## Illiteracy -0.65718861 -0.6719470  0.07726113\n## LifeExp     0.58221620  0.2620680 -0.10733194\n## Murder     -0.48797102 -0.5388834  0.22839021\n## HSGrad      1.00000000  0.3667797  0.33354187\n## Frost       0.36677970  1.0000000  0.05922910\n## Area        0.33354187  0.0592291  1.00000000"},{"path":"correlation-coefficients.html","id":"spearmans-rank-correlation-coefficient","chapter":"18 Correlation coefficients","heading":"18.10 Spearman’s rank correlation coefficient","text":"test first calculates rank numerical data (.e. position smallest (negative) largest (positive)) two variables calculates Pearson’s product moment correlation coefficient using ranks. consequence, test less sensitive outliers distribution.","code":""},{"path":"correlation-coefficients.html","id":"implement-test-7","chapter":"18 Correlation coefficients","heading":"18.11 Implement test","text":"using USArrests data set , run command:first argument matrix data frameThe argument method tells R correlation coefficient use","code":"\ncor(USArrests, method = \"spearman\")"},{"path":"correlation-coefficients.html","id":"interpret-output-and-report-results-7","chapter":"18 Correlation coefficients","heading":"18.12 Interpret output and report results","text":"gives following output:matrix gives correlation coefficient pair variables data frame. , matrix symmetric, diagonal values 1 expected. values obtained similar correlation coefficients obtained using Pearson test.","code":"##             Murder   Assault  UrbanPop   Robbery\n## Murder   1.0000000 0.8172735 0.1067163 0.6794265\n## Assault  0.8172735 1.0000000 0.2752133 0.7143681\n## UrbanPop 0.1067163 0.2752133 1.0000000 0.4381068\n## Robbery  0.6794265 0.7143681 0.4381068 1.0000000"},{"path":"correlation-coefficients.html","id":"exercise-10","chapter":"18 Correlation coefficients","heading":"18.13 Exercise","text":"Exercise 18.2  Spearman’s correlation USA state dataCalculate Spearman’s correlation coefficient data/raw/CS3-statedata.csv dataset.variable’s correlations affected use Spearman’s rank compared Pearson’s r?reference scatter plot produced earlier, can explain might ?Remember use row.names = 1 argument load data matrixInstead eye-balling differences, think can determine difference two correlation matricesThe heatmap() function can useful visualise matricesIn order determine variables affected choice Spearman vs Pearson just plot matrices side side try spot going , one reasons ’re using R can bit programmatic things.Let’s calculate difference two correlation matrices:, now just look grid 64 numbers see can spot biggest differences, eyes aren’t good processing parsing sort information display. better way somehow visualise data. can using R plotting functions, heatmap() exact. heatmap() function lot features don’t need ’m going go detail . main reason ’m using displays matrices right way round (plotting functions display matrices rotated 90 degrees) automatically labels rows columns.abs() function calculates absolute value (.e. just magnitude) matrix values. just care situations two correlation coefficients different don’t care larger. symm argument tells function symmetric matrix conjunction Rowv = NA argument stops plot reordering rows columns. Rowv = NA argument also stops function adding dendrograms margins plot.plot coloured yellow, indicating smallest values (case correspond difference correlation coefficients), orange dark red, indicating biggest values (case correspond variables biggest difference correlation coefficients).plot symmetric along leading diagonal (hopefully obvious reasons) can see majority squares light yellow colour, means isn’t much difference Spearman Pearson vast majority variables. squares appear darkest look along Area row/column suggesting ’s big difference correlation coefficients .can now revisit pairwise scatter plot see makes sense:can see clearly correspond plots noticeable outliers. example, Alaska twice big next biggest state, Texas. Big outliers data can large impact Pearson coefficient, whereas Spearman coefficient robust effects outliers. can see detail look Area vs Income graph coefficients. Pearson gives value 0.36, slight positive correlation, whereas Spearman gives value 0.057, basically uncorrelated. single outlier (Alaska) top-right scatter plot big effect Pearson practically ignored Spearman.Well done, Mr. Spearman.","code":"\ncor(USAstate, method = \"spearman\")##            Population      Income Illiteracy    LifeExp     Murder     HSGrad\n## Population  1.0000000  0.12460984  0.3130496 -0.1040171  0.3457401 -0.3833649\n## Income      0.1246098  1.00000000 -0.3145948  0.3241050 -0.2174623  0.5104809\n## Illiteracy  0.3130496 -0.31459482  1.0000000 -0.5553735  0.6723592 -0.6545396\n## LifeExp    -0.1040171  0.32410498 -0.5553735  1.0000000 -0.7802406  0.5239410\n## Murder      0.3457401 -0.21746230  0.6723592 -0.7802406  1.0000000 -0.4367330\n## HSGrad     -0.3833649  0.51048095 -0.6545396  0.5239410 -0.4367330  1.0000000\n## Frost      -0.4588526  0.19686382 -0.6831936  0.2983910 -0.5438432  0.3985351\n## Area       -0.1206723  0.05709484 -0.2503721  0.1275002  0.1064259  0.4389752\n##                 Frost        Area\n## Population -0.4588526 -0.12067227\n## Income      0.1968638  0.05709484\n## Illiteracy -0.6831936 -0.25037208\n## LifeExp     0.2983910  0.12750018\n## Murder     -0.5438432  0.10642590\n## HSGrad      0.3985351  0.43897520\n## Frost       1.0000000  0.11228778\n## Area        0.1122878  1.00000000\ncorPear <- cor(USAstate, method = \"pearson\")\ncorSpea <- cor(USAstate, method = \"spearman\")\ncorDiff <- corPear - corSpea\nheatmap(abs(corDiff), symm = TRUE, Rowv = NA)\npairs(USAstate)"},{"path":"correlation-coefficients.html","id":"key-points-4","chapter":"18 Correlation coefficients","heading":"18.14 Key points","text":"Correlation degree two variables linearly relatedCorrelation imply causationWe can visualise correlations using pairs() functionUsing cor() function can calculate correlation matricesTwo main correlation coefficients Pearson’s r Spearman’s rank, Spearman’s rank less sensitive outliers","code":""},{},{"path":"linear-regression.html","id":"linear-regression","chapter":"19 Linear regression","heading":"19 Linear regression","text":"","code":""},{"path":"linear-regression.html","id":"objectives-8","chapter":"19 Linear regression","heading":"19.1 Objectives","text":"QuestionsWhen use linear regression?interpret results?ObjectivesBe able perform linear regression RUse ANOVA check slope regression differs zeroUnderstand underlying assumptions linear regression analysisUse diagnostic plots check assumptions","code":""},{"path":"linear-regression.html","id":"purpose-and-aim-5","chapter":"19 Linear regression","heading":"19.2 Purpose and aim","text":"Regression analysis tests association two variables, also allows one investigate quantitatively nature relationship present, thus determine whether one variable may used predict values another.\nSimple linear regression essentially models dependence scalar dependent variable (y) independent (explanatory) variable (x) according relationship:\\[\\begin{equation*} \ny = \\beta_0 + \\beta_1 x\n\\end{equation*}\\]\\(\\beta_0\\) value intercept \\(\\beta_1\\) slope fitted line. aim simple linear regression analysis assess whether coefficient slope, \\(\\beta_1\\), actually different zero. different zero can say \\(x\\) significant effect \\(y\\) (since changing \\(x\\) leads predicted change \\(y\\)), whereas isn’t significantly different zero, say isn’t sufficient evidence relationship. course, order assess whether slope significantly different zero first need calculate values \\(\\beta_0\\) \\(\\beta_1\\).","code":""},{"path":"linear-regression.html","id":"section-commands-9","chapter":"19 Linear regression","heading":"19.3 Section commands","text":"new commands used section.","code":""},{"path":"linear-regression.html","id":"data-and-hypotheses-8","chapter":"19 Linear regression","heading":"19.4 Data and hypotheses","text":"perform simple linear regression analysis two variables Murder Assault USArrests dataset. wish determine whether Assault variable significant predictor Murder variable. means need find coefficients \\(\\beta_0\\) \\(\\beta_1\\) best fit following macabre equation:\\[\\begin{equation*}\nMurder  = \\beta_0 + \\beta_1 Assault\n\\end{equation*}\\]testing following null alternative hypotheses:\\(H_0\\): Assault significant predictor Murder, \\(\\beta_1 = 0\\)\\(H_1\\): Assault significant predictor Murder, \\(\\beta_1 \\neq 0\\)","code":""},{"path":"linear-regression.html","id":"summarise-and-visualise-8","chapter":"19 Linear regression","heading":"19.5 Summarise and visualise","text":"can visualise data :appears relatively strong positive relationship two variables whilst reasonable scatter points around trend line, probably expect significant result case.","code":"\nplot(Murder ~ Assault, data = USArrests)"},{"path":"linear-regression.html","id":"implement-test-8","chapter":"19 Linear regression","heading":"19.6 Implement test","text":"Fit straight line data:first argument lm formula saying Murder depends Assaults. seen , syntax generally dependent variable ~ independent variable.second argument specifies dataset useThe function lm returns linear model (lm) object essentially list containing everything necessary understand analyse linear model. However, just type (2nd line) just prints screen actual coefficients model .e. intercept slope line.found line best fit given :\\[\\begin{equation*}\nMurder = 0.63 + 0.042 Assault\n\\end{equation*}\\]Assess whether slope significantly different zero:, use anova() command assess significance. shouldn’t surprising stage introductory lectures made sense. mathematical perspective, one-way ANOVA simple linear regression exactly makes sense use command analyse R.","code":"\nlm_1 <- lm(Murder ~ Assault, data = USArrests)\n\n# show the linear model\nlm_1## \n## Call:\n## lm(formula = Murder ~ Assault, data = USArrests)\n## \n## Coefficients:\n## (Intercept)      Assault  \n##     0.63168      0.04191\nanova(lm_1)"},{"path":"linear-regression.html","id":"interpret-output-and-report-results-8","chapter":"19 Linear regression","heading":"19.7 Interpret output and report results","text":"exactly format table saw one-way ANOVA:1st line just tells ANOVA testThe 2nd line tells response variable (case Murder)3rd, 4th 5th lines ANOVA table contain useful values:\nDf column contains degrees freedom values row, 1 48 (’ll need reporting)\nF value column contains F statistic, 86.454 (’ll need reporting).\np-value 2.596e-12 number directly Pr(>F) 4th line.\nvalues table (Sum Sq Mean Sq) column used calculate F statistic don’t need know .\nDf column contains degrees freedom values row, 1 48 (’ll need reporting)F value column contains F statistic, 86.454 (’ll need reporting).p-value 2.596e-12 number directly Pr(>F) 4th line.values table (Sum Sq Mean Sq) column used calculate F statistic don’t need know ., p-value ’re interested shows us probability getting data null hypothesis actually true slope line actually zero.\nSince p-value excruciatingly tiny can reject null hypothesis state :simple linear regression showed assault rate US states significant predictor number murders (F = 86.45, df = 1,48, p = 2.59x10-12).Plotting regression lineIt can helpful plot regression line original data see far data predicted linear values. can :first command creates scatter plot dataThe second command uses results linear model fitting (object lm_1) add line best fit plot (colour red).","code":"## Analysis of Variance Table\n## \n## Response: Murder\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## Assault    1 597.70  597.70  86.454 2.596e-12 ***\n## Residuals 48 331.85    6.91                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# plot the data\nplot(Murder ~ Assault, data = USArrests)\n\n# add the regression line\nabline(lm_1, col = \"red\")"},{"path":"linear-regression.html","id":"assumptions-8","chapter":"19 Linear regression","heading":"19.8 Assumptions","text":"order linear regression analysis valid 4 key assumptions need met:data must linear (entirely possible calculate straight line data straight - doesn’t mean though!)residuals must normally distributedThe residuals must correlated fitted valuesThe fit depend overly much single point (point high leverage).Whether assumptions met can easily checked visually producing four key diagnostic plots.top left graph plots residuals fitted values. data best explained straight line uniform distribution points horizontal grey dotted line (sufficient points red line, moving average, top grey dotted line). plot pretty good.top right graph shows Q-Q plot allows visual inspection normality. residuals normally distributed, points lie diagonal dotted line. isn’t bad slight snaking towards upper end Georgia appears outlier .bottom left scale-location graph allows us investigate whether correlation residuals fitted values whether variance residuals changes significantly. , red line horizontal. correlation change variance red line horizontal. plot fine.last graph shows Cook’s distance tests one point unnecessarily large effect fit. important aspect see points lie beyond red dashed contour line top right corner plot. , point undue influence. plot good.Formally, concern looking diagnostic plots, linear regression valid. However, disappointingly, people ever check whether linear regression assumptions met quoting results.Let’s change leading example!","code":"\n# create a 2 x 2 output window\npar(mfrow = c(2,2))\n\n# and create the diagnostic plots for our model\nplot(lm_1)"},{"path":"linear-regression.html","id":"exercise-11","chapter":"19 Linear regression","heading":"19.9 Exercise","text":"Exercise 19.1  Linear regressionCalculate two simple linear regressions using data/raw/CS3-statedata.csv dataset, first variable LifeExp variable Murder variable HSGrad Frost.following cases:Find value slope intercept coefficients regressionsDetermine slope significantly different zero (.e. relationship two variables)Produce scatter plot data line best fit superimposed top.Produce diagnostic plots discuss (virtual) neighbour carried simple linear regression caseMurder Life ExpectancyLet’s see Murder variable can used predict Life.Exp variable. Let’s plot first ., ’ve fit linear model (second line) time plotting raw data (first line) just can add line best fit (third line). visualise reasons:check data aren’t obviously wrong. sensible values life expectancy (nothing massively large small), plausible values murder rates (’m au fait US murder rates 1976 small positive numbers seem plausible).check see expect statistical analysis. appear reasonable downward trend data. surprised didn’t get significant result given amount data spread data lineWe check assumptions (roughly though ’ll properly minute). Nothing immediately gives cause concern; data appear linear, spread data around line appears homogeneous symmetrical. outliers either.Now, let’s check assumptions diagnostic plots.residuals vs fitted plot appears symmetric enough (similar distribution points horizontal grey dotted line) happy linearity. Similarly red line scale-location plot looks horizontal enough happy homogeneity variance. aren’t influential points residuals vs leverage. plot give bit concern Normal Q-Q graph. see clear evidence snaking, although degree snaking isn’t actually bad. just means can pretty certain distribution residuals isn’t normal, also isn’t non-normal. situation? Well, three possible options:Appeal Central Limit Theorem. states large enough sample size don’t worry whether distribution residuals normally distributed. Large enough bit moving target honest depends non-normal underlying data . data little bit non-normal can get away using smaller sample data massively skewed (example). exact science, anything 30 data points considered lot mild moderate non-normality (case). data skewed looking data points (50-100). , example can legitimately just carry analysis without worrying.Try transforming data. try applying mathematical functions response variable (LifeExp) hope repeating analysis transformed variable make things better. honest might work won’t know try. Dealing transformed variables legitimate approach can make interpreting model bit challenging. particular example none traditional transformations (log, square-root, reciprocal) anything fix slight lack normality (can take word try ; plot(lm(log(LifeExp ~ Murder, data = USAstate))) example.Go permutation methods / bootstrapping. approach definitely work. don’t time explain (’s subject entire practical). approach also requires us reasonably large sample size work well assume distribution sample good approximation distribution entire dataset.case, large enough sample size deviation normality isn’t bad, can just crack standard analysis., let’s actually analysis:find Murder rate statistically significant predictor life expectancy US states. Woohoo!High School Graduation Frosty DaysNow let’s investigate relationship proportion High School Graduates state (HSGrad) mean number days freezing (Frost) within state., look data.doesn’t appear ridiculous errors data; High School graduation proportions 0-100% range mean number sub-zero days state 0 365, numbers plausible.Whilst trend upwards, wouldn’t surprise came back significant, ’m bit concerned …assumptions. ’m mainly concerned data aren’t linear. appears noticeable pattern data sort minimum around 50-60 Frost days. means ’s hard assess assumptions.Let’s check properlyNow, let’s check assumptions diagnostic plots.can see suspected backed residual vs fitted graph. data aren’t linear appears sort odd -pattern . Given lack linearity just isn’t worth worrying plots model misspecified: straight line just doesn’t represent data .Just reference, practice looking diagnostic plots, ignore lack linearity can say thatNormality pretty good Normal Q-Q plotHomogeneity variance isn’t good appears noticeable drop variance go left right (consideration Scale-Location plot)don’t appear influential points (looking residuals vs leverage graph)However, none relevant particular case since data aren’t linear straight line wrong model fit.situation?Well actually, bit tricky aren’t easy fixes . two broad solutions dealing misspecified model.common solution need predictor variables model. ’re trying explain/predict high school graduation using number frost days. Obviously many things affect proportion high school graduates just cold State (weird potential predictor think ) need statistical approach allows us look multiple predictor variables. ’ll cover approach next two sessions.potential solution say high school graduation can fact predicted number frost days relationship isn’t linear. need specify relationship (curve basically) try fit data new, non-linear, curve. process called, unsurprisingly, non-linear regression don’t cover course. process best used already strong theoretical reason non-linear relationship two variables (sigmoidal dose-response curves pharmacology exponential relationships cell growth). case don’t preconceived notions wouldn’t really appropriate case.Neither solutions can tackled knowledge far course can definitely say based upon data set, isn’t linear relationship (significant otherwise) frosty days high school graduation rates.","code":"\n# plot the data\nplot(LifeExp ~ Murder, data = USAstate)\n\n# create a linear model\nlm1 <- lm(LifeExp ~ Murder, data = USAstate)\n\n# and add a regression line\nabline(lm1, col = \"red\")\npar(mfrow = c(2,2))\nplot(lm1)\nanova(lm1)## Analysis of Variance Table\n## \n## Response: LifeExp\n##           Df Sum Sq Mean Sq F value   Pr(>F)    \n## Murder     1 53.838  53.838  74.989 2.26e-11 ***\n## Residuals 48 34.461   0.718                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# plot the data\nplot(HSGrad ~ Frost, data = USAstate)\n\n# create a linear model\nlm2<-lm(HSGrad ~ Frost, data=USAstate)\n\n# and add a regression line\nabline(lm2, col = \"red\")\npar(mfrow = c(2,2))\nplot(lm2)"},{"path":"linear-regression.html","id":"key-points-5","chapter":"19 Linear regression","heading":"19.10 Key points","text":"Linear regression tests linear relationship exists two variablesIf , can use one variable predict anotherA linear model intercept slope test slope differs zeroWe create linear models R lm() function use anova() assess slope coefficientWe can use linear regression four assumptions met:\ndata linear\nResiduals normally distributed\nResiduals correlated fitted values\nsingle point large influence linear model\ndata linearResiduals normally distributedResiduals correlated fitted valuesNo single point large influence linear modelWe use plot(model_name) get four diagnostic plots R, help evaluate assumptions","code":""},{},{"path":"cs4-intro.html","id":"cs4-intro","chapter":"20 Introduction","heading":"20 Introduction","text":"","code":""},{"path":"cs4-intro.html","id":"objectives-9","chapter":"20 Introduction","heading":"20.1 Objectives","text":"Aim: introduce R commands carrying two-way ANOVA linear regression grouped data/ANCOVABy end practical participants able achieve following:Carry two-way ANOVA using R interpret outputAnalyse linear regression grouped data (ANCOVA)","code":""},{"path":"cs4-intro.html","id":"background-3","chapter":"20 Introduction","heading":"20.2 Background","text":"practical focuses implementation various statistical tests relating multiple predictor variables R. focus underlying theory tests (although demonstrators happy answer questions may ).test section explaining perform test, section explaining results output screen, exercise complete relating test .","code":""},{},{"path":"introduction-3.html","id":"introduction-3","chapter":"21 Introduction","heading":"21 Introduction","text":"","code":""},{"path":"introduction-3.html","id":"cs4-datasets","chapter":"21 Introduction","heading":"21.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"two-way-anova.html","id":"two-way-anova","chapter":"22 Two-way ANOVA","heading":"22 Two-way ANOVA","text":"","code":""},{"path":"two-way-anova.html","id":"objectives-10","chapter":"22 Two-way ANOVA","heading":"22.1 Objectives","text":"QuestionsHow ……ObjectivesBe able …Use…","code":""},{"path":"two-way-anova.html","id":"purpose-and-aim-6","chapter":"22 Two-way ANOVA","heading":"22.2 Purpose and aim","text":"two-way analysis variance used two categorical predictor variables (factors) single continuous response variable. example, looking body Weight (continuous response variable kilograms) affected gender (categorical variable, Male Female) exercise type (categorical variable, Control Runner).analysing type data two things want know:either predictor variables effect response variable .e. gender affect body weight? runner affect body weight?interaction two predictor variables? interaction mean effect exercise weight depends whether male female rather independent gender. example male means runners weigh non-runners, female means runners weight less non-runners say interaction.first consider visualise data carrying appropriate statistical test.","code":""},{"path":"two-way-anova.html","id":"section-commands-10","chapter":"22 Two-way ANOVA","heading":"22.3 Section commands","text":"New commands used section:","code":""},{"path":"two-way-anova.html","id":"data-and-hypotheses-9","chapter":"22 Two-way ANOVA","heading":"22.4 Data and hypotheses","text":"recreate example analysis used lecture. data stored .csv file called CS4-exercise.csv.","code":""},{"path":"two-way-anova.html","id":"summarise-and-visualise-9","chapter":"22 Two-way ANOVA","heading":"22.5 Summarise and visualise","text":"Experiment dataframe three variables; Weight, Gender Exercise. Weight continuous response variable, whereas Gender Exercise categorical predictor variables.First,read data:visualise:produce basic box plots showing response variable (Weight) terms one predictor variables. values predictor variable case aren’t taken account. argument Weight ~ Gender (Weight ~ Exercise) key . tells R treat Weight function Gender (function Exercise .)\nalso basic plots just showing raw data using default arguments.(Optional) Add titles, axis labels information see fit plots make presentable.Visualise predictor variables together:produces box plots (four) combinations predictor variables. key argument Weight ~ Gender + Exercise. tells R treat Weight function Gender Exercise. + symbol mean add numbers together, Weight treated function Gender plus Exercise.\n, basic plot just shows raw data uses default arguments.(Optional) Add titles, axis labels information see fit plot make presentable.example four box plots relatively easy compare look interactions variables, two levels (groups) per categorical variable, become harder spot going . compare categorical variables easily just plot group means aids ability look interactions main effects predictor variable.Create interaction plot:first argument defines categorical variable used horizontal axis. must factor vector (comes data.frame automatically factor). function called x.factor.second argument defines categorical variable used different lines plotted. must factor vector. function called trace.factor.third argument defines response variable used vertical axis. must numerical vector. function argument called response.’s common get order arguments muddled . Remember ’s third argument defines variable goes vertical axis!default settings aren’t great displaying interaction plots. Try following (opinion) user-friendly display.choice categorical factor plotted horizontal axis plotted different lines completely arbitrary. Looking data ways shouldn’t add anything often ’ll find prefer one plot another.Plot interaction plot way round:now good feeling data already provide guesses following three questions:appear interaction two categorical variables?:\nExercise effect Weight?\nGender effect Weight?\nExercise effect Weight?Gender effect Weight?can now attempt answer three questions formally using ANOVA test. ask R explicitly test three things: interaction, effect Exercise effect Gender. use following code:Gender:Exercise term R represents concept interaction two variables.produces following output:row table different effects ’ve asked R consider. last column important one contains p-values (although also need F-values degrees freedom reporting purposes). need look interaction row first.Gender:Exercise p-value 0.028 (smaller 0.05) can conclude interaction Gender Exercise significant.must stop.top two lines (corresponding effects Gender Exercise) meaningless now p-values reported utterly redundant (particular way care p-values small).model significant interaction logically impossible meaningfully interpret main effects.report follows:two-way ANOVA test showed significant interaction effects Gender Exercise Weight (F = 5.8521, df = 1,16, p = 0.028). Exercise associated small loss weight males larger loss weight females.","code":"\nExperiment <- read.csv(\"data/raw/CS4-exercise.csv\")\nboxplot(Weight ~ Gender, data = Experiment)\nboxplot(Weight ~ Exercise, data = Experiment)\nboxplot(Weight ~ Gender + Exercise, data = Experiment)\ninteraction.plot(Experiment$Gender, Experiment$Exercise, Experiment$Weight)\ninteraction.plot(Experiment$Gender, Experiment$Exercise, Experiment$Weight,\n                 xlab = \"Gender\", ylab = \"Weight\", trace.label = \"Exercise\",\n                 type = \"b\", pch = 4, col = c(\"blue\", \"red\"))\ninteraction.plot(Experiment$Exercise, Experiment$Gender, Experiment$Weight,\n                 xlab = \"Gender\", ylab = \"Weight\", trace.label = \"Exercise\",\n                 type = \"b\", pch = 4, col = c(\"blue\", \"red\"))\n# define the linear model\nlm.exercise <- lm(Weight ~ Gender + Exercise + Gender:Exercise, data = Experiment)\n\n# perform the ANOVA\nanova(lm.exercise)## Analysis of Variance Table\n## \n## Response: Weight\n##                 Df Sum Sq Mean Sq F value    Pr(>F)    \n## Gender           1 607.20  607.20 43.1144 6.493e-06 ***\n## Exercise         1 184.83  184.83 13.1240  0.002287 ** \n## Gender:Exercise  1  82.42   82.42  5.8521  0.027839 *  \n## Residuals       16 225.34   14.08                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"two-way-anova.html","id":"assumptions-9","chapter":"22 Two-way ANOVA","heading":"22.6 Assumptions","text":"two-way ANOVA type linear model need satisfy pretty much assumptions simple linear regression one-way ANOVA:data must systematic pattern itThe residuals must normally distributedThe residuals must homogeneity varianceThe fit depend overly much single point (point high leverage)., check assumptions visually producing four key diagnostic plots.first command changes plotting parameters splits graphics window 2 rows 2 columns (won’t notice anything whilst run ).first command changes plotting parameters splits graphics window 2 rows 2 columns (won’t notice anything whilst run ).second command produces 3 plots graphics window one warning stating Residuals vs Factor Levels plot left . groups exactly number data points.second command produces 3 plots graphics window one warning stating Residuals vs Factor Levels plot left . groups exactly number data points.top left graph plots residuals fitted values. systematic pattern plot pretty good.top left graph plots residuals fitted values. systematic pattern plot pretty good.top right graph allows visual inspection normality. , looks ok (perfect ok).top right graph allows visual inspection normality. , looks ok (perfect ok).bottom left graph allows us investigate whether homogeneity variance. plot fine (perfect fine).bottom left graph allows us investigate whether homogeneity variance. plot fine (perfect fine).shorthand way writing:\nWeight ~ Gender + Exercise + Gender:ExerciseIf use following syntax:Weight ~ Gender*ExerciseThen R interprets exactly way writing three terms.\ncan see compare output following two commands:","code":"\npar(mfrow = c(2, 2))\n\nplot(lm.exercise)## hat values (leverages) are all = 0.2\n##  and there are no factor predictors; no plot no. 5\nanova(lm(Weight ~ Gender + Exercise + Gender:Exercise, data = Experiment))## Analysis of Variance Table\n## \n## Response: Weight\n##                 Df Sum Sq Mean Sq F value    Pr(>F)    \n## Gender           1 607.20  607.20 43.1144 6.493e-06 ***\n## Exercise         1 184.83  184.83 13.1240  0.002287 ** \n## Gender:Exercise  1  82.42   82.42  5.8521  0.027839 *  \n## Residuals       16 225.34   14.08                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(lm(Weight ~ Gender * Exercise, data= Experiment))## Analysis of Variance Table\n## \n## Response: Weight\n##                 Df Sum Sq Mean Sq F value    Pr(>F)    \n## Gender           1 607.20  607.20 43.1144 6.493e-06 ***\n## Exercise         1 184.83  184.83 13.1240  0.002287 ** \n## Gender:Exercise  1  82.42   82.42  5.8521  0.027839 *  \n## Residuals       16 225.34   14.08                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"two-way-anova.html","id":"exercise-cells","chapter":"22 Two-way ANOVA","heading":"22.7 Exercise: Cells","text":"Exercise 22.1  Cell growthThese data/examples/cs4-cells.csv data fictional experiment involves looking effect different concentrations substance growth rate two different cell types (annoyingly vague know – suggestions context welcome !). two cell types three concentrations.cell type control experiment substance added (.e. concentration none); low concentration substance high concentration substance. cells called B.\ncombination cell type substance concentration add substance individual cell petri dish 8 hours, count number cells dish (may well biologically weird/impossible – suggestions welcome). experiment repeated three times.cell type control experiment substance added (.e. concentration none); low concentration substance high concentration substance. cells called B.\ncombination cell type substance concentration add substance individual cell petri dish 8 hours, count number cells dish (may well biologically weird/impossible – suggestions welcome). experiment repeated three times.Let’s first visualise data:Let’s look interaction plots:’re constructed box plots ’ve also constructed two interaction plots. needed one interaction plot find can quite useful look data looks different angles. interaction plots suggest interaction lines plots aren’t parallel. Looking interaction plot concentration x-axis, appears non difference cell types concentration none, difference cell types concentration low high.Let’s carry two-way ANOVA:shows definitely significant interaction concentration cell_type.Let’s check assumptions:, actually look pretty good, although first glance might bit worried apparent heterogeneity variance. last group Residuals vs fitted graph appear spread 5 groups. echoed Scale-Location graph, red line kicks end. Whilst technically signify heterogeneity variance aren’t worried three data points per group. low number data points per group get one data point little bit extreme others (purely chance) large impact perception homogeneity variance. data points group certain observed heterogeneity variance true feature underlying parent population (therefore problem) rather just caused single random point (therefore problem).","code":"\n# read in the data\ncells <- read_csv(\"data/examples/cs4-cells.csv\")\n# read in the data\ncells <- read_csv(\"data/examples/cs4-cells.csv\")\n\n# let's have a peek at the data\ncells## # A tibble: 18 × 4\n##       id cell_type concentration cell_number\n##    <dbl> <chr>     <chr>               <dbl>\n##  1     1 A         none                    7\n##  2     2 A         none                    9\n##  3     3 A         none                    4\n##  4     4 B         none                    5\n##  5     5 B         none                    8\n##  6     6 B         none                    9\n##  7     7 A         low                    22\n##  8     8 A         low                    28\n##  9     9 A         low                    26\n## 10    10 B         low                    12\n## 11    11 B         low                    17\n## 12    12 B         low                    14\n## 13    13 A         high                   89\n## 14    14 A         high                   78\n## 15    15 A         high                   83\n## 16    16 B         high                   48\n## 17    17 B         high                   44\n## 18    18 B         high                   45\nboxplot(cell_number ~ concentration,\n        data = cells)\nboxplot(cell_number ~ cell_type,\n        data = cells)\n# by cell type\ninteraction.plot(cells$concentration, cells$cell_type, cells$cell_number)\n# by concentration\ninteraction.plot(cells$cell_type, cells$concentration, cells$cell_number)\n# define the linear model, with interaction term\nlm1 <- lm(cell_number ~ concentration * cell_type,\n          data = cells)\n\n# perform the ANOVA\nanova(lm1)## Analysis of Variance Table\n## \n## Response: cell_number\n##                         Df  Sum Sq Mean Sq F value    Pr(>F)    \n## concentration            2 10932.1  5466.1 537.645 1.807e-12 ***\n## cell_type                1  1152.0  1152.0 113.311 1.816e-07 ***\n## concentration:cell_type  2  1158.3   579.2  56.967 7.485e-07 ***\n## Residuals               12   122.0    10.2                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\npar(mfrow=c(2,2))\n\nplot(lm1)## hat values (leverages) are all = 0.3333333\n##  and there are no factor predictors; no plot no. 5"},{"path":"two-way-anova.html","id":"exercise-tulips","chapter":"22 Two-way ANOVA","heading":"22.8 Exercise: Tulips","text":"Exercise 22.2  Blooms growing conditionsThe data/raw/CS4-tulip.csv dataset contains information experiment determine best conditions growing tulips (well someone care sorts things!). average number flower heads (blooms) recorded 27 different plots. plot experienced one three different watering regimes one three different shade regimes.Investigate number blooms affected different growing conditions.dataset three variables; Blooms (response variable) Water Shade (two potential predictor variables). always ’ll visualise data first:, interaction plots suggest might interaction . Digging little deeper descriptive perspective, looks though Water regime 1 behaving differently Water regimes 2 3 different shade conditions.Let’s carry two-way ANOVA check assumptions. ’s worth pointing order carry doesn’t really matter ’ll making decision everything place. Technically, check assumptions first statistical test, long check ’m fairly relaxed order steps.appear significant interaction Water Shade expected.Let’s check assumptions:actually OK. Point number 8 messing homogeneity variance assumption little bit, since ’s one point won’t worry . 2-way ANOVA analysis stands.","code":"\n# read in the data\ntulip <- read.csv(\"data/raw/CS4-tulip.csv\")\nboxplot(Blooms ~ Water, data = tulip)\nboxplot(Blooms ~ Shade,data = tulip)\ninteraction.plot(tulip$Water, tulip$Shade, tulip$Blooms)\ninteraction.plot(tulip$Shade, tulip$Water, tulip$Blooms)\n# define the linear model\nlm.tulip <- lm(Blooms ~ Water * Shade,\n               data = tulip)\n\n# perform the ANOVA\nanova(lm.tulip)## Analysis of Variance Table\n## \n## Response: Blooms\n##             Df Sum Sq Mean Sq F value    Pr(>F)    \n## Water        1 103426  103426  43.057 1.075e-06 ***\n## Shade        1  31154   31154  12.970  0.001505 ** \n## Water:Shade  1  33520   33520  13.954  0.001082 ** \n## Residuals   23  55248    2402                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\npar(mfrow = c(2, 2))\nplot(lm.tulip)"},{"path":"two-way-anova.html","id":"key-points-6","chapter":"22 Two-way ANOVA","heading":"22.9 Key points","text":"Point 1Point 2Point 3","code":""}]
