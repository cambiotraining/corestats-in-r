[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform core data analysis techniques appropriately confidently using R.6 lecture-practicals6 lecture-practicalsOngoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey “mindlessly use stats program” course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented arbitrary dataset e.g.Know data analysis techniques availableKnow ones allowableBe able carry understand results","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Simple hypothesis testingCategorical predictor variablesContinuous predictorsTwo predictor variablesMultiple predictor variablesPower analysis","code":""},{"path":"index.html","id":"practicals","chapter":"1 Overview","heading":"1.3 Practicals","text":"practical document divided various sections. section explanatory text help understand going ’re trying achieve.\nmay list commands relevant section displayed boxes like :Conditional operatorsTo set filtering conditions, use following relational operators:> greater >= greater equal < less <= less equal == equal != different %% contained combine conditions, use following logical operators:& | ","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.4 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save …. Next unzip file copy working directory. data accessible via <working-directory-name>/data/tidy.","code":""},{},{"path":"cs5-intro.html","id":"cs5-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"cs5-intro.html","id":"objectives","chapter":"2 Introduction","heading":"2.1 Objectives","text":"Aim: introduce R commands constructing linear models multiple continuous categorical variables performing backwards stepwise eliminationBy end practical participants able achieve following:Construct linear model three continuous categorical variables\nUnderstand include exclude interaction terms\nUnderstand interpret output\nUnderstand include exclude interaction termsUnderstand interpret outputPerform backwards stepwise elimination produce minimal model","code":""},{"path":"cs5-intro.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"practical divided two main sections. first section explores concept linear model framework revisits work previous practicals. linear model concept expanded systems three predictor variables.second section focuses model selection technique called backwards stepwise elimination. technique allows comparisons made nested models uninformative predictor variables can dropped minimal model remains.Within section worked example exercise.","code":""},{},{"path":"introduction.html","id":"introduction","chapter":"3 Introduction","heading":"3 Introduction","text":"","code":""},{"path":"introduction.html","id":"cs5-datasets","chapter":"3 Introduction","heading":"3.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"linear-models.html","id":"linear-models","chapter":"4 Linear models","heading":"4 Linear models","text":"","code":""},{"path":"linear-models.html","id":"objectives-1","chapter":"4 Linear models","heading":"4.1 Objectives","text":"QuestionsHow use linear model framework three predictor variables?ObjectivesBe able expand linear model framework R three predictor variablesDefine equation regression line categorical variableBe able construct analyse possible combination predictor variables data","code":""},{"path":"linear-models.html","id":"purpose-and-aim","chapter":"4 Linear models","heading":"4.2 Purpose and aim","text":"Revisiting linear model framework expanding systems three predictor variables.","code":""},{"path":"linear-models.html","id":"section-commands","chapter":"4 Linear models","heading":"4.3 Section commands","text":"Commands used section","code":""},{"path":"linear-models.html","id":"data-and-hypotheses","chapter":"4 Linear models","heading":"4.4 Data and hypotheses","text":"first section uses following dataset:\ndata/tidy/CS5-H2S.csv. dataset comprising 16 observations three variables (one dependent two predictor). records air pollution caused H2S produced two types waste treatment plants. types treatment plant, obtain eight measurements H2S production (ppm). also obtain information daily temperature.","code":""},{"path":"linear-models.html","id":"summarise-and-visualise","chapter":"4 Linear models","heading":"4.5 Summarise and visualise","text":"Let’s first load data:four columns:id unique ID columntreatment_plant contains name waste treatment plantdaily_temp contains average daily temperature degrees Celsiushydrogen_sulfide contains H2S production (ppm)Next, visualise data:looks though variable treatment_plant effect H2S emissions (one cloud points higher ). also suggestion daily temperature might affect emissions (data sets look like gradient regression line respective cloud might zero) also appears might interaction treatment_plant daily_temperature gradient two regression lines parallel.","code":"\n#load the data\nairpoll <- read_csv(\"data/tidy/CS5-H2S.csv\")\n\n# look at the data\nairpoll## # A tibble: 16 × 4\n##       id treatment_plant daily_temp hydrogen_sulfide\n##    <dbl> <chr>                <dbl>            <dbl>\n##  1     1 A                       21             5.22\n##  2     2 A                       22             4.39\n##  3     3 A                       22             5.24\n##  4     4 A                       24             5.04\n##  5     5 A                       27             4.6 \n##  6     6 A                       28             5.04\n##  7     7 A                       29             5.08\n##  8     8 A                       30             3.97\n##  9     9 B                       21             6.06\n## 10    10 B                       21             6.51\n## 11    11 B                       22             6.33\n## 12    12 B                       23             6.01\n## 13    13 B                       28             6.09\n## 14    14 B                       28             6.93\n## 15    15 B                       28             7.6 \n## 16    16 B                       29             7.65\n# plot the data\nairpoll %>% \n  ggplot(aes(x = daily_temp,\n             y = hydrogen_sulfide,\n             colour = treatment_plant,\n             group = treatment_plant)) +\n  geom_point() +\n  # add regression lines\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"linear-models.html","id":"implemention","chapter":"4 Linear models","heading":"4.6 Implemention","text":"Construct analyse full linear model.construct model main effects interaction term. Remember hydrogen_sulfide ~ treatment_plant * daily_temp short hand version hydrogen_sulfide ~ treatment_plant + daily_temp + treatment_plant:daily_temp.gives us coefficients model:best interpreted using linear model notation:\\[\\begin{equation}\nH_2S = 6.20495 - 0.05448 \\cdot daily\\_temp + \\\\ \\binom{0}{-2.73075}\\binom{treatment\\_plantA}{treatment\\_plantB} + \\\\\n\\binom{0}{0.18141 \\cdot daily\\_temp}\\binom{treatment\\_plantA}{treatment\\_plantB}\n\\end{equation}\\]effectively shorthand writing equation two straight lines (one categorical variable):\\[\\begin{equation}\ntreatment\\_plantA = 6.20495 - 0.05448 \\cdot daily\\_temp\n\\end{equation}\\]\\[\\begin{equation}\ntreatment\\_plantB = 3.4742 + 0.12693 \\cdot daily\\_temp\n\\end{equation}\\]Performing ANOVA full linear model gives following output:can see interaction term appears marginally significant, implying effect temperature hydrogen sulfide production different two different treatment plants.check assumptions lm_full using diagnostic plots:","code":"\n# define the linear model with all terms and interactions\nlm_full <- lm(hydrogen_sulfide ~ treatment_plant * daily_temp,\n              data = airpoll)\n\n# view the model\nlm_full## \n## Call:\n## lm(formula = hydrogen_sulfide ~ treatment_plant * daily_temp, \n##     data = airpoll)\n## \n## Coefficients:\n##                 (Intercept)             treatment_plantB  \n##                     6.20495                     -2.73075  \n##                  daily_temp  treatment_plantB:daily_temp  \n##                    -0.05448                      0.18141## # A tibble: 4 × 2\n##   term                        estimate\n##   <chr>                          <dbl>\n## 1 (Intercept)                   6.20  \n## 2 treatment_plantB             -2.73  \n## 3 daily_temp                   -0.0545\n## 4 treatment_plantB:daily_temp   0.181\nanova(lm_full)## Analysis of Variance Table\n## \n## Response: hydrogen_sulfide\n##                            Df  Sum Sq Mean Sq F value    Pr(>F)    \n## treatment_plant             1 13.3225 13.3225 54.1557 8.746e-06 ***\n## daily_temp                  1  0.2316  0.2316  0.9415   0.35104    \n## treatment_plant:daily_temp  1  1.4470  1.4470  5.8822   0.03201 *  \n## Residuals                  12  2.9520  0.2460                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nlm_full %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)"},{"path":"linear-models.html","id":"exploring-models","chapter":"4 Linear models","heading":"4.7 Exploring models","text":"Rather stop however, use concept linear model full potential show can construct analyse possible combination predictor variables dataset. Namely consider following four extra models:","code":""},{"path":"linear-models.html","id":"additive-model","chapter":"4 Linear models","heading":"4.7.1 Additive model","text":"Construct analyse additive linear model.first line creates linear model seeks explain hydrogen_sulfide values purely terms categorical treatment_plant variable continuous daily_temp variable.second line produces following output:gives us coefficients additive model:best interpreted using linear model notation:\\[\\begin{equation}\nH_2S = 3.9 + 0.036 \\cdot daily\\_temp + \\\\\n\\binom{0}{1.8} \\binom{treatment\\_plantA}{treatment\\_plantB}\n\\end{equation}\\]effectively shorthand writing equation two straight lines (one categorical variable):\\[\\begin{equation}\nH_2S(treatment\\_plantA) = 3.9 + 0.036 \\cdot daily\\_temp\n\\end{equation}\\]\\[\\begin{equation}\nH_2S(treatment\\_plantB) = 5.7 + 0.036 \\cdot daily\\_temp\n\\end{equation}\\]important note much coefficients changed (natural assume change model given ’ve altered predictor variables included). striking signs coefficients changed! example, full model saw coefficient treatment_plantB negative (implying general treatment_plantB produced lower H2S values treatment_plantA default) whereas now positive indicating exactly opposite effect. Given difference two models inclusion interaction term saw significant analysis full model, perhaps, surprising dropping term lead different results.just imagine never included first place! looked additive model come completely different conclusions baseline pollution levels plant.3rd line produces following output:can see temperature term significant, whereas treatment_plant term significant indeed.Exercise 4.1  Check assumptions additive model. differ significantly full model?","code":"\n# define the linear model\nlm_add <- lm(hydrogen_sulfide ~ treatment_plant + daily_temp,\n             data = airpoll)\n\n# view the linear model\nlm_add\n\n# perform an ANOVA on the model\nanova(lm_add)## \n## Call:\n## lm(formula = hydrogen_sulfide ~ treatment_plant + daily_temp, \n##     data = airpoll)\n## \n## Coefficients:\n##      (Intercept)  treatment_plantB        daily_temp  \n##          3.90164           1.83861           0.03629## # A tibble: 3 × 2\n##   term             estimate\n##   <chr>               <dbl>\n## 1 (Intercept)        3.90  \n## 2 treatment_plantB   1.84  \n## 3 daily_temp         0.0363## Analysis of Variance Table\n## \n## Response: hydrogen_sulfide\n##                 Df  Sum Sq Mean Sq F value    Pr(>F)    \n## treatment_plant  1 13.3225 13.3225 39.3702 2.858e-05 ***\n## daily_temp       1  0.2316  0.2316  0.6845     0.423    \n## Residuals       13  4.3991  0.3384                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"linear-models.html","id":"revisiting-anova","chapter":"4 Linear models","heading":"4.7.2 Revisiting ANOVA","text":"Construct analyse effect treatment_plant:third line gives us model coefficients:case tells us means groups. (Intercept) mean treatment_plantA H2S data (4.8225) whilst treatment_plantB tells us mean treatment plant B H2S data 1.8250 intercept value .e. mean treatment_plantB 4.8225 + 1.8250 = 6.6475.last line gives us normal ANOVA table testing whether means two groups differ significantly .Exercise 4.2  Check assumptions plant model. differ significantly previous models?","code":"\n# visualise the data\nairpoll %>% \n  ggplot(aes(x = treatment_plant, y = hydrogen_sulfide)) +\n  geom_boxplot() +\n  # add the data points and ensure they are jittered\n  # so they do not overlap\n  geom_jitter(width = 0.1)\n# define the linear model\nlm_plant <- lm(hydrogen_sulfide ~ treatment_plant,\n               data = airpoll)\n\n# view the linear model\nlm_plant\n\n# perform an ANOVA on the model\nanova(lm_plant)## \n## Call:\n## lm(formula = hydrogen_sulfide ~ treatment_plant, data = airpoll)\n## \n## Coefficients:\n##      (Intercept)  treatment_plantB  \n##            4.823             1.825## Analysis of Variance Table\n## \n## Response: hydrogen_sulfide\n##                 Df  Sum Sq Mean Sq F value    Pr(>F)    \n## treatment_plant  1 13.3225 13.3225  40.278 1.809e-05 ***\n## Residuals       14  4.6307  0.3308                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"linear-models.html","id":"revisiting-regression","chapter":"4 Linear models","heading":"4.7.3 Revisiting regression","text":"Construct simple linear regression model, H2S depends average daily temperature:model gives us coefficients equation regression lineIn case tells us intercept (Intercept) gradient (daily_temp) regression line.last line gives us ANOVA analysis:Temperature clearly significant effect.Exercise 4.3  , check assumptions temperature model. differ significantly previous models?","code":"\n# plot the data\nairpoll %>% \n  ggplot(aes(x = daily_temp, y = hydrogen_sulfide)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n# define the linear model\nlm_temp <- lm(hydrogen_sulfide ~ daily_temp,\n              data = airpoll)\n\n# view the model\nlm_temp\n\n# perform an ANOVA on the model\nanova(lm_temp)## \n## Call:\n## lm(formula = hydrogen_sulfide ~ daily_temp, data = airpoll)\n## \n## Coefficients:\n## (Intercept)   daily_temp  \n##     5.21465      0.02066## Analysis of Variance Table\n## \n## Response: hydrogen_sulfide\n##            Df  Sum Sq Mean Sq F value Pr(>F)\n## daily_temp  1  0.0753  0.0753   0.059 0.8117\n## Residuals  14 17.8779  1.2770"},{"path":"linear-models.html","id":"the-null-model","chapter":"4 Linear models","heading":"4.7.4 The null model","text":"Construct analyse null model:lm_null fit null model data (effectively just finding mean H2S values dataset)null model gives us mean H2S values (.e. coefficient null model)null model rarely analysed sake instead used reference point sophisticated model selection techniques.","code":"\n# visualise the data\nairpoll %>% \n  ggplot(aes(y = hydrogen_sulfide)) +\n  geom_boxplot()\n# define the null model\nlm_null <- lm(hydrogen_sulfide ~ 1,\n              data = airpoll)\n\n# view the model\nlm_null## \n## Call:\n## lm(formula = hydrogen_sulfide ~ 1, data = airpoll)\n## \n## Coefficients:\n## (Intercept)  \n##       5.735"},{"path":"linear-models.html","id":"exercise-trees","chapter":"4 Linear models","heading":"4.8 Exercise: trees","text":"Exercise 4.4  Trees: example continuous variablesUse internal dataset trees. data frame 31 observations 3 continuous variables. variables height Height, diameter Girth timber volume Volume 31 felled black cherry trees.Investigate relationship Volume (dependent variable) Height Girth (predictor variables).variables continuous isn’t way producing 2D plot three variables visualisation purposes using R’s standard plotting functions.construct four linear models\nAssume volume depends Height, Girth interaction Girth Height\nAssume Volume depends Height Girth isn’t interaction .\nAssume Volume depends Girth (plot result, regression line).\nAssume Volume depends Height (plot result, regression line).\nAssume volume depends Height, Girth interaction Girth HeightAssume Volume depends Height Girth isn’t interaction .Assume Volume depends Girth (plot result, regression line).Assume Volume depends Height (plot result, regression line).linear model write algebraic equation linear model produces relates volume two continuous predictor variables.Check assumptions model. concerns?NB: two continuous predictors, interaction term simply two values multiplied together (Girth:Height means Girth x Height)Use equations calculate predicted volume tree diameter 20 inches height 67 feet case.Let’s construct four linear models turn.r commands :can use output get following equation:Volume = 69.40 + -1.30 \\(\\cdot\\) Height + -5.86 \\(\\cdot\\) Girth + 0.13 \\(\\cdot\\) Height \\(\\cdot\\) GirthIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = 69.40 + -1.30 \\(\\cdot\\) 67 + -5.86 \\(\\cdot\\) 20 + 0.13 \\(\\cdot\\) 67 \\(\\cdot\\) 20Volume = 45.81Here note interaction term just requires us multiple three numbers together (haven’t looked continuous predictors examples exercise included check see whole process making sense).look diagnostic plots model using following commands get:assumptions OK.suggestion heterogeneity variance (variance lower small large fitted (.e. predicted Volume) values), can attributed small number data points edges, ’m overly concerned.Similarly, suggestion snaking Q-Q plot (suggesting lack normality) mainly due inclusion one data point overall plot looks acceptable.highly influential pointsThe r commands :can use output get following equation:Volume = -57.99 + 0.34 \\(\\cdot\\) Height + 4.71 \\(\\cdot\\) GirthIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = -57.99 + 0.34 \\(\\cdot\\) 67 + 4.71 \\(\\cdot\\) 20Volume = 58.91If look diagnostic plots model using following commands get following:model isn’t great.worrying lack linearity exhibited Residuals plot suggesting linear model isn’t appropriate.Assumptions Normality seem OKEquality variance harder interpret. Given lack linearity data isn’t really sensible interpret Location-Scale plot stands (since plot generated assuming ’ve fitted straight line data), sake practising interpretation ’ll go. definitely suggestions heterogeneity variance cluster points fitted values around 20 noticeably lower variance rest dataset.One point influential weren’t issues linearity model remove point repeat analysis. stands isn’t much point.r commands :can use output get following equation:Volume = `-87.12 + 1.54 \\(\\cdot\\) HeightIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = -87.12 + 1.54 \\(\\cdot\\) 67Volume = 16.28If look diagnostic plots model using following commands get following:model also isn’t great.main issue clear heterogeneity variance. trees bigger volumes data much spread trees smaller volumes (can seen clearly Location-Scale plot).Apart , assumption Normality seems OKAnd aren’t hugely influential points modelThe r commands :can use output get following equation:Volume = -36.94 + 5.07 \\(\\cdot\\) GirthIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = -36.94 + 5.07 \\(\\cdot\\) 20Volume = 64.37If look diagnostic plots model using following commands get following:diagnostic plots look rather similar ones generated additive model issue lack linearity, heterogeneity variance one data points influential.","code":"\n# define the model\nlm_tree_full <- lm(Volume ~ Height * Girth,\n                   data = trees)\n\n# view the model\nlm_tree_full## \n## Call:\n## lm(formula = Volume ~ Height * Girth, data = trees)\n## \n## Coefficients:\n##  (Intercept)        Height         Girth  Height:Girth  \n##      69.3963       -1.2971       -5.8558        0.1347\nlm_tree_full %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)\n# define the model\nlm_tree_add <- lm(Volume ~ Height + Girth,\n                  data = trees)\n\n# view the model\nlm_tree_add## \n## Call:\n## lm(formula = Volume ~ Height + Girth, data = trees)\n## \n## Coefficients:\n## (Intercept)       Height        Girth  \n##    -57.9877       0.3393       4.7082\nlm_tree_add %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)\n# define the model\nlm_height <- lm(Volume ~ Height,\n              data = trees)\n\n# view the model\nlm_height## \n## Call:\n## lm(formula = Volume ~ Height, data = trees)\n## \n## Coefficients:\n## (Intercept)       Height  \n##     -87.124        1.543\nlm_height %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)\n# define the model\nlm_girth <- lm(Volume ~ Girth,\n               data = trees)\n\n# view the model\nlm_girth## \n## Call:\n## lm(formula = Volume ~ Girth, data = trees)\n## \n## Coefficients:\n## (Intercept)        Girth  \n##     -36.943        5.066\nlm_girth %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)"},{"path":"linear-models.html","id":"full-model","chapter":"4 Linear models","heading":"4.8.1 Full model","text":"r commands :can use output get following equation:Volume = 69.40 + -1.30 \\(\\cdot\\) Height + -5.86 \\(\\cdot\\) Girth + 0.13 \\(\\cdot\\) Height \\(\\cdot\\) GirthIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = 69.40 + -1.30 \\(\\cdot\\) 67 + -5.86 \\(\\cdot\\) 20 + 0.13 \\(\\cdot\\) 67 \\(\\cdot\\) 20Volume = 45.81Here note interaction term just requires us multiple three numbers together (haven’t looked continuous predictors examples exercise included check see whole process making sense).look diagnostic plots model using following commands get:assumptions OK.suggestion heterogeneity variance (variance lower small large fitted (.e. predicted Volume) values), can attributed small number data points edges, ’m overly concerned.Similarly, suggestion snaking Q-Q plot (suggesting lack normality) mainly due inclusion one data point overall plot looks acceptable.highly influential points","code":"\n# define the model\nlm_tree_full <- lm(Volume ~ Height * Girth,\n                   data = trees)\n\n# view the model\nlm_tree_full## \n## Call:\n## lm(formula = Volume ~ Height * Girth, data = trees)\n## \n## Coefficients:\n##  (Intercept)        Height         Girth  Height:Girth  \n##      69.3963       -1.2971       -5.8558        0.1347\nlm_tree_full %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)"},{"path":"linear-models.html","id":"additive-model-1","chapter":"4 Linear models","heading":"4.8.2 Additive model","text":"r commands :can use output get following equation:Volume = -57.99 + 0.34 \\(\\cdot\\) Height + 4.71 \\(\\cdot\\) GirthIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = -57.99 + 0.34 \\(\\cdot\\) 67 + 4.71 \\(\\cdot\\) 20Volume = 58.91If look diagnostic plots model using following commands get following:model isn’t great.worrying lack linearity exhibited Residuals plot suggesting linear model isn’t appropriate.Assumptions Normality seem OKEquality variance harder interpret. Given lack linearity data isn’t really sensible interpret Location-Scale plot stands (since plot generated assuming ’ve fitted straight line data), sake practising interpretation ’ll go. definitely suggestions heterogeneity variance cluster points fitted values around 20 noticeably lower variance rest dataset.One point influential weren’t issues linearity model remove point repeat analysis. stands isn’t much point.","code":"\n# define the model\nlm_tree_add <- lm(Volume ~ Height + Girth,\n                  data = trees)\n\n# view the model\nlm_tree_add## \n## Call:\n## lm(formula = Volume ~ Height + Girth, data = trees)\n## \n## Coefficients:\n## (Intercept)       Height        Girth  \n##    -57.9877       0.3393       4.7082\nlm_tree_add %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)"},{"path":"linear-models.html","id":"height-only-model","chapter":"4 Linear models","heading":"4.8.3 Height-only model","text":"r commands :can use output get following equation:Volume = `-87.12 + 1.54 \\(\\cdot\\) HeightIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = -87.12 + 1.54 \\(\\cdot\\) 67Volume = 16.28If look diagnostic plots model using following commands get following:model also isn’t great.main issue clear heterogeneity variance. trees bigger volumes data much spread trees smaller volumes (can seen clearly Location-Scale plot).Apart , assumption Normality seems OKAnd aren’t hugely influential points model","code":"\n# define the model\nlm_height <- lm(Volume ~ Height,\n              data = trees)\n\n# view the model\nlm_height## \n## Call:\n## lm(formula = Volume ~ Height, data = trees)\n## \n## Coefficients:\n## (Intercept)       Height  \n##     -87.124        1.543\nlm_height %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)"},{"path":"linear-models.html","id":"girth-only-model","chapter":"4 Linear models","heading":"4.8.4 Girth-only model","text":"r commands :can use output get following equation:Volume = -36.94 + 5.07 \\(\\cdot\\) GirthIf stick numbers (Girth = 20 Height = 67) get following equation:Volume = -36.94 + 5.07 \\(\\cdot\\) 20Volume = 64.37If look diagnostic plots model using following commands get following:diagnostic plots look rather similar ones generated additive model issue lack linearity, heterogeneity variance one data points influential.","code":"\n# define the model\nlm_girth <- lm(Volume ~ Girth,\n               data = trees)\n\n# view the model\nlm_girth## \n## Call:\n## lm(formula = Volume ~ Girth, data = trees)\n## \n## Coefficients:\n## (Intercept)        Girth  \n##     -36.943        5.066\nlm_girth %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)"},{"path":"linear-models.html","id":"key-points","chapter":"4 Linear models","heading":"4.9 Key points","text":"can define linear model lm(), adding extra variablesUsing coefficients model can construct linear model equationThe underlying assumptions linear model three predictor variables two-way ANOVA","code":""},{},{"path":"model-comparisons.html","id":"model-comparisons","chapter":"5 Model comparisons","heading":"5 Model comparisons","text":"","code":""},{"path":"model-comparisons.html","id":"objectives-2","chapter":"5 Model comparisons","heading":"5.1 Objectives","text":"QuestionsHow compare linear models?decide one “best” model?ObjectivesBe able compare models using Akaike Information Criterion (AIC)Use AIC context Backwards Stepwise Elimination R","code":""},{"path":"model-comparisons.html","id":"purpose-and-aim-1","chapter":"5 Model comparisons","heading":"5.2 Purpose and aim","text":"previous example used single dataset fitted five linear models depending predictor variables used. Whilst fun (seriously, else right now?) seems “better way.” Well, thankfully ! fact several methods can used compare different models order help identify “best” model. specifically, can determine full model (uses available predictor variables interactions) necessary appropriately describe dependent variable, whether can throw away terms (e.g. interaction term) don’t offer useful predictive power.use Akaike Information Criterion order compare different models.","code":""},{"path":"model-comparisons.html","id":"section-commands-1","chapter":"5 Model comparisons","heading":"5.3 Section commands","text":"New commands section:","code":""},{"path":"model-comparisons.html","id":"data-and-hypotheses-1","chapter":"5 Model comparisons","heading":"5.4 Data and hypotheses","text":"section uses data/tidy/CS5-Ladybird.csv data set. data set comprises 20 observations three variables (one dependent two predictor). records clutch size (eggs) species ladybird alongside two potential predictor variables; mass female (weight), colour male (male) categorical variable.","code":""},{"path":"model-comparisons.html","id":"backwards-stepwise-elimination","chapter":"5 Model comparisons","heading":"5.5 Backwards Stepwise Elimination","text":"First, load data store object called ladybird. visualise data.","code":"\nladybird <- read_csv(\"data/tidy/CS5-Ladybird.csv\")\n# visualise the data\nladybird %>% \n  ggplot(aes(x = weight, y = eggs,\n             colour = male)) +\n  geom_point() +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"model-comparisons.html","id":"comparing-models-with-aic-step-1","chapter":"5 Model comparisons","heading":"5.5.1 Comparing models with AIC (step 1)","text":"First, construct full linear model:Now construct reduced model (.e. next simplest model) doesn’t interactions:compare two models simply use command extractAIC() model.line first number tells many parameters model second number tells AIC score model. can see full model 4 parameters (intercept, coefficient continuous variable weight, coefficient categorical variable male coefficient interaction term weight:male) AIC score 41.3 (1dp). reduced model lower AIC score 40.4 (1dp) 3 parameters (since ’ve dropped interaction term). different ways interpreting AIC scores widely used interpretation says :difference two AIC scores greater 2 model smallest AIC score supported model higher AIC scoreif difference two models’ AIC scores less 2 models equally well supportedThis choice language (supported vs significant) deliberate areas statistics AIC scores used differently way going use (ask want bit philosophical ramble ). However, situation use AIC scores decide whether reduced model least good full model. since difference AIC scores less 2, can say dropping interaction term left us model simpler (fewer terms) least good (AIC score) full model. reduced model eggs ~ weight + male designated current working minimal model.","code":"\n# define the full model\nlm_full <- lm(eggs ~ weight * male,\n              data = ladybird)\n\n# view the model summary\nsummary(lm_full)\n# define the model\nlm_red <- lm(eggs ~ weight + male,\n             data = ladybird)\n\n# view the model summary\nsummary(lm_red)\nextractAIC(lm_full)## [1]  4.00000 41.28452\nextractAIC(lm_red)## [1]  3.00000 40.43819"},{"path":"model-comparisons.html","id":"comparing-models-with-aic-step-2","chapter":"5 Model comparisons","heading":"5.5.2 Comparing models with AIC (step 2)","text":"Next, see remaining terms can dropped. look models dropped male weight (.e. eggs ~ weight eggs ~ male) compare AIC values AIC current minimal model (eggs ~ weight + male). AIC values least one new reduced models lower (least 2 greater) AIC current minimal model, can drop relevant term get new minimal model. find situation can drop one term drop term gives us model lowest AIC.Drop variable weight examine AIC:Drop variable male examine AIC:Considering outputs together comparing AIC current minimal model (40.4) can see dropping male decreased AIC 38.8, whereas dropping weight actually increased AIC 60.0 thus worsened model quality.Hence can drop male new minimal model eggs ~ weight.","code":"\n# define the model\nlm_male <- lm(eggs ~ male,\n              data = ladybird)\n\n# extract the AIC\nextractAIC(lm_male)## [1]  2.00000 59.95172\n# define the model\nlm_weight <- lm(eggs ~ weight,\n                data = ladybird)\n\n# extract the AIC\nextractAIC(lm_weight)## [1]  2.00000 38.76847"},{"path":"model-comparisons.html","id":"comparing-models-with-aic-step-3","chapter":"5 Model comparisons","heading":"5.5.3 Comparing models with AIC (step 3)","text":"final comparison drop variable weight compare simple model null model (eggs ~ 1), assumes brood size constant across parameters.Drop variable weight see effect:AIC null model quite bit larger current minimal model eggs ~ weight conclude weight important. minimal model eggs ~ weight., summary, conclude :Female size useful predictor clutch size, male type important.stage can analyse minimal linear (lm.weight) model using anova() function, consider diagnostic plots using plot(lm.weight) command.","code":"\n# define the model\nlm_null <- lm(eggs ~ 1,\n              data = ladybird)\n\n# extract the AIC\nextractAIC(lm_null)## [1]  1.00000 58.46029"},{"path":"model-comparisons.html","id":"notes-on-backwards-stepwise-elimination","chapter":"5 Model comparisons","heading":"5.6 Notes on Backwards Stepwise Elimination","text":"method finding minimal model starting full model removing variables called backward stepwise elimination. Although regularly practised data analysis, increasing criticism approach, calls avoided entirely.made work procedure ? Given prevalence academic papers, useful aware procedures know issues . situations, using AIC model comparisons justified come across regularly. Additionally, may situations feel good reasons drop parameter model – using technique can justify doesn’t affect model fit. Taken together, using backwards stepwise elimination model comparison still useful technique.Performing backwards stepwise elimination manually can quite tedious. Thankfully R acknowledges single inbuilt function called step() can perform necessary steps using AIC.perform full backwards stepwise elimination process find minimal model . output familiar ask demonstrator questions.Yes, told earlier, ’s fun ? (also useful understand steps behind technique suppose…)","code":"## Start:  AIC=41.28\n## eggs ~ weight * male\n## \n##               Df Sum of Sq    RSS    AIC\n## - weight:male  1    6.2724 111.90 40.438\n## <none>                     105.63 41.285\n## \n## Step:  AIC=40.44\n## eggs ~ weight + male\n## \n##          Df Sum of Sq    RSS    AIC\n## - male    1     1.863 113.77 38.768\n## <none>                111.90 40.438\n## - weight  1   216.196 328.10 59.952\n## \n## Step:  AIC=38.77\n## eggs ~ weight\n## \n##          Df Sum of Sq    RSS    AIC\n## <none>                113.77 38.768\n## - weight  1    222.78 336.55 58.460## \n## Call:\n## lm(formula = eggs ~ weight, data = ladybird)\n## \n## Coefficients:\n## (Intercept)       weight  \n##       4.320        1.873"},{"path":"model-comparisons.html","id":"exercise-bse","chapter":"5 Model comparisons","heading":"5.7 Exercise: BSE","text":"Exercise 5.1  BSE trees airpollUse internal dataset trees airpoll dataset earlier.Perform backwards stepwise elimination datasets discover minimal model using AIC.NB: interaction term significant main factor part interaction term dropped model.’re feeling attempt backwards stepwise elimination process internal CO2 dataset. data frame 1 dependent variable (uptake) 4 predictor variables (Plant, Type, Treatment, conc). Unfortunately, dataset contain enough data construct full linear model using 4 predictor variables (interactions), ignore Plant variable take uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc +  Treatment:conc + Type:Treatment:conc full model.relatively straightforward using step() function.need first construct full linear model simply pass linear model object step function R rest.construct full linear model Height, Girth interaction run step() function:BSE approach gets far first step (trying drop interaction term). see immediately dropping interaction term makes model worse process stops. next line (underneath Call:) see best model still full model get see coefficients term.construct full linear model treatment_plant, daily_temp interaction run step function:, BSE approach gets far first step (trying drop interaction term). see immediately dropping interaction term makes model worse process stops. next line (underneath Call:) see best model still full model get see coefficients term.time manage three steps. first successful manage drop three-way interaction Type:Treatment:conc. next step end dropping Treatment:conc interaction. final step realise can’t drop terms ’re done. minimal model 5 terms coefficients model given bottom output.","code":"\n# define the full model\nlm_trees <- lm(Volume ~ Girth * Height,\n               data = trees)\n\n# perform BSE\nstep(lm_trees)## Start:  AIC=65.49\n## Volume ~ Girth * Height\n## \n##                Df Sum of Sq    RSS    AIC\n## <none>                      198.08 65.495\n## - Girth:Height  1    223.84 421.92 86.936## \n## Call:\n## lm(formula = Volume ~ Girth * Height, data = trees)\n## \n## Coefficients:\n##  (Intercept)         Girth        Height  Girth:Height  \n##      69.3963       -5.8558       -1.2971        0.1347## Rows: 16 Columns: 4## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (1): treatment_plant\n## dbl (3): id, daily_temp, hydrogen_sulfide## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n# define the full model\nlm_airpoll <- lm(hydrogen_sulfide ~ treatment_plant * daily_temp,\n                 data = airpoll)\n\n# perform BSE\nstep(lm_airpoll)## Start:  AIC=-19.04\n## hydrogen_sulfide ~ treatment_plant * daily_temp\n## \n##                              Df Sum of Sq    RSS     AIC\n## <none>                                    2.9520 -19.041\n## - treatment_plant:daily_temp  1     1.447 4.3991 -14.659## \n## Call:\n## lm(formula = hydrogen_sulfide ~ treatment_plant * daily_temp, \n##     data = airpoll)\n## \n## Coefficients:\n##                 (Intercept)             treatment_plantB  \n##                     6.20495                     -2.73075  \n##                  daily_temp  treatment_plantB:daily_temp  \n##                    -0.05448                      0.18141\n# define the model, ignore the Plant variable\nlm_co2 <- lm(uptake ~ Type + Treatment + conc\n             + Type:Treatment + Type:conc + Treatment:conc\n             + Type:Treatment:conc,\n             data = CO2)\nstep(lm_co2)## Start:  AIC=302.6\n## uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc + \n##     Treatment:conc + Type:Treatment:conc\n## \n##                       Df Sum of Sq    RSS    AIC\n## - Type:Treatment:conc  1    55.535 2602.7 302.41\n## <none>                             2547.2 302.60\n## \n## Step:  AIC=302.41\n## uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc + \n##     Treatment:conc\n## \n##                  Df Sum of Sq    RSS    AIC\n## - Treatment:conc  1    31.871 2634.6 301.44\n## <none>                        2602.7 302.41\n## - Type:conc       1   207.998 2810.7 306.87\n## - Type:Treatment  1   225.730 2828.5 307.40\n## \n## Step:  AIC=301.44\n## uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc\n## \n##                  Df Sum of Sq    RSS    AIC\n## <none>                        2634.6 301.44\n## - Type:conc       1    208.00 2842.6 305.82\n## - Type:Treatment  1    225.73 2860.3 306.34## \n## Call:\n## lm(formula = uptake ~ Type + Treatment + conc + Type:Treatment + \n##     Type:conc, data = CO2)\n## \n## Coefficients:\n##                      (Intercept)                   TypeMississippi  \n##                         25.29351                          -4.72692  \n##                 Treatmentchilled                              conc  \n##                         -3.58095                           0.02308  \n## TypeMississippi:Treatmentchilled              TypeMississippi:conc  \n##                         -6.55714                          -0.01070"},{"path":"model-comparisons.html","id":"trees-dataset","chapter":"5 Model comparisons","heading":"5.7.1 trees dataset","text":"construct full linear model Height, Girth interaction run step() function:BSE approach gets far first step (trying drop interaction term). see immediately dropping interaction term makes model worse process stops. next line (underneath Call:) see best model still full model get see coefficients term.","code":"\n# define the full model\nlm_trees <- lm(Volume ~ Girth * Height,\n               data = trees)\n\n# perform BSE\nstep(lm_trees)## Start:  AIC=65.49\n## Volume ~ Girth * Height\n## \n##                Df Sum of Sq    RSS    AIC\n## <none>                      198.08 65.495\n## - Girth:Height  1    223.84 421.92 86.936## \n## Call:\n## lm(formula = Volume ~ Girth * Height, data = trees)\n## \n## Coefficients:\n##  (Intercept)         Girth        Height  Girth:Height  \n##      69.3963       -5.8558       -1.2971        0.1347"},{"path":"model-comparisons.html","id":"airpoll-dataset","chapter":"5 Model comparisons","heading":"5.7.2 airpoll dataset","text":"construct full linear model treatment_plant, daily_temp interaction run step function:, BSE approach gets far first step (trying drop interaction term). see immediately dropping interaction term makes model worse process stops. next line (underneath Call:) see best model still full model get see coefficients term.","code":"## Rows: 16 Columns: 4## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (1): treatment_plant\n## dbl (3): id, daily_temp, hydrogen_sulfide## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n# define the full model\nlm_airpoll <- lm(hydrogen_sulfide ~ treatment_plant * daily_temp,\n                 data = airpoll)\n\n# perform BSE\nstep(lm_airpoll)## Start:  AIC=-19.04\n## hydrogen_sulfide ~ treatment_plant * daily_temp\n## \n##                              Df Sum of Sq    RSS     AIC\n## <none>                                    2.9520 -19.041\n## - treatment_plant:daily_temp  1     1.447 4.3991 -14.659## \n## Call:\n## lm(formula = hydrogen_sulfide ~ treatment_plant * daily_temp, \n##     data = airpoll)\n## \n## Coefficients:\n##                 (Intercept)             treatment_plantB  \n##                     6.20495                     -2.73075  \n##                  daily_temp  treatment_plantB:daily_temp  \n##                    -0.05448                      0.18141"},{"path":"model-comparisons.html","id":"co2-dataset","chapter":"5 Model comparisons","heading":"5.7.3 CO2 dataset","text":"time manage three steps. first successful manage drop three-way interaction Type:Treatment:conc. next step end dropping Treatment:conc interaction. final step realise can’t drop terms ’re done. minimal model 5 terms coefficients model given bottom output.","code":"\n# define the model, ignore the Plant variable\nlm_co2 <- lm(uptake ~ Type + Treatment + conc\n             + Type:Treatment + Type:conc + Treatment:conc\n             + Type:Treatment:conc,\n             data = CO2)\nstep(lm_co2)## Start:  AIC=302.6\n## uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc + \n##     Treatment:conc + Type:Treatment:conc\n## \n##                       Df Sum of Sq    RSS    AIC\n## - Type:Treatment:conc  1    55.535 2602.7 302.41\n## <none>                             2547.2 302.60\n## \n## Step:  AIC=302.41\n## uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc + \n##     Treatment:conc\n## \n##                  Df Sum of Sq    RSS    AIC\n## - Treatment:conc  1    31.871 2634.6 301.44\n## <none>                        2602.7 302.41\n## - Type:conc       1   207.998 2810.7 306.87\n## - Type:Treatment  1   225.730 2828.5 307.40\n## \n## Step:  AIC=301.44\n## uptake ~ Type + Treatment + conc + Type:Treatment + Type:conc\n## \n##                  Df Sum of Sq    RSS    AIC\n## <none>                        2634.6 301.44\n## - Type:conc       1    208.00 2842.6 305.82\n## - Type:Treatment  1    225.73 2860.3 306.34## \n## Call:\n## lm(formula = uptake ~ Type + Treatment + conc + Type:Treatment + \n##     Type:conc, data = CO2)\n## \n## Coefficients:\n##                      (Intercept)                   TypeMississippi  \n##                         25.29351                          -4.72692  \n##                 Treatmentchilled                              conc  \n##                         -3.58095                           0.02308  \n## TypeMississippi:Treatmentchilled              TypeMississippi:conc  \n##                         -6.55714                          -0.01070"},{"path":"model-comparisons.html","id":"key-points-1","chapter":"5 Model comparisons","heading":"5.8 Key points","text":"can use Backwards Stepwise Elimination (BSE) full model see certain terms add predictive power model notThe AIC allows us compare different models - difference AIC 2 two models, smallest AIC score supportedWe can use step() function let R perform automatic BSE","code":""}]
