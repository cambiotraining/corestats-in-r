[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform core data analysis techniques appropriately confidently using R.6 lecture-practicals6 lecture-practicalsOngoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey ‚Äúmindlessly use stats program‚Äù course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented arbitrary dataset e.g.Know data analysis techniques availableKnow ones allowableBe able carry understand results","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Simple Hypothesis TestingCategorical Predictor VariablesContinuous PredictorsMultiple Predictor VariablesLinear ModelsErrors, Power Multiple Comparisons","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder copy working directory. data accessible via <working-directory-name>/data/raw.","code":""},{},{"path":"power-analysis.html","id":"power-analysis","chapter":"2 Power analysis","heading":"2 Power analysis","text":"","code":""},{"path":"power-analysis.html","id":"objectives","chapter":"2 Power analysis","heading":"2.1 Objectives","text":"QuestionsHow ‚Ä¶‚Ä¶ObjectivesBe able ‚Ä¶Use‚Ä¶","code":""},{"path":"power-analysis.html","id":"background","chapter":"2 Power analysis","heading":"2.2 Background","text":"hypothesis tests can wrong two ways:can appear found significant result really isn‚Äôt anything : false positive (Type error), orwe can fail spot significant result really something interesting going : false negative (Type II error).probability getting false positive analysis precisely significance level use analysis. , order reduce likelihood getting false positive simply reduce significance level test (0.05 0.01 say). Easy .Unfortunately, unintended consequences (doesn‚Äôt everything?). turns reducing significance level means increase chance getting false negatives. make sense; ‚Äôre increasing barrier entry terms acceptance ‚Äôll also accidentally miss good stuff.Power capacity test detect significant different results. affected three things:effect size: .e.¬†big difference want able detect, alternatively consider meaningful effect/difference ?sample sizethe significance levelIn ideal world want carrying highly powerful tests using low significance levels, reduce chance getting false positive maximise chances finding true effect.*Power analysis allows us design experiments just . Given:desired power (0.8 80% considered pretty good)significance level (0.05 5% trusty yet arbitrary steed )effect size like detectwe can calculate amount data need collect experiments. (Woohoo! looks statistics actually give us answer last rather perpetual shades--grey ‚Äúmaybes‚Äù).reality easily usable power analysis functions operate assumption data collect meet assumptions chosen statistical test perfectly. , example, want design experiment investigating effectiveness single drug compared placebo (simple t-test) want know many patients group order test work, standard power analysis techniques still assume data end collecting meet assumptions t-test carry (Sorry raised hopes ever slightly üòâ).","code":""},{"path":"power-analysis.html","id":"effect-size","chapter":"2 Power analysis","heading":"2.2.1 Effect size","text":"shall see commands carrying power analyses simple implement apart concept effect size. tricky issue people get grips two reasons:Effect size related biological significance rather statistical significanceThe way specify effect sizesWith respect first point common conversation goes bit like :: ‚Äú‚Äôve told carry power analysis, eh? Lucky . sort effect size looking ?‚Äù: ‚Äúidea ‚Äôre talking . want know drug better placebo. many patients need?‚Äù: ‚Äúdepends big difference think drug compared placebo.‚Äù: ‚Äúhaven‚Äôt carried experiment yet, absolutely idea big effect !‚Äù: (honest relatively well-informed conversation: much closer things actually go)key point effect sizes power analyses need specify effect size interested observing, one biologically relevant see. may well actually 0.1% difference effectiveness drug placebo designing experiment detect require markedly individuals experiment trying detect 50% difference effectiveness. reality three places can get sense effect sizes :pilot studyPrevious literature theoryJacob CohenJacob Cohen American statistician developed large set measures effect sizes (use today). came rough set numerical measures ‚Äúsmall,‚Äù ‚Äúmedium‚Äù ‚Äúlarge‚Äù effect sizes still use today. come caveats though; Jacob psychologist assessment large effect may somewhat different . form useful starting point however.lot different ways specifying effects sizes, can split three distinct families estimates:Correlation estimates: use R2 measure variance explained model (linear models, anova etc. large R2 value indicate lot variance explained model expect see lot difference groups, tight cluster points around line best fit. argument goes need fewer data points observe relationship confidence. Trying find relationship low R2 value trickier therefore require data points equivalent power.Difference means: look far apart means two groups , measured units standard deviations (t-tests). effect size 2 case interpreted two groups means two standard deviations away (quite big difference), whereas effect size 0.2 harder detect require data pick .Difference count data: freely admit idea intuitively explain (shock, horror). Mathematically based chi-squared statistic ‚Äôs good can tell ‚Äôm afraid. , however, pretty easy calculate.reference Cohen‚Äôs suggested values effect sizes different tests. ‚Äôll probably surprised small .look carry power analyses estimate effect sizes section.","code":""},{"path":"power-analysis.html","id":"packages","chapter":"2 Power analysis","heading":"2.3 Packages","text":"using pwr powerAnalysis packages section. Please install now.can running following code console:Next, load running:packages lot overlap unfortunately neither one quite functionality ‚Äôd like. powerAnalysis functions explicitly calculating effect sizes previous studies smaller range power calculation functions. pwr power functions fewer effect size functions. However, together job.","code":"\ninstall.packages(c(\"pwr\", \"powerAnalysis\"))\nlibrary(pwr)\nlibrary(powerAnalysis)"},{"path":"power-analysis.html","id":"section-commands","chapter":"2 Power analysis","heading":"2.4 Section commands","text":"New commands used section:","code":""},{"path":"power-analysis.html","id":"t-tests","chapter":"2 Power analysis","heading":"2.5 t-tests","text":"Let‚Äôs assume want design experiment determine whether difference mean price male female students pay cafe. many male female students need observe order detect ‚Äúmedium‚Äù effect size 80% power significance level 0.05?first need think test use analyse data. two groups continuous response. Clearly t-test.","code":""},{"path":"power-analysis.html","id":"get-the-effect-size","chapter":"2 Power analysis","heading":"2.5.1 Get the effect size","text":"Now need work ‚Äúmedium‚Äù effect size . absence information appeal Cohen‚Äôs conventional values:function just returns default conventional values effect sizes determined Jacob Cohen back day. just saves us scrolling back page look table provided. takes two arguments:test one \n‚Äút,‚Äù t-tests,\n‚Äúanova‚Äù anova,\n‚Äúf2‚Äù linear models\n‚Äúchisq‚Äù chi-squared test\n‚Äút,‚Äù t-tests,‚Äúanova‚Äù anova,‚Äúf2‚Äù linear models‚Äúchisq‚Äù chi-squared testsize, just one ‚Äúsmall,‚Äù ‚Äúmedium‚Äù ‚Äúlarge.‚Äùbit want bottom line; apparently want effect size 0.5.\nsort study effect size measured terms Cohen‚Äôs d statistic. simply measure different means two groups expressed terms number standard deviations apart . , case ‚Äôre looking detect two means 0.5 standard deviations away . minute ‚Äôll look means real data.","code":"\ncohen.ES(test = \"t\", size = \"medium\")## \n##      Conventional effect size from Cohen (1982) \n## \n##            test = t\n##            size = medium\n##     effect.size = 0.5"},{"path":"power-analysis.html","id":"carry-out-a-power-analysis","chapter":"2 Power analysis","heading":"2.5.2 Carry out a power analysis","text":"follows:first line ‚Äôre looking n = 63.76 tells need 64 (rounding ) students group (128 total) order carry study sufficient power. lines self-explanatory (well stage; need tell function just returning values ‚Äôve just typed bigger problems worry ).pwr.t.test() function six arguments. Two specify sort t-test ‚Äôll carrying \n* type; describes type t-test eventually carrying (one two.sample, one.sample paired), \n* alternative; describes type alternative hypothesis want test (one two.sided, less greater)four arguments used power analysis:d; effect size, single number calculated using Cohen‚Äôs d statistic.sig.level; significance levelpower; powern; number observations per sample.function works allowing specify three four arguments function works fourth. example used test standard fashion specifying power, significance desired effect size getting function tell us necessary sample size.can use function answer different question:know advance can observe 30 students per group, effect size able observe 80% power 5% significance level?time want see effect size look second line can see experiment many people expected detect difference means d = 0.74 standard deviations. good bad? Well, depends natural variation data; data really noisy large variation large standard deviation mean 0.74 standard deviations might actually quite big difference groups. hand data doesn‚Äôt vary much, 0.74 standard deviations might actually really small number test pick even quite small differences mean.previous two examples little bit context-free terms effect size. Let‚Äôs look can use pilot study real data calculate effect sizes perform power analysis inform future study.Let‚Äôs look fishlength data saw first practical relating lengths fish two separate rivers. saved data/raw/CS6-fishlength.csv.summary() command can see 39 records Aripo river 29 records Guanapo river. box plot see groups appear different means t-test analysis can see difference significant.Can use information design efficient experiment? One confident powerful enough pick difference means big observed study fewer observations?Let‚Äôs first work exactly effect size previous study really estimating Cohen‚Äôs d using data.function calculates effect size using t-statistic (t) values sample sizes two groups (n1, n2). function can perform calculation given information (means two groups, standard deviations two groups etc.) look five examples bottom help file (?ES.t.two) see ways can used.second line d value want.rest output just padding reminds us conventional values effect sizes reference .can know actually answer question see many fish really need catch future:can see future experiments really need use 19 fish group (18.77 first line rounded , fish harmed experiment‚Ä¶) wanted confident detecting difference observed previous study.approach can also used pilot study showed smaller effect size wasn‚Äôt observed significant (indeed arguably, pilot study shouldn‚Äôt really concern significance really used way assessing potential effect sizes can used follow-study).","code":"\npwr.t.test(d = 0.5, sig.level = 0.05, power = 0.8,\n           type = \"two.sample\", alternative=\"two.sided\")## \n##      Two-sample t test power calculation \n## \n##               n = 63.76561\n##               d = 0.5\n##       sig.level = 0.05\n##           power = 0.8\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\npwr.t.test(n = 30, sig.level = 0.05, power = 0.8,\n           type = \"two.sample\", alternative = \"two.sided\")## \n##      Two-sample t test power calculation \n## \n##               n = 30\n##               d = 0.7356292\n##       sig.level = 0.05\n##           power = 0.8\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\n# read in the data\nfishlength <- read.csv(\"data/raw/CS6-fishlength.csv\")\n\n# summarise the data\nsummary(fishlength)##      length         river          \n##  Min.   :11.20   Length:68         \n##  1st Qu.:18.40   Class :character  \n##  Median :19.30   Mode  :character  \n##  Mean   :19.46                     \n##  3rd Qu.:20.93                     \n##  Max.   :26.40\n# visualise the data\nboxplot(length ~ river,\n        data = fishlength)\n# perform a t-test, assuming equal variance\nt.test(length ~ river,\n       data = fishlength, var.equal = TRUE)## \n##  Two Sample t-test\n## \n## data:  length by river\n## t = 3.8433, df = 66, p-value = 0.0002754\n## alternative hypothesis: true difference in means between group Aripo and group Guanapo is not equal to 0\n## 95 percent confidence interval:\n##  0.9774482 3.0909868\n## sample estimates:\n##   mean in group Aripo mean in group Guanapo \n##              20.33077              18.29655\nES.t.two(t = 3.8433, n1 = 39, n2 = 29)## \n##      effect size (Cohen's d) of independent two-sample t test \n## \n##               d = 0.942383\n##     alternative = two.sided\n## \n## NOTE: The alternative hypothesis is m1 != m2\n## small effect size:  d = 0.2\n## medium effect size: d = 0.5\n## large effect size:  d = 0.8\npwr.t.test(d = 0.94, power = 0.8, sig.level = 0.05,\n           type = \"two.sample\", alternative = \"two.sided\")## \n##      Two-sample t test power calculation \n## \n##               n = 18.77618\n##               d = 0.94\n##       sig.level = 0.05\n##           power = 0.8\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group"},{"path":"power-analysis.html","id":"exercise-one-sample","chapter":"2 Power analysis","heading":"2.6 Exercise: one-sample","text":"Exercise 2.1  Performing power analysis one-sample data setLoad data/raw/CS6-onesample.csv (data looked earlier practical containing information fish lengths single river).Assume pilot study analyse data using one-sample t-test see evidence mean length fish differs 19 cm.Use results analysis estimate effect size.Work big sample size required detect effect big power 0.8 significance 0.05.sample size change wanted 0.9 power significance 0.01?First, read data:Let‚Äôs run one-sample t-test :OK, doesn‚Äôt appear statistically significant result ; mean length fish doesn‚Äôt appear different 19cm. output though see mean length sample fish 18.30 (2dp), sample little bit smaller 19 cm.Let‚Äôs calculate effect size using t-statistic degrees freedom t-test output . gives us following value effect size terms Cohen‚Äôs d metric.effect size 0.277 somewhere small medium effect size. means hard detect small sample size ‚Äôs likely need just 29 observations detect effect big.Now, let‚Äôs power analysis actually calculate sample size required:need 105 (round n value) observations experimental protocol order able detect effect size big (small?) 5% significance level 80% power. Let‚Äôs see happen wanted even stringent:198 observations! need lot work wanted work level significance power. small differences fish length biologically meaningful?","code":"\nexOne <- read.csv(\"data/raw/CS6-onesample.csv\")\nt.test(exOne$Guanapo , mu = 19)## \n##  One Sample t-test\n## \n## data:  exOne$Guanapo\n## t = -1.4657, df = 28, p-value = 0.1539\n## alternative hypothesis: true mean is not equal to 19\n## 95 percent confidence interval:\n##  17.31341 19.27969\n## sample estimates:\n## mean of x \n##  18.29655\nES.t.one(t = -1.4657 , df = 28)## \n##      effect size (Cohen's d) of one-sample t test \n## \n##               d = 0.2769913\n##     alternative = two.sided\n## \n## NOTE: The alternative hypothesis is m != mu\n## small effect size:  d = 0.2\n## medium effect size: d = 0.5\n## large effect size:  d = 0.8\npwr.t.test(d = 0.2769913, sig.level = 0.05, power = 0.8,\n           type = \"one.sample\")## \n##      One-sample t test power calculation \n## \n##               n = 104.2368\n##               d = 0.2769913\n##       sig.level = 0.05\n##           power = 0.8\n##     alternative = two.sided\npwr.t.test(d = 0.2769913, sig.level = 0.01, power = 0.9,\n           type = \"one.sample\")## \n##      One-sample t test power calculation \n## \n##               n = 197.2625\n##               d = 0.2769913\n##       sig.level = 0.01\n##           power = 0.9\n##     alternative = two.sided"},{"path":"power-analysis.html","id":"exercise-two-sample-paired","chapter":"2 Power analysis","heading":"2.7 Exercise: two-sample paired","text":"Exercise 2.2  Power analysis paired two-sample data setLoad data/raw/CS6-twopaired.csv (data used earlier practical relates cortisol levels measured 20 participants morning evening).first carry power analysis work big effect size experiment able detect power 0.8 significance level 0.05. Don‚Äôt look data just yet!Now calculate actual observed effect size study.repeat study future, many observations necessary detect observed effect 80% power significance level 0.01?First, read data:paired dataset 20 pairs observations, sort effect size detect significance level 0.05 power 0.8?Remember get effect size measured Cohen‚Äôs d metric. experimental design able detect d value 0.66 (2dp) medium large effect size.Now let‚Äôs look actual data work effect size actually :Use t-statistic calculate effect size:(1.19) massive effect size. ‚Äôs quite likely actually participants study actually need given large effect. Let calculate many individuals actually need:needed 12 pairs participants study given size effect trying detect.","code":"\nexTwo <- read.csv(\"data/raw/CS6-twopaired.csv\")\npwr.t.test(n = 20, sig.level = 0.05, power = 0.8,\n           type=\"paired\")## \n##      Paired t test power calculation \n## \n##               n = 20\n##               d = 0.6604413\n##       sig.level = 0.05\n##           power = 0.8\n##     alternative = two.sided\n## \n## NOTE: n is number of *pairs*\nt.test(exTwo$morning, exTwo$evening, paired=T)## \n##  Paired t-test\n## \n## data:  exTwo$morning and exTwo$evening\n## t = 5.1833, df = 19, p-value = 5.288e-05\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##   69.20962 162.96038\n## sample estimates:\n## mean of the differences \n##                 116.085\nES.t.paired(t = 5.1833, df = 19)## \n##      effect size (Cohen's d) of paired two-sample t test \n## \n##               d = 1.189131\n##     alternative = two.sided\n## \n## NOTE: The alternative hypothesis is md != 0\n## small effect size:  d = 0.2\n## medium effect size: d = 0.5\n## large effect size:  d = 0.8\npwr.t.test(d = 1.189131, sig.level = 0.01, power=0.8,\n           type = \"paired\")## \n##      Paired t test power calculation \n## \n##               n = 11.67291\n##               d = 1.189131\n##       sig.level = 0.01\n##           power = 0.8\n##     alternative = two.sided\n## \n## NOTE: n is number of *pairs*"},{"path":"power-analysis.html","id":"key-points","chapter":"2 Power analysis","heading":"2.8 Key points","text":"Point 1Point 2Point 3","code":""}]
