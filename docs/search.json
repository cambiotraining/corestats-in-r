[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform core data analysis techniques appropriately confidently using R.6 lecture-practicals6 lecture-practicalsOngoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey ‚Äúmindlessly use stats program‚Äù course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented arbitrary dataset e.g.Know data analysis techniques availableKnow ones allowableBe able carry understand results","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Simple Hypothesis TestingCategorical Predictor VariablesContinuous PredictorsMultiple Predictor VariablesLinear ModelsErrors, Power Multiple Comparisons","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder copy working directory. data accessible via <working-directory-name>/data/raw.","code":""},{},{"path":"cs1-intro.html","id":"cs1-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"cs1-intro.html","id":"objectives","chapter":"2 Introduction","heading":"2.1 Objectives","text":"Aim: carry basic one two sample statistical tests.end section practical participants able achieve following listed tests:Understand purpose test isPerform test RInterpret test outputUnderstand assumptions/conditions test appropriateCheck assumptionsThe tests covered practical :One-sample tests\nOne sample t-test\nOne-sample Wilcoxon signed-rank test\nOne sample t-testOne-sample Wilcoxon signed-rank testTwo-sample tests\nStudent‚Äôs t-test\nMann-Whitney U test\nPaired two-sample t-test\nWilcoxon signed-rank test\nStudent‚Äôs t-testMann-Whitney U testPaired two-sample t-testWilcoxon signed-rank test","code":""},{"path":"cs1-intro.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"practical focus underlying mathematical theory tests although demonstrators happy answer questions.\ntest section explaining purpose, section explaining perform test R, section explaining results output screen, section covering assumptions required perform test.","code":""},{},{"path":"introduction.html","id":"introduction","chapter":"3 Introduction","heading":"3 Introduction","text":"practical document divided various sections. section explanatory text help understand going ‚Äôre trying achieve.\nmay list commands relevant section displayed boxes like :Conditional operatorsTo set filtering conditions, use following relational operators:> greater >= greater equal < less <= less equal == equal != different %% contained combine conditions, use following logical operators:& | ","code":""},{"path":"introduction.html","id":"cs1-datasets","chapter":"3 Introduction","heading":"3.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"cs1-one-sample-tests.html","id":"cs1-one-sample-tests","chapter":"4 One-sample tests","heading":"4 One-sample tests","text":"","code":""},{"path":"cs1-one-sample-tests.html","id":"objectives-1","chapter":"4 One-sample tests","heading":"4.1 Objectives","text":"QuestionsWhen perform one-sample test?one-sample tests assumptions?interpret present results tests?ObjectivesSet hypothesis single sample continuous dataBe able summarise visualise data RUnderstand assess underlying assumptions testsPerform one-sample t-test Wilcoxon signed-rank test RKnow test appropriate whenBe able interpret report results","code":""},{"path":"cs1-one-sample-tests.html","id":"purpose-and-aim","chapter":"4 One-sample tests","heading":"4.2 Purpose and aim","text":"tests used single sample continuous data. used find sample came parent distribution given mean (median). essentially boils finding sample mean (median) ‚Äúclose enough‚Äù hypothesised parent population mean (median).\n, figure , use tests see probability sample ten points comes distribution plotted .e.¬†population mean 20 mm.","code":""},{"path":"cs1-one-sample-tests.html","id":"choosing-a-test","chapter":"4 One-sample tests","heading":"4.3 Choosing a test","text":"two tests going look situation; one-sample t-test, one-sample Wilcoxon signed rank test. tests work sort data ‚Äôre considering , different assumptions.data normally distributed, one-sample t-test appropriate. data aren‚Äôt normally distributed, distribution symmetric, sample size small one-sample Wilcoxon signed rank test appropriate.statistical test consider five tasks. come back , pay extra close attention.Setting hypothesisSummarise visualisation dataAssessment assumptionsImplementation statistical testInterpreting output presentation resultsWe won‚Äôt always carry exactly order, always consider five tasks every test.","code":""},{},{"path":"cs1-one-sample-t-test.html","id":"cs1-one-sample-t-test","chapter":"5 1-sample t-test","heading":"5 1-sample t-test","text":"","code":""},{"path":"cs1-one-sample-t-test.html","id":"section-commands","chapter":"5 1-sample t-test","heading":"5.1 Section commands","text":"New commands used section:","code":""},{"path":"cs1-one-sample-t-test.html","id":"data-and-hypotheses","chapter":"5 1-sample t-test","heading":"5.2 Data and hypotheses","text":"example, suppose measure body lengths male guppies (mm) collected Guanapo River Trinidad. want test whether data support hypothesis mean body actually 20 mm. form following null alternative hypotheses:\\(H_0\\): mean body length equal 20mm (\\(\\mu =\\) 20).\\(H_1\\): mean body length equal 20mm (\\(\\mu \\neq\\) 20).use one-sample, two-tailed t-test see reject null hypothesis .use one-sample test one sample.use two-tailed t-test want know data suggest true (population) mean different 20 mm either direction rather just see greater less 20 mm (case use one-tailed test).‚Äôre using t-test don‚Äôt know better yet ‚Äôm telling . ‚Äôll look precise assumptions/requirements need moment.Make sure downloaded data (see: Datasets) placed data/raw folder within working directory.read data create vector containing data.first line reads data R creates object called data frame. data frame contains single column numbers called ‚ÄúGuanapo‚Äù (name river). situations, statistical analyses, data stored data frame exactly ‚Äôd want. However, one sample tests actually need data stored vector. , second line extracts values Guanapo column fishlengthDF data frame creates simple vector numbers called fishlength. step necessary one-sample tests look complex datasets, won‚Äôt need second step .","code":"\n# import the data\nfishlengthDF <- read.csv(\"data/raw/CS1-onesample.csv\")\n\n# create a vector containing the data\nfishlength <- fishlengthDF$Guanapo"},{"path":"cs1-one-sample-t-test.html","id":"summarise-and-visualise","chapter":"5 1-sample t-test","heading":"5.3 Summarise and visualise","text":"Summarise data visualise :data appear contain obvious errors, whilst mean median less 20 (18.3 18.8 respectively) absolutely certain sample mean sufficiently different value ‚Äústatistically significant,‚Äù although may anticipate result.","code":"\nsummary(fishlength)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    11.2    17.5    18.8    18.3    19.7    23.3\nboxplot(fishlength, main = \"Male guppies\", ylab = \"Length (mm)\")"},{"path":"cs1-one-sample-t-test.html","id":"implement-the-test","chapter":"5 1-sample t-test","heading":"5.4 Implement the test","text":"Perform one-sample, two-tailed t-test:first argument must numerical vector data values.second argument must number mean tested null hypothesis.third argument gives type alternative hypothesis must one two.sided, greater less.","code":"\nt.test(fishlength, mu = 20, alternative = \"two.sided\")## \n##  One Sample t-test\n## \n## data:  fishlength\n## t = -3.5492, df = 28, p-value = 0.001387\n## alternative hypothesis: true mean is not equal to 20\n## 95 percent confidence interval:\n##  17.31341 19.27969\n## sample estimates:\n## mean of x \n##  18.29655"},{"path":"cs1-one-sample-t-test.html","id":"interpreting-the-output-and-report-results","chapter":"5 1-sample t-test","heading":"5.5 Interpreting the output and report results","text":"output now see console window:1st line gives name test 2nd line reminds dataset calledThe 3rd line contains three key outputs test:\ncalculated t-value -3.5492 (‚Äôll need reporting)\n28 degrees freedom (‚Äôll need reporting)\np-value 0.001387.\ncalculated t-value -3.5492 (‚Äôll need reporting)28 degrees freedom (‚Äôll need reporting)p-value 0.001387.4th line simply states alternative hypothesisThe 5th 6th lines give 95th confidence interval (don‚Äôt need know )7th, 8th 9th lines give sample mean (18.29655).p-value 3rd line ‚Äôre interested . gives probability us getting sample null hypothesis actually true.:high p-value means high probability observing sample null hypothesis probably true whereasa low p-value means low probability observing sample null hypothesis probably true.important realise p-value just indication absolute certainty interpretation.People, however like definite answers pick artificial probability threshold (called significance level) order able say something decisive. standard significance level 0.05 since p-value smaller choose say ‚Äúunlikely particular sample null hypothesis true.‚Äù Consequently, can reject null hypothesis state :one-sample t-test indicated mean body length male guppies (\\(\\mu\\) = 18.29mm) differs significantly 20 mm (t = -3.55, df = 28, p = 0.0014).sentence adequate concluding statement test write paper report. Note included (brackets) information actual mean value group(\\(\\mu\\) = 18.29mm), test statistic (t = -3.55), degrees freedom (df = 28), p-value (p = 0.0014). journals required report whether p-value less critical value (e.g.¬†p < 0.05) always recommend reporting actual p-value obtained.Please feel free ask demonstrator aspect section unclear form core classical hypothesis testing logic applies rest tests.","code":"## \n##  One Sample t-test\n## \n## data:  fishlength\n## t = -3.5492, df = 28, p-value = 0.001387\n## alternative hypothesis: true mean is not equal to 20\n## 95 percent confidence interval:\n##  17.31341 19.27969\n## sample estimates:\n## mean of x \n##  18.29655"},{"path":"cs1-one-sample-t-test.html","id":"assumptions","chapter":"5 1-sample t-test","heading":"5.6 Assumptions","text":"order use t-test analysis (results strictly valid) make two assumptions:parent distribution sample taken normally distributed (sample data normally distributed ).worth noting though t-test actually pretty robust situations sample data normal. sufficiently large sample sizes (guess good mine, conventionally means 30 data points), can use t-test without worrying whether underlying population normally distributed .data point sample independent others. general something can tested instead considered sampling procedure. example, taking repeated measurements individual generate data independent.second point know nothing ignore (issue needs considered experimental design), whereas first assumption can checked.\nthree ways checking normality:increasing order rigour, haveHistogramQuantile-quantile plotShapiro-Wilk test","code":""},{"path":"cs1-one-sample-t-test.html","id":"histogram-of-the-data","chapter":"5 1-sample t-test","heading":"5.6.1 Histogram of the data","text":"Plot histogram data, gives:distribution appears uni-modal symmetric, isn‚Äôt obviously non-normal. However, lot distributions simple properties aren‚Äôt normal, isn‚Äôt exactly rigorous. Thankfully , rigorous tests.NB. even looking distribution assess assumption normality already going far beyond anyone else ever . Nevertheless, continue.","code":"\nhist(fishlength, breaks = 15)"},{"path":"cs1-one-sample-t-test.html","id":"q-q-plot-of-the-data","chapter":"5 1-sample t-test","heading":"5.6.2 Q-Q plot of the data","text":"Q-Q plot short quantile-quantile plot. diagnostic plot (sometimes called) way comparing two distributions. Q-Q plots work won‚Äôt explained ask demonstrator really want know going .Construct Q-Q Plot quantiles data quantiles normal distribution:important know data normally distributed points lie (close ) diagonal line graph.case, points lie quite close line part sample quantiles (points) either end sample distribution either smaller (line left) larger (line right) expected supposed normally distributed. suggests sample distribution bit spread expected came normal distribution.important recognise isn‚Äôt simple unambiguous answer interpreting types graph, terms whether assumption normality well met instead often boils matter experience.rare situation indeed assumptions necessary test met unequivocally certain degree personal interpretation always needed. ask whether data normal ‚Äúenough‚Äù confident validity test.four examples QQ plots different types distributions:two graphs relate 200 data points drawn normal distribution. Even can see points lie perfectly diagonal line QQ plot, certain amount deviation top bottom graph can happen just chance (draw different set point graph look slightly different).two graphs relate 200 data points drawn uniform distribution. Uniform distributions condensed normal distributions, reflected QQ plot pronounced S-shaped pattern (colloquially known snaking).two graphs relate 200 data points drawn t distribution. t distributions spread normal distributions, reflected QQ plot pronounced S-shaped pattern , time snaking reflection observed uniform distribution.two graphs relate 200 data points drawn exponential distribution. Exponential distributions symmetric skewed compared normal distributions. significant right-skew distribution reflected QQ plot points curve away diagonal line ends (left-skew points line ends).four cases worth noting deviations ends plot.","code":"\n# plot the Q-Q plot\nqqnorm(fishlength)\n\n# and add a comparison line\nqqline(fishlength)"},{"path":"cs1-one-sample-t-test.html","id":"shapiro-wilk-test","chapter":"5 1-sample t-test","heading":"5.6.3 Shapiro-Wilk test","text":"one number formal statistical test assess whether given sample numbers come normal distribution. calculates probability getting sample data underlying distribution fact normal. easy carry R.Perform Shapiro-Wilk test data:1st line gives name test 2nd line reminds dataset calledThe 3rd line contains two key outputs test:\ncalculated w-value 0.9494 (don‚Äôt need know )\np-value 0.1764\ncalculated w-value 0.9494 (don‚Äôt need know )p-value 0.1764As p-value bigger 0.05 (say) can say insufficient evidence reject null hypothesis sample came normal distribution.important recognise Shapiro-Wilk test without limitations. rather sensitive sample size considered. general, small sample sizes, test relaxed normality (nearly datasets considered normal), whereas large sample sizes test can overly strict, can fail recognise datasets nearly normal indeed.","code":"\nshapiro.test(fishlength)## \n##  Shapiro-Wilk normality test\n## \n## data:  fishlength\n## W = 0.94938, p-value = 0.1764"},{"path":"cs1-one-sample-t-test.html","id":"assumptions-overview","chapter":"5 1-sample t-test","heading":"5.6.4 Assumptions overview","text":"terms assessing assumptions test always worth considering several methods, graphical analytic, just relying single method.fishlength example, graphical Q-Q plot analysis especially conclusive suggestion snaking plots, Shapiro-Wilk test gave non-significant p-value (0.1764). Putting two together, along original histogram recognition 30 data points dataset personally happy assumptions t-test met well enough trust result t-test, may ‚Ä¶case consider alternative test less stringent assumptions (less powerful): one-sample Wilcoxon signed rank test.","code":""},{"path":"cs1-one-sample-t-test.html","id":"exercise","chapter":"5 1-sample t-test","heading":"5.7 Exercise","text":"Exercise 5.1  following data dissolving times (seconds) drug agitated gastric juice:42.7, 43.4, 44.6, 45.1, 45.6, 45.9, 46.8, 47.6Do results provide evidence suggest dissolving time drug different 45 seconds?Write null alternative hypotheses.Summarise visualise data perform appropriate one-sample t-test.\ncan say dissolving time? (sentence use report )\ncan say dissolving time? (sentence use report )Check assumptions test.\ntest valid?\ntest valid?Hypotheses\n\\(H_0\\) : mean = 45s\\(H_1\\) : mean \\(\\neq\\) 45sCreate data, summarise visualiseThere 8 data points, default histogram looks bit rubbish / uninformative. Thankfully box-plot bit useful . can see:don‚Äôt appear major errors data entry aren‚Äôt huge outliersThe median value box-plot (thick black line) pretty close 45 wouldn‚Äôt surprised mean data isn‚Äôt significantly different 45. can confirm looking mean median values calculated using summary command earlier.data appear symmetric, whilst can‚Äôt tell ‚Äôre normal ‚Äôre least massively skewed.Carry t-testA one-sample t-test indicated mean dissolving time drug significantly different 45s (t=0.366 , df=7 , p=0.725),Explore Assumptions\nNormality:Shapiro test p-value 0.964 (given bigger 0.05) suggests data normal enough.qq-plot isn‚Äôt perfect, deviation points away line since points aren‚Äôt accelerating away line , since 8 points, can claim, slight reservations, assumption normality appears adequately well met.Overall, somewhat confident assumption normality well-enough met t-test appropriate method analysing data. Note ridiculous number caveats slightly political/slippery language ‚Äôm using. intentional reflects ambiguous nature assumption checking. important approach statistics need embrace.reality, found situation also try non-parametric test data (Wilcoxon-signed Rank test) see whether get conclusion whether median dissolving time differs 45s. Technically, don‚Äôt know Wilcoxon test yet haven‚Äôt done section handout. Anyway, get conclusion confidence result test goes considerably; doesn‚Äôt matter well assumption met , get result. hand get completely different conclusion carrying non-parametric test bets ; now little confidence test result don‚Äôt know one believe (case assumptions test bit unclear). example Wilcoxon test also gives us non-significant result good.","code":"\ndissolving<-c(42.7 , 43.4 , 44.6 , 45.1 , 45.6 , 45.9 , 46.8 , 47.6)\nsummary(dissolving)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   42.70   44.30   45.35   45.21   46.12   47.60\nhist(dissolving)\nboxplot(dissolving)\nt.test(dissolving , mu=45 , alternative = \"two.sided\")## \n##  One Sample t-test\n## \n## data:  dissolving\n## t = 0.36647, df = 7, p-value = 0.7248\n## alternative hypothesis: true mean is not equal to 45\n## 95 percent confidence interval:\n##  43.84137 46.58363\n## sample estimates:\n## mean of x \n##   45.2125\nshapiro.test(dissolving)## \n##  Shapiro-Wilk normality test\n## \n## data:  dissolving\n## W = 0.98023, p-value = 0.9641\nqqnorm(dissolving)\nqqline(dissolving)"},{},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"cs1-onesample-wilcoxon-signed-rank","chapter":"6 Wilcoxon signed-rank test","heading":"6 Wilcoxon signed-rank test","text":"test also considers single sample, however test (contrast one sample t-test) don‚Äôt assume parent distribution normally distributed. still need parent distribution (consequently sample) symmetric though. test look see median parent distributions differs significantly given hypothesised value (contrast t-test looks mean).","code":""},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"section-commands-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.1 Section commands","text":"New commands used section:, use fishlength dataset. one-sample Wilcoxon signed-rank test allows see median body length different specified value. want test whether data support hypothesis median body actually 20 mm. following null alternative hypotheses similar used one sample t-test:\\(H_0\\): median body length equal 20 mm (\\(\\mu =\\) 20).\\(H_1\\): median body length equal 20 mm (\\(\\mu \\neq\\) 20).use one-sample, two-tailed Wilcoxon signed-rank test see reject null hypothesis .","code":""},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"summarise-and-visualise-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.2 Summarise and visualise","text":"previous section, nothing really changed now (‚Äôre good start practical!)","code":""},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"implement-the-test-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.3 Implement the test","text":"Perform one-sample, two-tailed Wilcoxon signed-rank test:syntax identical one-sample t-test carried earlier.first argument must numerical vector data values.second argument must number median tested null hypothesis.third argument gives type alternative hypothesis must one two.sided, greater less.","code":"\nwilcox.test(fishlength, mu = 20, alternative = \"two.sided\")"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"interpreting-the-output-and-report-results-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.4 Interpreting the output and report results","text":"output now see console windowThe first two lines give warning (error) message regarding implementation test. can safely ignored case p-value small, essentially, ‚Äôs letting know data values identical . supposed happen dealing continuous data test, practice ‚Äôs something need worry .3rd line gives name test 4th line reminds dataset calledThe 5th line contains two key outputs test:\ncalculated statistic 67.5 (‚Äôll need reporting)\np-value 0.001222.\ncalculated statistic 67.5 (‚Äôll need reporting)p-value 0.001222.6th line simply states alternative hypothesisAgain, p-value ‚Äôre interested . gives probability us getting sample null hypothesis actually true.\n, case since p-value less 0.05 can reject null hypothesis state :one-sample Wilcoxon signed-rank test indicated median body length male guppies (\\(\\mu\\) = 18.8 mm) differs significantly 20 mm (V = 67.5, n = 29, p = 0.0012).sentence adequate concluding statement test write paper report. Note included (brackets) information median value group (\\(\\mu\\) = 18.8 mm), test statistic (V = 67.5), number observations (n = 29), p-value (p = 0.0012).","code":"## Warning in wilcox.test.default(fishlength, mu = 20, alternative = \"two.sided\"):\n## cannot compute exact p-value with ties## \n##  Wilcoxon signed rank test with continuity correction\n## \n## data:  fishlength\n## V = 67.5, p-value = 0.001222\n## alternative hypothesis: true location is not equal to 20"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"assumptions-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.5 Assumptions","text":"order use one-sample Wilcoxon rank-sum test analysis (results strictly valid) make two assumptions:parent distribution sample symmetricEach data point sample independent others. t-test common feature nearly statistical tests. Lack independence data really tough deal (impossible) large part proper experimental design ensuring .Whilst formal statistical tests symmetry opt simple visual inspection using boxplot histogram.Plot histogram boxplot data:get following plots:can see whilst distribution isn‚Äôt perfectly symmetric, neither heavily skewed left right can make call distribution symmetric enough us happy results test.","code":"\nhist(fishlength, breaks = 10)\n\nboxplot(fishlength)"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"exercise-1","chapter":"6 Wilcoxon signed-rank test","heading":"6.6 Exercise","text":"Exercise 6.1  Performing Wilcoxon signed-rank test:Analyse drug dataset using one-sample Wilcoxon signed-rank testDiscuss (virtual) neighbour two tests feel best suited data.matter case?Hypotheses\n\\(H_0\\) : median = 45s\\(H_1\\) : median \\(\\neq\\) 45sWilcoxon signed-rank testA one-sample Wilcoxon-signed rank test indicated median dissolving time drug significantly different 45 s (V=22, n=8 , p=0.64)Assumptions\nbox-plot previous exercise already know data symmetric enough test valid.Discussion\nterms choosing two test can see meet respective assumptions tests valid. case tests also agree terms conclusions .e.¬†average dissolving time (either mean median) doesn‚Äôt differ significantly proposed value 45 s.one answer doesn‚Äôt matter test use.Another answer pick test measures quantity ‚Äôre interested .e.¬†care medians use Wilcoxon test, whereas care means use t-test.final answer , since test valid prefer use test greater power. t-tests always power Wilcoxon tests (long ‚Äôre valid) report one. (‚Äôll talk last session power effectively capacity test detect significant difference - power better).","code":"\nwilcox.test(dissolving , mu=45 , alternative = \"two.sided\")## \n##  Wilcoxon signed rank exact test\n## \n## data:  dissolving\n## V = 22, p-value = 0.6406\n## alternative hypothesis: true location is not equal to 45"},{"path":"cs1-onesample-wilcoxon-signed-rank.html","id":"key-points","chapter":"6 Wilcoxon signed-rank test","heading":"6.7 Key points","text":"One-sample tests used single sample continuous dataWe can summarise data using summary() function visualise boxplot()t-test assumes data normally distributed independent otherThe Wilcoxon signed-rank test assume normal distribution, require independent samplesThe t.test() compares mean parent distribution differs hypothesised value, whereas wilcox.test() compares median.good way assessing assumptions visually check looking distribution hist() quantile-quantile plots qqnorm() qqline()","code":""},{},{"path":"cs1-two-sample.html","id":"cs1-two-sample","chapter":"7 Two-sample tests","heading":"7 Two-sample tests","text":"","code":""},{"path":"cs1-two-sample.html","id":"objectives-2","chapter":"7 Two-sample tests","heading":"7.1 Objectives","text":"QuestionsWhen perform two-sample test?two-sample tests assumptions?interpret present results tests?ObjectivesSet hypothesis two-sample continuous dataDetermine correct data format perform two-sample test RSummarise visualise dataCheck underlying assumptions (normality, homogeneity variance)able choose appropriate two-sample test run RBe able interpret report results","code":""},{"path":"cs1-two-sample.html","id":"purpose-and-aim-1","chapter":"7 Two-sample tests","heading":"7.2 Purpose and aim","text":"tests used two samples continuous data trying find samples came parent distribution . essentially boils finding difference means two samples.","code":""},{"path":"cs1-two-sample.html","id":"two-sample-choosing-a-test","chapter":"7 Two-sample tests","heading":"7.3 Choosing a test","text":"five key tests can used deal two samples. Choosing test use depends upon key assumptions satisfied sample data effectively boils answering four questions samples:samples normally distributed? (Yes/)big samples? (<30 data points >30 data points)samples paired? (Yes/)samples variance? (Yes/)two sets tests consider depending answers questions 1 2. data normally distributed big samples need look parametric tests. data normally distributed sample size small, need look non-parametric tests (see Figure 7.1. Questions 3 4 help pick specific test use, summarised Figure 7.2.\nFigure 7.1: Category test\n\nFigure 7.2: test use\nTesting whether sample comes normal distribution covered One-sample tests. need visualise data /use Shapiro-Wilk test.size sample makes things easier. maths (specifically due something called central limit theorem even going attempt touch upon ) large samples can use tests assume normality parent population (Student‚Äôs t-test, Welch‚Äôs t-test paired t-test) even parent populations certainly normal. really want understand exactly works, rigorous mathematics. , moment ‚Äôm going say ‚Äôs OK take facts faith just trust .Paired samples mean every data point one sample matching data point sample linked inextricable way. typical example involve group 20 test subjects measured experiment. Providing experiment didn‚Äôt anything fatal test subjects data consist two samples; 20 pre-experiment measurements 20 post-experiment measurements. However, test subjects used pre-experiment data point can matched exactly one post-experiment data points. sense two samples said ‚Äúpaired.‚Äùcouple tests (Bartlett‚Äôs test Levene‚Äôs test) can used see two samples come distributions variance. covered later section.Resampling techniques aren‚Äôt covered course require mixture statistical understanding programming skill. Ask demonstrator (Google üòâ) want know .","code":""},{"path":"cs1-two-sample.html","id":"tidy-data","chapter":"7 Two-sample tests","heading":"7.4 Tidy data","text":"two samples data can stored one three formats R:two separate vectors,stacked data frame,unstacked data frame/list.Two separate vectors case (hopefully) obvious.using data frame different options organise data. best way formatting data R using tidy data format.Tidy data following properties:variable columnEach observation rowEach value cellStacked form (long format data) data arranged way variable (thing measured) column. consider dataset containing meerkat weights (g) two different countries stacked format data look like:unstacked (wide format) form variable (measured thing) present one column. example, let‚Äôs say measured meerkat weight two countries period years. organise data way year measured values split country:tidy data easiest way analyses R strongly encourage start adopting format standard data collection processing.","code":""},{},{"path":"cs1-students-t-test.html","id":"cs1-students-t-test","chapter":"8 Student‚Äôs t-test","heading":"8 Student‚Äôs t-test","text":"test assume sample data sets normally distributed equal variance. test see means two samples differ significantly .language used section slightly different used section 4. Although language used section 4 technically correct, sentences somewhat onerous read. ‚Äôve opted easier reading style expense technical accuracy. Please feel free re-write section (leisure).","code":""},{"path":"cs1-students-t-test.html","id":"section-commands-2","chapter":"8 Student‚Äôs t-test","heading":"8.1 Section commands","text":"New commands used section:","code":""},{"path":"cs1-students-t-test.html","id":"data-and-hypotheses-1","chapter":"8 Student‚Äôs t-test","heading":"8.2 Data and hypotheses","text":"example, suppose now measure body lengths male guppies (mm) collected two rivers Trinidad; Aripo Guanapo. want test whether mean body length differs samples. form following null alternative hypotheses:\\(H_0\\): mean body length differ two groups (\\(\\mu = \\mu G\\))\\(H_1\\): mean body length differ two groups (\\(\\mu \\neq \\mu G\\))use two-sample, two-tailed t-test see can reject null hypothesis.use two-sample test now two samples.use two-tailed t-test want know data suggest true (population) means different one another rather one mean specifically bigger smaller .‚Äôre using Student‚Äôs t-test sample sizes big ‚Äôre assuming parent populations equal variance (can check later).data stored stacked format file data/raw/CS1-twosample.csv.Read R:","code":"\nrivers <- read.csv(\"data/raw/CS1-twosample.csv\")"},{"path":"cs1-students-t-test.html","id":"cs1-students-sumvisual","chapter":"8 Student‚Äôs t-test","heading":"8.3 Summarise and visualise","text":"Let‚Äôs summarise data‚Ä¶visualise :boxplot appear suggest two samples different means, moreover guppies Guanapo may smaller guppies Aripo. isn‚Äôt immediately obvious two populations don‚Äôt equal variances though, plough .","code":"\naggregate(length ~ river, data = rivers, summary)##     river length.Min. length.1st Qu. length.Median length.Mean length.3rd Qu.\n## 1   Aripo    17.50000       19.10000      20.10000    20.33077       21.30000\n## 2 Guanapo    11.20000       17.50000      18.80000    18.29655       19.70000\n##   length.Max.\n## 1    26.40000\n## 2    23.30000\nboxplot(length ~ river, data = rivers,\n        main = \"Male guppies\",\n        ylab = \"Length (mm)\")"},{"path":"cs1-students-t-test.html","id":"implement-test","chapter":"8 Student‚Äôs t-test","heading":"8.4 Implement test","text":"Perform two-sample, two-tailed, t-test:case, data stacked format:first argument must formula format: variables ~ categoryThe second argument must name data frameThe third argument gives type alternative hypothesis must one two.sided, greater lessThe fourth argument says whether variance two samples can assumed equal (Student‚Äôs t-test) unequal (Welch‚Äôs t-test)next section shows can perform exactly test data different (unstacked) format. potentially somewhat redundant (thorough depending point view). Probably best just anyway just case gain extra insight repetition (works rowers‚Ä¶)Convert data unstacked format repeat t test:","code":"\nt.test(length ~ river, data = rivers,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n# create a new object that contains the unstacked data\nuns_rivers <- unstack(rivers)\n\n# have a look at the data\nuns_rivers\n# perform the t-test\nt.test(uns_rivers$Guanapo, uns_rivers$Aripo,\n       alternative = \"two.sided\",\n       var.equal = TRUE)"},{"path":"cs1-students-t-test.html","id":"interpret-output-and-report-results","chapter":"8 Student‚Äôs t-test","heading":"8.5 Interpret output and report results","text":"Let‚Äôs look results t-test performed original (stacked) data frame:1st line gives name test 2nd line reminds dataset called, variables used.3rd line contains three key outputs test:\ncalculated t-value 3.8433 (need reporting)\n66 degrees freedom (need reporting)\np-value 0.0002754.\ncalculated t-value 3.8433 (need reporting)66 degrees freedom (need reporting)p-value 0.0002754.4th line simply states alternative hypothesis terms difference two sample means (testing two sample means different equivalent testing whether difference means equal zero).5th 6th lines give 95th confidence interval (don‚Äôt need know ).7th, 8th 9th lines give sample means group (20.33077 Aripo 18.29655 Guanapo) found earlier., p-value 3rd line ‚Äôre interested . Since p-value small (much smaller standard significance level) choose say ‚Äúunlikely two samples came parent distribution can reject null hypothesis‚Äù state :Student‚Äôs t-test indicated mean body length male guppies Guanapo river (18.29 mm) differs significantly mean body length male guppies Aripo river (20.33 mm) (t = 3.8433, df = 66, p = 0.0003).Now ‚Äôs conversation starter.","code":"## \n##  Two Sample t-test\n## \n## data:  length by river\n## t = 3.8433, df = 66, p-value = 0.0002754\n## alternative hypothesis: true difference in means between group Aripo and group Guanapo is not equal to 0\n## 95 percent confidence interval:\n##  0.9774482 3.0909868\n## sample estimates:\n##   mean in group Aripo mean in group Guanapo \n##              20.33077              18.29655"},{"path":"cs1-students-t-test.html","id":"assumptions-2","chapter":"8 Student‚Äôs t-test","heading":"8.6 Assumptions","text":"order use Student‚Äôs t-test (results strictly valid) make three assumptions:parent distributions samples taken normally distributed (lead sample data normally distributed ).data point samples independent others.parent distributions variance.example first assumption can ignored sample sizes large enough (maths, Aripo containing 2 Guanapo 2 samples). samples smaller use tests previous section.second point can nothing unless know data collected, ignore .third point regarding equality variance can tested using either Bartlett‚Äôs test (samples normally distributed) Levene‚Äôs test (samples normally distributed).\ngets bit trickier. Although don‚Äôt care samples normally distributed t-test valid (sample size big enough compensate), need know normally distributed order decide variance test use.perform Shapiro-Wilk test samples separately:can see whilst Guanapo data probably normally distributed (p = 0.1764 > 0.05), Aripo data unlikely normally distributed (p = 0.02802 < 0.05). Remember p-value gives probability observing sample parent population actually normally distributed.\nShapiro-Wilk test quite sensitive sample size. means large sample even small deviations normality cause sample fail test, whereas smaller samples allowed pass much larger deviations. Aripo data nearly 40 points compared Guanapo data much easier Aripo sample fail compared Guanapo data.","code":"\nshapiro.test(uns_rivers$Aripo)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_rivers$Aripo\n## W = 0.93596, p-value = 0.02802\nshapiro.test(uns_rivers$Guanapo)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_rivers$Guanapo\n## W = 0.94938, p-value = 0.1764"},{"path":"cs1-students-t-test.html","id":"exercise-2","chapter":"8 Student‚Äôs t-test","heading":"8.7 Exercise","text":"Exercise 8.1  Q-Q plots rivers dataCreate Q-Q plots two samples discuss neighbour see light results Shapiro-Wilk test.Q-Q plots mirror found Shapiro-Wilk tests: data Aripo pretty normally distributed, whereas assumption normality Guanapo data less certain.Remember statistical tests provide answers, merely suggest patterns. Human interpretation still crucial aspect .Nevertheless, Shapiro-Wilk test shown data normal enough order test equality variance use Levene‚Äôs test.\nLevene‚Äôs test included default R packages may require installation additional package called car (Companion Applied Regression).install car package, run following command console:Alternatively, go Tools > Install packages‚Ä¶ > Packages, type car press InstallWe can now perform Levene‚Äôs test:Ignore warning might get coercion factors (test needs create grouped variables work R versions 4.x onwards read data factors).key bit information 3rd line text Pr(>F). p-value (0.1876) test. tells us probability observing two samples come distributions variance. probability greater arbitrary significance level 0.05 can somewhat confident necessary assumptions carrying Student‚Äôs t-test two samples valid. (woohoo!)information :wanted carry Bartlett‚Äôs test (.e.¬†data sufficiently normally distributed) command :relevant p-value given 3rd line.","code":"\npar(mfrow=c(1,2))\nqqnorm(uns_rivers$Aripo, main = \"Aripo\")\nqqline(uns_rivers$Aripo, col = \"red\")\n\nqqnorm(uns_rivers$Guanapo, main = \"Guanapo\")\nqqline(uns_rivers$Guanapo, col = \"red\")\ninstall.packages(\"car\")\nleveneTest(length ~ river, data = rivers)## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  1  1.7732 0.1876\n##       66\nbartlett.test(length ~ river, data = rivers)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  length by river\n## Bartlett's K-squared = 4.4734, df = 1, p-value = 0.03443"},{"path":"cs1-students-t-test.html","id":"exercise-3","chapter":"8 Student‚Äôs t-test","heading":"8.8 Exercise","text":"Exercise 8.2  Serum cholesterol concentrations turtlesUsing following data, test null hypothesis male female turtles mean serum cholesterol concentrations.\nTable 8.1: Serum cholesterol (mg/100 ml\nWrite null alternative hypothesesChoose representation data (stacked unstacked) create csv fileImport data RSummarise visualise dataCheck assumptions (normality variance) using appropriate tests plotsPerform two-sample t-testWrite sentence summarises results found1. Hypotheses\\(H_0\\) : male mean \\(=\\) female mean\\(H_1\\) : male mean \\(\\neq\\) female mean2-4. Import Data, Summarise visualiseI‚Äôd always recommend storing data tidy, stacked format (fact can‚Äôt think situation want store data untidy, unstacked format!) example manually input data Excel following layout, saving data CSV file reading :Let‚Äôs summarise data‚Ä¶visualise data:always use plot summary assess three things:look like ‚Äôve loaded data correctly?\ntwo groups extreme values plots seem match dataset, ‚Äôm happy haven‚Äôt done anything massively wrong .\ntwo groups extreme values plots seem match dataset, ‚Äôm happy haven‚Äôt done anything massively wrong .think difference two groups?\nneed result formal test make sense given data, ‚Äôs important develop sense think going happen . Whilst ranges two groups suggests Female serum levels might higher males look things closely realise isn‚Äôt case. boxplot shows median values two groups virtually identical backed summary statistics calculated: medians 224.1, means fairly close (225.7 vs 224.2). Based , fact 13 observations total surprised test came back showing difference groups.\nneed result formal test make sense given data, ‚Äôs important develop sense think going happen . Whilst ranges two groups suggests Female serum levels might higher males look things closely realise isn‚Äôt case. boxplot shows median values two groups virtually identical backed summary statistics calculated: medians 224.1, means fairly close (225.7 vs 224.2). Based , fact 13 observations total surprised test came back showing difference groups.think assumptions?\nNormality looks bit worrying: whilst Male group appears nice symmetric (might normal), Female group appears quite skewed (since median much closer bottom top). ‚Äôll look carefully formal checks decided whether think data normal enough us use t-test.\nHomogeneity variance. stage spread data within group looks similar, potential skew Female group ‚Äôll want check assumptions carefully.\nNormality looks bit worrying: whilst Male group appears nice symmetric (might normal), Female group appears quite skewed (since median much closer bottom top). ‚Äôll look carefully formal checks decided whether think data normal enough us use t-test.Homogeneity variance. stage spread data within group looks similar, potential skew Female group ‚Äôll want check assumptions carefully.5. Check AssumptionsNormalityLet‚Äôs look normality groups separately. several ways getting serum values Males Females separately. ‚Äôll use unstacking method, use Shapiro-Wilk followed qqplots.p-values Shapiro-Wilk tests non-significant suggests data normal enough. bit surprising given saw boxplot two bits information can use reassure us.p-value Female group smaller Male group (suggesting Female group closer non-normal Male group) makes sense.Shapiro-Wilk test generally quite relaxed normality small sample sizes (notoriously strict large sample sizes). group 6 data points , data actually really, really skewed distribution. Given Female group 6 data points , ‚Äôs surprising Shapiro-Wilk test came back saying everything OK.results Q-Q plots echo ‚Äôve already seen Shapiro-Wilk analyses. Male group doesn‚Äôt look bad whereas Female group looks somewhat dodgy.Overall, assumption normality data doesn‚Äôt appear well met , bear mind data points group might just seeing pattern data due random chance rather underlying populations actually normally distributed. Personally, though ‚Äôd edge towards non-normal .Homogeneity VarianceIt‚Äôs clear whether data normal , isn‚Äôt clear test use . sensible approach hope agree (fingers crossed!)Bartlett‚Äôs test gives us:Levene‚Äôs test gives us:good news Levene Bartlett agree homogeneity variance two groups (thank goodness!).Overall, means ‚Äôre sure normality, homogeneity variance pretty good.6. Carry two-sample t-testBecause result Bartlett test know can carry two-sample Student‚Äôs t-test (opposed two-sample Welch‚Äôs t-test, ‚Äôre confused, see Figure 7.2)p-value 0.544, test tells insufficient evidence suggest means two groups different. suitable summary sentence :Student‚Äôs two-sample t-test indicated mean serum cholesterol level differ significantly Male Female turtles (t = 0.627, df = 11, p = 0.544).DiscussionIn reality, ambiguous normality assumption assessment, dataset actually carry two different tests; two-sample t-test equal variance Mann-Whitney U test. agreed wouldn‚Äôt matter much one reported (‚Äôd personally report short sentence say ‚Äôm wasn‚Äôt clear whether assumption normality met), acceptable report just one.","code":"\nturtle <- read.csv(\"data/examples/cs1-turtle.csv\")\n\nturtle##    serum    sex\n## 1  220.1   Male\n## 2  218.6   Male\n## 3  229.6   Male\n## 4  228.8   Male\n## 5  222.0   Male\n## 6  224.1   Male\n## 7  226.5   Male\n## 8  223.4 Female\n## 9  221.5 Female\n## 10 230.2 Female\n## 11 224.3 Female\n## 12 223.8 Female\n## 13 230.8 Female\naggregate(serum ~ sex , data = turtle, summary)##      sex serum.Min. serum.1st Qu. serum.Median serum.Mean serum.3rd Qu.\n## 1 Female   221.5000      223.5000     224.0500   225.6667      228.7250\n## 2   Male   218.6000      221.0500     224.1000   224.2429      227.6500\n##   serum.Max.\n## 1   230.8000\n## 2   229.6000\nboxplot(serum ~ sex , data = turtle)\nuns_turtle <- unstack(turtle, serum ~ sex)\nshapiro.test(uns_turtle$Male)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_turtle$Male\n## W = 0.94392, p-value = 0.6743\nshapiro.test(uns_turtle$Female)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_turtle$Female\n## W = 0.84178, p-value = 0.1349\npar(mfrow=c(1,2))\nqqnorm(uns_turtle$Male, main = \"Male\")\nqqline(uns_turtle$Male, col = \"red\")\nqqnorm(uns_turtle$Female, main = \"Female\")\nqqline(uns_turtle$Female, col = \"red\")\nbartlett.test(serum ~ sex, turtle)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  serum by sex\n## Bartlett's K-squared = 0.045377, df = 1, p-value = 0.8313\n# load if needed\n# library(car)\n\nleveneTest(serum ~ sex, turtle)## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  1  0.2434 0.6315\n##       11\nt.test(serum ~ sex , turtle,\n       alternative=\"two.sided\",\n       var.equal=TRUE)## \n##  Two Sample t-test\n## \n## data:  serum by sex\n## t = 0.62681, df = 11, p-value = 0.5436\n## alternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n## 95 percent confidence interval:\n##  -3.575759  6.423378\n## sample estimates:\n## mean in group Female   mean in group Male \n##             225.6667             224.2429"},{},{"path":"cs1-mannwhitney-u-test.html","id":"cs1-mannwhitney-u-test","chapter":"9 Mann-Whitney U test","heading":"9 Mann-Whitney U test","text":"test also compares two samples, however test (contrast Student‚Äôs t-test) don‚Äôt assume parent distributions normally distributed. order compare medians two groups still need parent distributions (consequently samples) shape variance. test look see medians two parent distributions differ significantly .","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"section-commands-3","chapter":"9 Mann-Whitney U test","heading":"9.1 Section commands","text":"new commands used section.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"data-and-hypotheses-2","chapter":"9 Mann-Whitney U test","heading":"9.2 Data and hypotheses","text":", use rivers dataset. want test whether median body length male guppies differs samples. form following null alternative hypotheses:\\(H_0\\): difference median body length two groups 0 (\\(\\mu - \\mu G = 0\\))\\(H_1\\): difference median body length two groups 0 (\\(\\mu - \\mu G \\neq 0\\))use two-tailed Mann-Whitney U test see can reject null hypothesis.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"summarise-and-visualise-2","chapter":"9 Mann-Whitney U test","heading":"9.3 Summarise and visualise","text":"previous section.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"implement-test-1","chapter":"9 Mann-Whitney U test","heading":"9.4 Implement test","text":"Perform two-tailed, Mann-Whitney U test:case, data tidy format:first argument must formula format: variable ~ categoryThe second argument must name data frameThe third argument gives type alternative hypothesis must one two.sided, greater less","code":"\nwilcox.test(length ~ river, data = rivers,\n            alternative = \"two.sided\")## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  length by river\n## W = 841, p-value = 0.0006464\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"cs1-mannwhitney-u-test.html","id":"interpret-output-and-report-results-1","chapter":"9 Mann-Whitney U test","heading":"9.5 Interpret output and report results","text":"may get warning message console stating compute exact p-value ties. just means data points exactly value affects internal mathematics slightly. However, given p-value small, something need worry .warning message:1st line gives name test 2nd line reminds dataset called, variables usedThe 3rd line contains two key outputs test:\ncalculated W-value 841 (‚Äôll use reporting)\np-value 0.0006464.\ncalculated W-value 841 (‚Äôll use reporting)p-value 0.0006464.4th line simply states alternative hypothesis terms difference two sample medians difference one distribution shifted relative .Given p-value less 0.05 can reject null hypothesis confidence level.\n, p-value 3rd line ‚Äôre interested . Since p-value small (much smaller standard significance level) choose say ‚Äúunlikely two samples came parent distribution can reject null hypothesis.‚Äùput completely, can state :Mann-Whitney test indicated median body length male guppies Guanapo river (18.8 mm) differs significantly median body length male guppies Aripo river (20.1 mm) (W = 841, p = 0.0006).","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"assumptions-3","chapter":"9 Mann-Whitney U test","heading":"9.6 Assumptions","text":"checked previously.","code":""},{"path":"cs1-mannwhitney-u-test.html","id":"exercise-4","chapter":"9 Mann-Whitney U test","heading":"9.7 Exercise","text":"Exercise 9.1  Analyse turtle dataset using Mann Whitney test.follow process Student‚Äôs t-test.Hypotheses\\(H_0\\) : male median \\(=\\) female median\\(H_1\\) : male median \\(\\neq\\) female medianSummarise visualiseThis .AssumptionsWe‚Äôve already checked variances two groups similar, ‚Äôre OK . Whilst Mann-Whitney test doesn‚Äôt require normality symmetry distributions require distributions shape. example, just handful data points group, ‚Äôs quite hard make call one way another. advice case say unless ‚Äôs obvious distributions different can just allow assumption pass, ‚Äôre going see obvious differences distribution shape considerably data points .Carry Mann-Whitney testThis gives us exactly conclusion got two-sample t-test .e. isn‚Äôt significant difference two groups.Mann-Whitney test indicated wasn‚Äôt significant difference median Serum Cholesterol levels male female turtles (W = 26, p = 0.534)","code":"\nwilcox.test(serum ~ sex, data = turtle,\n            alternative = \"two.sided\")## \n##  Wilcoxon rank sum exact test\n## \n## data:  serum by sex\n## W = 26, p-value = 0.5338\n## alternative hypothesis: true location shift is not equal to 0"},{},{"path":"cs1-paired-two-sample-t-test.html","id":"cs1-paired-two-sample-t-test","chapter":"10 Paired two-sample t-test","heading":"10 Paired two-sample t-test","text":"paired t-test used two samples continuous data can paired (examples sort data weights individuals diet). test applicable number paired points within samples large (>30) , number points small, test also works parent distributions normally distributed.","code":""},{"path":"cs1-paired-two-sample-t-test.html","id":"section-commands-4","chapter":"10 Paired two-sample t-test","heading":"10.1 Section commands","text":"new commands section.","code":""},{"path":"cs1-paired-two-sample-t-test.html","id":"data-and-hypotheses-3","chapter":"10 Paired two-sample t-test","heading":"10.2 Data and hypotheses","text":"example, suppose measure cortisol levels 20 adult females (nmol/l) first thing morning evening. want test whether cortisol levels differs two measurement times. initially form following null alternative hypotheses:\\(H_0\\): difference cortisol level times (\\(\\mu M = \\mu E\\))\\(H_1\\): difference cortisol levels times (\\(\\mu M \\neq \\mu E\\))use two-sample, two-tailed paired t-test see can reject null hypothesis.use two-sample test now two samplesWe use two-tailed t-test want know data suggest true (population) means different one another rather one mean specifically bigger smaller otherWe use paired test data point first sample can linked another data point second sample connecting factorWe‚Äôre using t-test ‚Äôre assuming parent populations normal equal variance (‚Äôll check bit)data stored unstacked format file ‚ÄúCS1-twopaired.csv.‚Äù\nRead R:","code":"\ncortisol <- read.csv(\"data/raw/CS1-twopaired.csv\")"},{"path":"cs1-paired-two-sample-t-test.html","id":"summarise-and-visualise-3","chapter":"10 Paired two-sample t-test","heading":"10.3 Summarise and visualise","text":"box plot capture cortisol level individual subject changed though. can explore individual changes morning evening creating boxplot differences two times measurement.differences cortisol levels appear much less zero, (meaning evening cortisol levels appear much lower morning ones). expect test give pretty significant result.","code":"\nsummary(cortisol)##     morning         evening     \n##  Min.   :146.1   Min.   : 60.1  \n##  1st Qu.:266.6   1st Qu.:137.8  \n##  Median :320.5   Median :188.9  \n##  Mean   :313.5   Mean   :197.4  \n##  3rd Qu.:359.7   3rd Qu.:260.8  \n##  Max.   :432.5   Max.   :379.3\nboxplot(cortisol, ylab = \"Level (nmol/l)\")\n# calculate the difference between evening and morning values\nchangeCor <- cortisol$evening - cortisol$morning\n\nboxplot(changeCor, ylab = \"Change in cortisol (nmol/l)\")"},{"path":"cs1-paired-two-sample-t-test.html","id":"implement-test-2","chapter":"10 Paired two-sample t-test","heading":"10.4 Implement test","text":"Perform two-sample, two-tailed, paired t-test:first two arguments must vectors containing numerical data samplesThe third argument gives type alternative hypothesis must one two.sided, greater lessThe fourth argument says data paired","code":"\nt.test(cortisol$evening, cortisol$morning,\n       alternative = \"two.sided\", paired = TRUE)"},{"path":"cs1-paired-two-sample-t-test.html","id":"interpret-output-and-report-results-2","chapter":"10 Paired two-sample t-test","heading":"10.5 Interpret output and report results","text":"perspective value interested 3rd line (p-value = 5.288e10-5). Given substantially less 0.05 can reject null hypothesis state:two-tailed, paired t-test indicated cortisol level adult females differed significantly morning (313.5 nmol/l) evening (197.4 nmol/l) (t = -5.1833, df = 19, p = 5.3x10-5).","code":"## \n##  Paired t-test\n## \n## data:  cortisol$evening and cortisol$morning\n## t = -5.1833, df = 19, p-value = 5.288e-05\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -162.96038  -69.20962\n## sample estimates:\n## mean of the differences \n##                -116.085"},{"path":"cs1-paired-two-sample-t-test.html","id":"assumptions-4","chapter":"10 Paired two-sample t-test","heading":"10.6 Assumptions","text":"exercise!","code":""},{"path":"cs1-paired-two-sample-t-test.html","id":"exercise-5","chapter":"10 Paired two-sample t-test","heading":"10.7 Exercise","text":"Exercise 10.1  Checking assumptionsCheck assumptions necessary paired t-test.\npaired t-test appropriate test?paired test really just one-sample test disguise. actually don‚Äôt care much distributions individual groups. Instead care properties differences. paired t-test valid dataset, need differences morning evening values normally distributed.Let‚Äôs check Shapiro-Wilk Q-Q plots using changeCor variable created earlier.Shapiro-Wilk test says data normal enough whilst Q-Q plot mostly fine, suggestion snaking bottom left. ‚Äôm actually OK suggestion snaking actually due single point (last point left). cover point thumb (finger choice) remaining points Q-Q plot look pretty damn good, suggestion snaking actually driven single point (can happen chance). ‚Äôm actually happy assumption normality well met case. single point check useful thing remember assessing diagnostic plots., yep, paired t-test appropriate dataset.","code":"\nshapiro.test(changeCor)## \n##  Shapiro-Wilk normality test\n## \n## data:  changeCor\n## W = 0.92362, p-value = 0.1164\nqqnorm(changeCor)\nqqline(changeCor, col = \"red\")"},{},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"cs1-twosample-wilcoxon-signed-rank","chapter":"11 Wilcoxon signed-rank test","heading":"11 Wilcoxon signed-rank test","text":"Wilcoxon signed-rank test alternative paired t-test. require data drawn normal distributions, require distribution differences symmetric. ‚Äôre effectively testing see median differences two samples differs significantly zero.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"section-commands-5","chapter":"11 Wilcoxon signed-rank test","heading":"11.1 Section commands","text":"new commands section.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"data-and-hypotheses-4","chapter":"11 Wilcoxon signed-rank test","heading":"11.2 Data and hypotheses","text":"Using cortisol dataset form following null alternative hypotheses:\\(H_0\\): median difference cortisol levels two groups 0 (\\(\\mu M = \\mu E\\))\\(H_1\\): median difference cortisol levels two groups 0 (\\(\\mu M \\neq \\mu E\\))use two-tailed Wilcoxon signed-rank test see can reject null hypothesis.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"summarise-and-visualise-4","chapter":"11 Wilcoxon signed-rank test","heading":"11.3 Summarise and visualise","text":"Already implemented previously.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"implement-test-3","chapter":"11 Wilcoxon signed-rank test","heading":"11.4 Implement test","text":"Perform two-tailed, Wilcoxon signed-rank test:first two arguments must two samples numerical vector formatThe second argument gives type alternative hypothesis must one two.sided, greater lessThe third argument indicates test paired","code":"\nwilcox.test(cortisol$morning, cortisol$evening,\n            alternative = \"two.sided\", paired = TRUE)"},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"interpret-output-and-report-results-3","chapter":"11 Wilcoxon signed-rank test","heading":"11.5 Interpret output and report results","text":"p value given 3rd line (p-value = 0.0001678). Given less 0.05 can still reject null hypothesis.two-tailed, Wilcoxon signed-rank test indicated median cortisol level adult females differed significantly morning (320.5 nmol/l) evening (188.9 nmol/l) (V = 197, p = 0.00017).","code":"## \n##  Wilcoxon signed rank exact test\n## \n## data:  cortisol$morning and cortisol$evening\n## V = 197, p-value = 0.0001678\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"assumptions-5","chapter":"11 Wilcoxon signed-rank test","heading":"11.6 Assumptions","text":"checked previously.","code":""},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"exercise-6","chapter":"11 Wilcoxon signed-rank test","heading":"11.7 Exercise","text":"Exercise 11.1  Deer legsUsing following data, test null hypothesis fore hind legs deer length.\nTable 11.1: Deer leg length (cm)\nresults provide evidence suggest fore- hind-leg length differ deer?Write null alternative hypothesesChoose representation data (stacked unstacked) create csv fileImport data RSummarise visualise dataPerform two-sample paired t-testPerform Wilcoxon signed-rank testNow check assumptions (normality variance) using appropriate testsDiscuss (virtual) neighbour test appropriate?Write sentence summarise results found1. Hypotheses\\(H_0\\) : foreleg average (mean median) \\(=\\) hindleg average (mean median)\\(H_1\\) : foreleg average \\(\\neq\\) hindleg average2-4. Import Data, Summarise visualiseI always recommend storing data stacked format even example, even though case might seem easier store data unstacked format (pretty much time even sensible option). example manually input data excel following layout:ordering data important ; first hindleg row corresponds first foreleg row, second second . indicate use id column, observation unique ID.Let‚Äôs look data see can see.looks though might difference legs, hindlegs longer forelegs. However, representation obscures fact paired data. really need look difference leg length deer:gives us much clearer picture. looks though hindlegs 4 cm longer forelegs, average. also suggests leg differences might normally distributed (data look bit skewed).5. Perform two-sample t-testThe paired t-test assumes data stored exactly entered (.e.¬†first hindleg row matches first foreleg row). apparently see significant difference.6. Perform paired Wilcoxon testThe paired Wilcoxon test makes assumptions order data paired t-test. significant difference.7. Check assumptionsWe need consider distribution difference leg lengths rather individual distributions.Shapiro-Wilk test Q-Q plot suggest difference data aren‚Äôt normally distributed, rules paired t-test. therefore consider paired Wilcoxon test next. Remember test requires distribution differences symmetric, whereas box-plot suggested data much skewed.8. ConclusionsSo, frustratingly, neither tests appropriate dataset. differences fore- hind leg lengths neither normal enough paired t-test symmetric enough Wilcoxon test don‚Äôt enough data just use t-test (‚Äôd need 30 points ). situation? Well answer aren‚Äôt actually traditional statistical tests valid dataset stands!two options available someone:try transforming raw data (take logs, square root, reciprocals) hope one leads modified dataset satisfies assumptions one tests ‚Äôve covered, oruse permutation test approach (work beyond scope course).reason included example first practical purely illustrate simple dataset apparently clear message (leg lengths differ within deer) can intractable. don‚Äôt need complex datasets go beyond capabilities classical statistics.Jeremy Clarkson put :bombshell, ‚Äôs time end. Goodnight!","code":"\ndeer <- read.csv(\"data/examples/cs1-deer.csv\")\naggregate(length ~ leg, data = deer, summary)##       leg length.Min. length.1st Qu. length.Median length.Mean length.3rd Qu.\n## 1 foreleg      136.00         138.25        142.00      141.40         144.50\n## 2 hindleg      140.00         142.00        144.00      144.70         147.50\n##   length.Max.\n## 1      147.00\n## 2      150.00\nboxplot(length ~ leg, data = deer)\nuns_deer <- unstack(deer, length ~ leg)\ndeerDiff <- uns_deer$hindleg - uns_deer$foreleg\nsummary(deerDiff)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    -3.0     2.5     4.5     3.3     5.0     6.0\nboxplot(deerDiff)\nt.test(length ~ leg, data = deer, paired = TRUE)## \n##  Paired t-test\n## \n## data:  length by leg\n## t = -3.4138, df = 9, p-value = 0.007703\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -5.486752 -1.113248\n## sample estimates:\n## mean of the differences \n##                    -3.3\nwilcox.test(length ~ leg, data = deer, paired = TRUE)## Warning in wilcox.test.default(x = c(138L, 136L, 147L, 139L, 143L, 141L, :\n## cannot compute exact p-value with ties## \n##  Wilcoxon signed rank test with continuity correction\n## \n## data:  length by leg\n## V = 4, p-value = 0.01859\n## alternative hypothesis: true location shift is not equal to 0\nshapiro.test(deerDiff)## \n##  Shapiro-Wilk normality test\n## \n## data:  deerDiff\n## W = 0.81366, p-value = 0.02123\nqqnorm(deerDiff)\nqqline(deerDiff, col = \"red\")"},{"path":"cs1-twosample-wilcoxon-signed-rank.html","id":"key-points-1","chapter":"11 Wilcoxon signed-rank test","heading":"11.8 Key points","text":"use two-sample tests see two samples continuous data come parent distributionThis essentially boils testing mean median differs two samplesThere 5 key two-sample tests: Student‚Äôs t-test, Welch‚Äôs t-test, Mann-Whitney U test, paired t-test Wilcoxon signed-rank testWhich one use depends normality distribution, sample size, paired unpaired data variance samplesParametric tests used data normally distributed sample size largeNon-parametric tests used data normally distributed sample size smallEquality variance determines test appropriateYou can ask 3 questions determine test:\ndata paired?\nneed parametric non-parametric test\ncan assume equality variance?\ndata paired?need parametric non-parametric testcan assume equality variance?","code":""},{},{"path":"cs2-intro.html","id":"cs2-intro","chapter":"12 Introduction","heading":"12 Introduction","text":"","code":""},{"path":"cs2-intro.html","id":"objectives-3","chapter":"12 Introduction","heading":"12.1 Objectives","text":"Aim: introduce R commands analysing single categorical predictors.end practical participants able perform following statistical analyses:One-way Analysis Variance (ANOVA)Kruskal-Wallis testFor , participants able :Perform test RInterpret outputCheck assumptions testCarry post-hoc test appropriateThe tests covered practical :One-way ANOVAKruskall-Wallis test","code":""},{"path":"cs2-intro.html","id":"background-1","chapter":"12 Introduction","heading":"12.2 Background","text":"practical focuses implementation various statistical tests relating categorical predictors. boil ANOVA Kruskal-Wallis (non-parametric alternative).\n, focus underlying theory tests (although demonstrators happy answer questions may ).test section :explains purpose test,explains visualise data,explains perform test R,explains interpret output report results, andexplains assess assumptions required perform test.","code":""},{},{"path":"introduction-1.html","id":"introduction-1","chapter":"13 Introduction","heading":"13 Introduction","text":"practical introducing can compare data different groups.","code":""},{"path":"introduction-1.html","id":"cs2-datasets","chapter":"13 Introduction","heading":"13.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"cs2-anova.html","id":"cs2-anova","chapter":"14 ANOVA","heading":"14 ANOVA","text":"","code":""},{"path":"cs2-anova.html","id":"objectives-4","chapter":"14 ANOVA","heading":"14.1 Objectives","text":"QuestionsHow ‚Ä¶‚Ä¶ObjectivesBe able ‚Ä¶Use‚Ä¶","code":""},{"path":"cs2-anova.html","id":"purpose-and-aim-2","chapter":"14 ANOVA","heading":"14.2 Purpose and aim","text":"Analysis variance ANOVA test can used multiple samples continuous data. Whilst possible use ANOVA two samples, generally used three groups. used find samples came parent distributions mean. can thought generalisation two-sample Student‚Äôs t-test.","code":""},{"path":"cs2-anova.html","id":"section-commands-6","chapter":"14 ANOVA","heading":"14.3 Section commands","text":"New commands used section.","code":""},{"path":"cs2-anova.html","id":"data-and-hypotheses-5","chapter":"14 ANOVA","heading":"14.4 Data and hypotheses","text":"example, suppose measure feeding rate oyster catchers (shellfish per hour) three sites characterised degree shelter wind, imaginatively called exposed (E), partially sheltered (P) sheltered (S). want test whether data support hypothesis feeding rates don‚Äôt differ locations. form following null alternative hypotheses:\\(H_0\\): mean feeding rates three sites \\(\\mu E = \\mu P = \\mu S\\)\\(H_1\\): mean feeding rates equal.use one-way ANOVA test check .use one-way ANOVA test one predictor variable (categorical variable location).‚Äôre using ANOVA two groups don‚Äôt know better yet respect exact assumptions.data stored file CS2-oystercatcher.csv.","code":""},{"path":"cs2-anova.html","id":"summarise-and-visualise-5","chapter":"14 ANOVA","heading":"14.5 Summarise and visualise","text":"First read data.Next summarise data visualise . quick peek first rows data head() can see data organised.data stacked format. first column contains information feeding rates called feeding. second column categorical data type site called site.Looking data, appears noticeable difference feeding rates three sites. probably expect reasonably significant statistical result .","code":"\noystercatcher <- read.csv(\"data/raw/CS2-oystercatcher.csv\")\nhead(oystercatcher)##   feeding    site\n## 1    14.2 Exposed\n## 2    16.5 Exposed\n## 3     9.3 Exposed\n## 4    15.1 Exposed\n## 5    13.4 Exposed\n## 6    18.4 Partial\naggregate(feeding ~ site, data = oystercatcher, summary)##        site feeding.Min. feeding.1st Qu. feeding.Median feeding.Mean\n## 1   Exposed         9.30           13.40          14.20        13.70\n## 2   Partial        13.00           16.50          17.40        17.14\n## 3 Sheltered        21.50           22.20          24.10        23.64\n##   feeding.3rd Qu. feeding.Max.\n## 1           15.10        16.50\n## 2           18.40        20.40\n## 3           25.10        25.30\nboxplot(feeding ~ site, data = oystercatcher)"},{"path":"cs2-anova.html","id":"implement-test-4","chapter":"14 ANOVA","heading":"14.6 Implement test","text":"Perform ANOVA test data:first line fits linear model data (.e.¬†finds means three groups calculates load intermediary data need statistical analysis) stores information R object (‚Äôve called lm_oystercatchers, can call like). second line actually carries ANOVA analysis.first argument must formula format: response ~ predictorIf data stored stacked format, second argument must name data frameThe anova() command takes linear model object main argument","code":"\nlm_oystercatcher <- lm(feeding ~ site, data = oystercatcher)\n\nanova(lm_oystercatcher)"},{"path":"cs2-anova.html","id":"interpret-output-and-report-results-4","chapter":"14 ANOVA","heading":"14.7 Interpret output and report results","text":"output now see console window:1st line just tells ANOVA testThe 2nd line tells response variable (case feeding)3rd, 4th 5th lines ANOVA table contain useful values:\nDf column contains degrees freedom values row, 2 12 (‚Äôll need reporting)\nF value column contains F statistic, 21.508 (‚Äôll need reporting).\np-value 0.0001077 number directly Pr(>F) 4th line.\nvalues table (Sum Sq Mean Sq) columns used calculate F statistic don‚Äôt need know .\nDf column contains degrees freedom values row, 2 12 (‚Äôll need reporting)F value column contains F statistic, 21.508 (‚Äôll need reporting).p-value 0.0001077 number directly Pr(>F) 4th line.values table (Sum Sq Mean Sq) columns used calculate F statistic don‚Äôt need know .6th line symbolic codes represent big (small) p-value ; , p-value smaller 0.001 *** symbol next (). Whereas p-value 0.01 0.05 simply * character next , etc. Thankfully can cope actual numbers don‚Äôt need short-hand code determine reporting experiments (please tell ‚Äôs true‚Ä¶!), p-value ‚Äôre interested shows us probability getting samples null hypothesis actually true.Since p-value small (much smaller standard significance level 0.05) can say ‚Äúunlikely three samples came parent distribution‚Äù can reject null hypothesis state :one-way ANOVA showed mean feeding rate oystercatchers differed significantly locations (F = 21.51, df = 2, 12, p = 0.00011).Note included (brackets) information test statistic (F = 21.51), degrees freedom (df = 2, 12), p-value (p = 0.00011).","code":"## Analysis of Variance Table\n## \n## Response: feeding\n##           Df  Sum Sq Mean Sq F value    Pr(>F)    \n## site       2 254.812 127.406  21.508 0.0001077 ***\n## Residuals 12  71.084   5.924                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"cs2-anova.html","id":"assumptions-6","chapter":"14 ANOVA","heading":"14.8 Assumptions","text":"use ANOVA test, make three assumptions:parent distributions samples taken normally distributedEach data point samples independent othersThe parent distributions varianceIn similar way two-sample tests consider normality equality variance assumptions using tests graphical inspection (ignore independence assumption).1. NormalityUnstack data perform Shapiro-Wilk test group separately.output now see console window:can see three groups appear normally distributed good.ANOVA however, considering group turn often considered quite excessive , cases, sufficient consider normality combined set residuals data. ‚Äôll explain residuals properly next session effectively difference data point group mean. residuals can obtained directly linear model fitted earlier.Extract residuals data check normality:, can see combined residuals three groups appear normally distributed (expected given normally distributed individually!)2. Equality VarianceWe now test equality variance using Bartlett‚Äôs test (since ‚Äôve just found individual groups normally distributed).Perform Bartlett‚Äôs test data:relevant p-value given 3rd line. see group appear variance.3. Graphical Interpretation Diagnostic PlotsR provides convenient set graphs allow us assess assumptions graphically. simply ask R plot lm object created, can see diagnostic plots.Create standard set diagnostic plots:second line creates three diagnostic plots (actually tries create four plots can‚Äôt dataset ‚Äôll also see warning text output screen (something hat values). ‚Äôll go next session ‚Äôs easier explain).example, two plots (top-left bottom-left) show effectively thing: distribution data group look like. allow informal check equality variance assumption.\ntop-left graph want data symmetric 0 horizontal line spread (please ignore red line; unhelpful addition graphs).\nbottom-left graph, look red line want approximately horizontal.\ntop-left graph want data symmetric 0 horizontal line spread (please ignore red line; unhelpful addition graphs).bottom-left graph, look red line want approximately horizontal.top-right graph familiar Q-Q plot used previously assess normality, looks combined residuals groups (much way looked Shapiro-Wilk test combined residuals).can see graphs much line ‚Äôve just looked using test, reassuring. groups appear spread data, whilst QQ-plot isn‚Äôt perfect, appears assumption normality allright.stage, point nearly always stick graphical method assessing assumptions test. Assumptions rarely either completely met met always degree personal assessment.Whilst formal statistical tests (like Shapiro) technically fine, can often create false sense things absolutely right wrong spite fact still probabilistic statistical tests. exercises using approaches whilst gain confidence experience interpreting graphical output whilst absolutely fine use future strongly recommend don‚Äôt rely solely statistical tests isolation.","code":"\nuns_oyster <- unstack(oystercatcher)\n\nshapiro.test(uns_oyster$Exposed)\nshapiro.test(uns_oyster$Partial)\nshapiro.test(uns_oyster$Sheltered)## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_oyster$Exposed\n## W = 0.9151, p-value = 0.4988## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_oyster$Partial\n## W = 0.96913, p-value = 0.8697## \n##  Shapiro-Wilk normality test\n## \n## data:  uns_oyster$Sheltered\n## W = 0.88532, p-value = 0.3341\nresid_oyster <- residuals(lm_oystercatcher)\n\nshapiro.test(resid_oyster)## \n##  Shapiro-Wilk normality test\n## \n## data:  resid_oyster\n## W = 0.93592, p-value = 0.3338\nbartlett.test(feeding ~ site, data = oystercatcher)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  feeding by site\n## Bartlett's K-squared = 0.90632, df = 2, p-value = 0.6356\n# create a neat 2x2 window\npar(mfrow = c(2,2))\n# create the diagnostic plots\nplot(lm_oystercatcher)\n# and return the window back to normal\npar(mfrow = c(1,1))## hat values (leverages) are all = 0.2\n##  and there are no factor predictors; no plot no. 5"},{"path":"cs2-anova.html","id":"post-hoc-testing","chapter":"14 ANOVA","heading":"14.9 Post-hoc testing","text":"One drawback using ANOVA test tests see means , get significant result using ANOVA can say means , rather anything pairs groups differ. example, consider following boxplot three samples.group random sample 20 points normal distribution variance 1. Groups 1 2 come parent population mean 0 whereas group 3 come parent population mean 2. data clearly satisfy assumptions ANOVA test.1. Read data plot2. Test significant difference group meansHere p-value 2.39x10-7 test conclusively rejected hypothesis means equal.However, due sample means different, rather just one groups different others. order drill investigate use new test called Tukey‚Äôs range test (Tukey‚Äôs honest significant difference test ‚Äì always makes think terrible cowboy/western dialogue). compare groups pairwise fashion reports whether significant difference exists.3. Performing Tukey‚Äôs test dataThe first argument repeats ANOVA using different function ‚Äòaov().‚Äô store output function R object called aov_tukey.\nNote TukeyHSD() function takes output aov() function argument raw data.bottom three lines contain information want. final column (entitled p adj) p-value ‚Äôre looking . null hypothesis case difference mean two groups. can see first line shows isn‚Äôt significant difference sample1 sample2 2nd 3rd lines show significant difference sample1 sample3, well sample2 sample3. matches expected based boxplot.4. AssumptionsWhen use Tukey‚Äôs range test matter debate (strangely enough lot statistical analysis techniques currently matters opinion rather mathematical fact ‚Äì explain little whole field appears bloody confusing!)people claim perform Tukey‚Äôs range test (post-hoc tests) preceding ANOVA test showed significant difference groups ANOVA test shown significant differences groups stop .people say rubbish can hell like, like long tell people .background rather involved one reasons debate prevent -called data-dredging p-hacking. scientists/analysts fixated getting ‚Äúsignificant‚Äù result perform huge variety statistical techniques find one shows data significant (particular problem psychological studies ‚Äì point fingers though, working hard sort stuff . Kudos!).Whether use post-hoc testing depend experimental design questions ‚Äôre attempting answer.Tukey‚Äôs range test, decide use , requires three assumptions ANOVA test:Normality distributionsEquality variance groupsIndependence observations","code":"\ntukey <- read.csv(\"data/raw/CS2-tukey.csv\")\nboxplot(response ~ group, data = tukey)\nlm_tukey <- lm(response ~ group, data = tukey)\n\nanova(lm_tukey)## Analysis of Variance Table\n## \n## Response: response\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## group      2 33.850 16.9250   20.16 2.392e-07 ***\n## Residuals 57 47.854  0.8395                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\naov_tukey <- aov(response ~ group, data = tukey)\n\nTukeyHSD(aov_tukey)##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = response ~ group, data = tukey)\n## \n## $group\n##                      diff        lwr      upr     p adj\n## sample2-sample1 0.3037563 -0.3934982 1.001011 0.5498005\n## sample3-sample1 1.7233591  1.0261047 2.420614 0.0000005\n## sample3-sample2 1.4196028  0.7223484 2.116857 0.0000246"},{"path":"cs2-anova.html","id":"exercise-7","chapter":"14 ANOVA","heading":"14.10 Exercise","text":"Exercise 14.1  Juvenile lobster weightJuvenile lobsters aquaculture grown three different diets (fresh mussels, semi-dry pellets dry flakes). nine weeks, wet weight :evidence diet affects growth rate lobsters?Write null alternative hypothesesImport data R\ndata stored file data/raw/CS2-lobsters.csv\ndata stored file data/raw/CS2-lobsters.csvSummarise visualise dataCheck assumptions using appropriate tests graphical analysesPerform ANOVA testWrite sentence summarise results foundPerform post-hoc test report findings1. Hypotheses\\(H_0\\) : means equal\\(H_1\\) : means equal2-3. Import Data, summarise visualiseThe data stored .csv file stacked format columns called weight diet.Let‚Äôs look data see can see.always use plot summary assess three things:load data properly?see three groups reasonable values. aren‚Äôt data points obviously wrong (negative, zero massively big) right number groups. looks didn‚Äôt anything obviously wrong.expect result statistical test?Whilst Mussels group look higher two groups, Pellets Flakes appear almost identical terms average values, ‚Äôs quite bit overlap Mussels group. non-significant result likely answer, surprised see significant p-value - especially given small sample size .think assumptions?groups appear mainly symmetric (although Pellets bit weird) ‚Äôre immediately massively worried lack normality. , Flakes Mussels appear similar variances ‚Äôs bit hard decide ‚Äôs going Pellets. ‚Äôs hard say ‚Äôs going assumptions ‚Äôll wait see tests say.4. Explore AssumptionsNormalityWe‚Äôll really thorough consider normality group separately jointly using Shapiro-Wilk test, well looking Q-Q plot. reality, examples , ‚Äôll use Q-Q plot.‚Äôll need unstack data use Shapiro-Wilk test individual groups:Flakes Mussels fine, , suspected earlier, Pellets appears marginally significant Normality test result.Let‚Äôs look Shapiro-Wilk test data together:hand says everything fine. Let‚Äôs look Q-Q-plot:, ‚Äôve used extra argument normal diagnostic plots call. default option plot 4 diagnostic plots, can tell R plot specific one. (want know look plot.lm help documentation using ?plot.lm). ‚Äôve asked R plot Q-Q plot = 2 argument.Q-Q plot looks OK, perfect, good enough us confidence normality data.Overall, ‚Äôd happy assumption normality adequately well met . suggested lack normality Pellets just significant take account 5 data points group. lot points group, Q-Q plot considerably worse wouldn‚Äôt confident.Equality VarianceWe‚Äôll consider Bartlett test ‚Äôll look diagnostic plots .code, ‚Äôve used trick argument plot two diagnostic plots relate equality variance (residuals vs fitted scale-location).three methods agree isn‚Äôt issues equality variance:Bartlett test p-value large non-significantthe spread points three groups residuals vs fitted graph roughly samethe red line scale-location graph pretty horizontalOverall, assumption pretty well met.5. Carry one-way ANOVAWith assumptions normality equality variance met can confident one-way ANOVA appropriate test.6. ResultA one-way ANOVA test indicated mean weight juvenile lobsters differ significantly diets (F = 1.64, df = 2,15, p = 0.23).7. Post-hoc testing TukeyHere can see actually, significant difference pairs groups dataset.want reiterate carrying post-hoc test getting non-significant result ANOVA something think carefully depends research question .research question :diet affect lobster weight? effect diet lobster weight?got non-significant result ANOVA test just stopped answer. Going digging ‚Äúsignificant‚Äù results running tests main factor contributes towards lack reproducibility research.hand research question :specific diets better worse lobster weight others?probably just skipped one-way ANOVA test entirely just jumped straight Tukey‚Äôs range test, important point result one-way ANOVA test doesn‚Äôt preclude carrying Tukey test.","code":"\nlobsters <- read.csv(\"data/raw/CS2-lobsters.csv\")##    weight    diet\n## 1   151.6 Mussels\n## 2   132.1 Mussels\n## 3   104.2 Mussels\n## 4   153.5 Mussels\n## 5   132.0 Mussels\n## 6   119.0 Mussels\n## 7   161.9 Mussels\n## 8   117.7 Pellets\n## 9   110.8 Pellets\n## 10  128.6 Pellets\n## 11  110.1 Pellets\n## 12  175.2 Pellets\n## 13  101.8  Flakes\n## 14  102.9  Flakes\n## 15   90.4  Flakes\n## 16  132.8  Flakes\n## 17  129.3  Flakes\n## 18  129.4  Flakes\naggregate(weight ~ diet, data = lobsters, summary)##      diet weight.Min. weight.1st Qu. weight.Median weight.Mean weight.3rd Qu.\n## 1  Flakes     90.4000       102.0750      116.1000    114.4333       129.3750\n## 2 Mussels    104.2000       125.5000      132.1000    136.3286       152.5500\n## 3 Pellets    110.1000       110.8000      117.7000    128.4800       128.6000\n##   weight.Max.\n## 1    132.8000\n## 2    161.9000\n## 3    175.2000\nboxplot(weight ~ diet, data = lobsters)\nlobst_uns <- unstack(lobsters, weight ~ diet)\nshapiro.test(lobst_uns$Flakes)## \n##  Shapiro-Wilk normality test\n## \n## data:  lobst_uns$Flakes\n## W = 0.84368, p-value = 0.1398\nshapiro.test(lobst_uns$Mussels)## \n##  Shapiro-Wilk normality test\n## \n## data:  lobst_uns$Mussels\n## W = 0.94784, p-value = 0.71\nshapiro.test(lobst_uns$Pellets)## \n##  Shapiro-Wilk normality test\n## \n## data:  lobst_uns$Pellets\n## W = 0.76706, p-value = 0.0425\nresid_lobst <- residuals(lm(weight ~ diet, data = lobsters))\nshapiro.test(resid_lobst)## \n##  Shapiro-Wilk normality test\n## \n## data:  resid_lobst\n## W = 0.94779, p-value = 0.3914\nplot(lm(weight ~ diet , data = lobsters),\n     which = 2)\nbartlett.test(weight ~ diet, data = lobsters)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  weight by diet\n## Bartlett's K-squared = 0.71273, df = 2, p-value = 0.7002\nplot(lm(weight ~ diet, data = lobsters),\n     which = c(1,3))\nanova(lm(weight ~ diet, data = lobsters))## Analysis of Variance Table\n## \n## Response: weight\n##           Df Sum Sq Mean Sq F value Pr(>F)\n## diet       2 1567.2  783.61  1.6432 0.2263\n## Residuals 15 7153.1  476.87\nTukeyHSD(aov(weight ~ diet, data = lobsters))##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = weight ~ diet, data = lobsters)\n## \n## $diet\n##                      diff        lwr      upr     p adj\n## Mussels-Flakes  21.895238  -9.661957 53.45243 0.2024851\n## Pellets-Flakes  14.046667 -20.300196 48.39353 0.5508657\n## Pellets-Mussels -7.848571 -41.061560 25.36442 0.8148766"},{"path":"cs2-anova.html","id":"key-points-2","chapter":"14 ANOVA","heading":"14.11 Key points","text":"Point 1Point 2Point 3","code":""},{},{"path":"kruskal-wallis-test.html","id":"kruskal-wallis-test","chapter":"15 Kruskal-Wallis test","heading":"15 Kruskal-Wallis test","text":"","code":""},{"path":"kruskal-wallis-test.html","id":"objectives-5","chapter":"15 Kruskal-Wallis test","heading":"15.1 Objectives","text":"QuestionsHow ‚Ä¶‚Ä¶ObjectivesBe able ‚Ä¶Use‚Ä¶","code":""},{"path":"kruskal-wallis-test.html","id":"purpose-and-aim-3","chapter":"15 Kruskal-Wallis test","heading":"15.2 Purpose and aim","text":"Kruskal-Wallis one-way analysis variance test analogue ANOVA can used assumption normality met. way extension Mann-Whitney test two groups.","code":""},{"path":"kruskal-wallis-test.html","id":"section-commands-7","chapter":"15 Kruskal-Wallis test","heading":"15.3 Section commands","text":"New commands used section:","code":""},{"path":"kruskal-wallis-test.html","id":"data-and-hypotheses-6","chapter":"15 Kruskal-Wallis test","heading":"15.4 Data and hypotheses","text":"example, suppose behavioural ecologist records rate spider monkeys behaved aggressively towards one another function closely related two monkeys . familiarity two monkeys involved interaction classified high, low none. want test data support hypothesis aggression rates differ according strength relatedness. form following null alternative hypotheses:\\(H_0\\): median aggression rates types familiarity \\(H_1\\): median aggression rates equalWe use Kruskal-Wallis test check .data stored file data/raw/CS2-spidermonkey.csv.First read data :","code":"\nspidermonkey <- read.csv(\"data/raw/CS2-spidermonkey.csv\")"},{"path":"kruskal-wallis-test.html","id":"summarise-and-visualise-6","chapter":"15 Kruskal-Wallis test","heading":"15.5 Summarise and visualise","text":"data appear show significant difference aggression rates three types familiarity. probably expect reasonably significant result .","code":"\n# look at the data format\nhead(spidermonkey)##   aggression familiarity\n## 1        0.2        high\n## 2        0.1        high\n## 3        0.4        high\n## 4        0.8        high\n## 5        0.3        high\n## 6        0.5        high\n# summarise the data\naggregate(aggression ~ familiarity, data = spidermonkey, summary)##   familiarity aggression.Min. aggression.1st Qu. aggression.Median\n## 1        high       0.1000000          0.2000000         0.3000000\n## 2         low       0.3000000          0.4500000         0.5000000\n## 3        none       0.9000000          1.1500000         1.2000000\n##   aggression.Mean aggression.3rd Qu. aggression.Max.\n## 1       0.3571429          0.4500000       0.8000000\n## 2       0.6285714          0.7500000       1.2000000\n## 3       1.2571429          1.4000000       1.6000000\n# create boxplot\nboxplot(aggression ~ familiarity, data = spidermonkey)"},{"path":"kruskal-wallis-test.html","id":"implement-test-5","chapter":"15 Kruskal-Wallis test","heading":"15.6 Implement test","text":"Perform Kruskal-Wallis test data:first argument must formula format: variable ~ categoryIf data stored stacked format, second argument must name data frame","code":"\nkruskal.test(aggression ~ familiarity, data = spidermonkey)"},{"path":"kruskal-wallis-test.html","id":"interpret-output-and-report-results-5","chapter":"15 Kruskal-Wallis test","heading":"15.7 Interpret output and report results","text":"output now see console window:p-value given 3rd line. shows us probability getting samples null hypothesis actually true.Since p-value small (much smaller standard significance level 0.05) can say ‚Äúunlikely three samples came parent distribution can reject null hypothesis‚Äù state :one-way Kruskal-Wallis rank sum test showed aggression rates spidermonkeys depends upon degree familiarity (KW = 13.597, df = 2, p = 0.0011).","code":"## \n##  Kruskal-Wallis rank sum test\n## \n## data:  aggression by familiarity\n## Kruskal-Wallis chi-squared = 13.597, df = 2, p-value = 0.001115"},{"path":"kruskal-wallis-test.html","id":"assumptions-7","chapter":"15 Kruskal-Wallis test","heading":"15.8 Assumptions","text":"use Kruskal-Wallis test make three assumptions:parent distributions samples drawn shape (‚Äôre normal use one-way ANOVA)data point samples independent othersThe parent distributions varianceIndependence ‚Äôll ignore usual. Similar shape best assessed earlier visualisation data. means need check equality variance.Equality varianceWe test equality variance using Levene‚Äôs test (since can‚Äôt assume normal parent distributions rules Bartlett‚Äôs test).Levene‚Äôs test included default R packages may require installation additional package called car (Companion Applied Regression).install car package, run following command console:Alternatively, go Tools > Install packages‚Ä¶ > Packages, type car press InstallRemember load library library(car).Perform Levene‚Äôs test data:relevant p-value given 3rd line (Pr(>F) = 0.893). quite large see group appear variance.also warning group coerced factor. need worry - Levene‚Äôs test needs compare different groups aggression encoded numeric value, converts categorical one running test.","code":"\ninstall.packages(\"car\")\nleveneTest(aggression ~ familiarity, data = spidermonkey)## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\n## factor.## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  2  0.1139  0.893\n##       18"},{"path":"kruskal-wallis-test.html","id":"post-hoc-testing-1","chapter":"15 Kruskal-Wallis test","heading":"15.9 Post-hoc testing","text":"equivalent Tukey‚Äôs range test non-normal data Dunn‚Äôs test.\nDunn‚Äôs test also included default R packages may require installation additional package called dunn.test.install dunn.test package, run following command console:Alternatively, go Tools > Install packages‚Ä¶ > Packages, type dunn.test press InstallRemember load library library(dunn.test).Test significant difference group medians:Note Dunn‚Äôs test requires us enter two arguments, first vector values second vector containing category labels (.e.¬†factor).give following output:can see dunn.test() function also performs Kruskal-Wallis test data, results reported initially.comparison pairs groups reported table bottom. cell table two rows. bottom row contains p-values want. table shows isn‚Äôt significant difference high low groups, p-value (0.0799) high. two comparisons high familiarity familiarity groups low groups significant though.","code":"\ninstall.packages(\"dunn.test\")\ndunn.test(spidermonkey$aggression, spidermonkey$familiarity)##   Kruskal-Wallis rank sum test\n## \n## data: x and group\n## Kruskal-Wallis chi-squared = 13.5972, df = 2, p-value = 0\n## \n## \n##                            Comparison of x by group                            \n##                                 (No adjustment)                                \n## Col Mean-|\n## Row Mean |       high        low\n## ---------+----------------------\n##      low |  -1.405820\n##          |     0.0799\n##          |\n##     none |  -3.655132  -2.249312\n##          |    0.0001*    0.0122*\n## \n## alpha = 0.05\n## Reject Ho if p <= alpha/2"},{"path":"kruskal-wallis-test.html","id":"exercise-8","chapter":"15 Kruskal-Wallis test","heading":"15.10 Exercise","text":"Exercise 15.1  Kruskal-Wallis Dunn‚Äôs test lobster dataPerform Kruskal-Wallis test post-hoc test lobster data set.1. Hypotheses\\(H_0\\) : medians equal\\(H_1\\) : medians equal2. Import data, summarise visualiseAll done previously.3. AssumptionsFrom , since data normal enough definitely similar enough Kruskal-Wallis test equality variance assessment diagnostic plots. completeness though look Levene‚Äôs testGiven p-value high, agrees previous assessment equality variance assumption well met. Rock .4. Kruskal-Wallis testA Kruskal-Wallis test indicated median weight juvenile lobsters differ significantly diets (KW = 3.26, df = 2, p = 0.20).5. Dunn‚Äôs testAlthough rather unneccessary, since detect significant differences diets, can perform non-parametric equivalent Tukey‚Äôs range test: Dunn‚Äôs test., ‚Äôve used optional argument called altp dunn.test() call. default option reports p-values divided 2. assessment significance requires compare p-value 0.025 rather 0.05. Using argument altp = TRUE means Dunn‚Äôs test reports actual p-values.Either way, can see none comparisons significant ().","code":"\nleveneTest(weight ~ diet, data = lobsters)## Levene's Test for Homogeneity of Variance (center = median)\n##       Df F value Pr(>F)\n## group  2  0.0028 0.9972\n##       15\nkruskal.test(weight ~ diet, data = lobsters)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  weight by diet\n## Kruskal-Wallis chi-squared = 3.2565, df = 2, p-value = 0.1963\ndunn.test(lobsters$weight, lobsters$diet, altp = TRUE)##   Kruskal-Wallis rank sum test\n## \n## data: x and group\n## Kruskal-Wallis chi-squared = 3.2565, df = 2, p-value = 0.2\n## \n## \n##                            Comparison of x by group                            \n##                                 (No adjustment)                                \n## Col Mean-|\n## Row Mean |     Flakes    Mussels\n## ---------+----------------------\n##  Mussels |  -1.787664\n##          |     0.0738\n##          |\n##  Pellets |  -0.670245   1.005415\n##          |     0.5027     0.3147\n## \n## alpha = 0.05\n## Reject Ho if p <= alpha"},{"path":"kruskal-wallis-test.html","id":"key-points-3","chapter":"15 Kruskal-Wallis test","heading":"15.11 Key points","text":"Point 1Point 2Point 3","code":""},{},{"path":"cs3-intro.html","id":"cs3-intro","chapter":"16 Introduction","heading":"16 Introduction","text":"","code":""},{"path":"cs3-intro.html","id":"objectives-6","chapter":"16 Introduction","heading":"16.1 Objectives","text":"Aim: introduce R commands analysing simple linear modelsBy end practical participants able perform following statistical analyses:Simple Linear RegressionCorrelationFor , participants able :Perform test RInterpret outputCheck assumptions test","code":""},{"path":"cs3-intro.html","id":"background-2","chapter":"16 Introduction","heading":"16.2 Background","text":"practical focuses implementation various statistical tests relating simple linear regression correlation., focus underlying theory tests (although demonstrators happy answer questions may ).test section :explains purpose test,explains visualise data,explains perform test R,explains interpret output report results, andexplains assess assumptions required perform test.","code":""},{},{"path":"introduction-2.html","id":"introduction-2","chapter":"17 Introduction","heading":"17 Introduction","text":"practical introducing can compare data different continuous variables.","code":""},{"path":"introduction-2.html","id":"cs3-datasets","chapter":"17 Introduction","heading":"17.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"correlation-coefficients.html","id":"correlation-coefficients","chapter":"18 Correlation coefficients","heading":"18 Correlation coefficients","text":"","code":""},{"path":"correlation-coefficients.html","id":"objectives-7","chapter":"18 Correlation coefficients","heading":"18.1 Objectives","text":"QuestionsWhat correlation coefficients?kind correlation coefficients use ?ObjectivesBe able calculate correlation coefficients RUse visual tools explore correlations variablesKnow limitations correlation coefficients","code":""},{"path":"correlation-coefficients.html","id":"purpose-and-aim-4","chapter":"18 Correlation coefficients","heading":"18.2 Purpose and aim","text":"Correlation refers relationship two variables (datasets) one another. Two datasets said correlated independent one another. Correlations can useful can indicate predictive relationship may exist. However just two datasets correlated mean causally related.","code":""},{"path":"correlation-coefficients.html","id":"section-commands-8","chapter":"18 Correlation coefficients","heading":"18.3 Section commands","text":"New commands used section:","code":""},{"path":"correlation-coefficients.html","id":"data-and-hypotheses-7","chapter":"18 Correlation coefficients","heading":"18.4 Data and hypotheses","text":"use USArrests dataset example. rather bleak dataset contains statistics arrests per 100,000 residents assault, murder robbery 50 US states 1973, alongside proportion population lived urban areas time. USArrests unstacked data frame 50 observations four variables: Murder, Assault, UrbanPop Robbery.data stored file data/raw/CS3-usarrests.csv.First read data:syntax reading data frame little different. want use first column .csv file specify names rows dataset rather include information inside dataset . using row.names = 1 argument tells R use 1st column file row names. need functions using require matrix input (basically data frame containing numbers).","code":"\nUSArrests <- read.csv(\"data/raw/CS3-usarrests.csv\", row.names = 1)\n\n# have a look at the data\nhead(USArrests)##            Murder Assault UrbanPop Robbery\n## Alabama      13.2     236       58    21.2\n## Alaska       10.0     263       48    44.5\n## Arizona       8.1     294       80    31.0\n## Arkansas      8.8     190       50    19.5\n## California    9.0     276       91    40.6\n## Colorado      7.9     204       78    38.7"},{"path":"correlation-coefficients.html","id":"pearsons-product-moment-correlation-coefficient","chapter":"18 Correlation coefficients","heading":"18.5 Pearson‚Äôs product moment correlation coefficient","text":"Pearson‚Äôs r (quantity also known) measure linear correlation two variables. value -1 +1, +1 means perfect positive correlation, -1 means perfect negative correlation 0 means correlation .","code":""},{"path":"correlation-coefficients.html","id":"summarise-and-visualise-7","chapter":"18 Correlation coefficients","heading":"18.6 Summarise and visualise","text":"Run command:first argument matrix data frameThe argument lower.panel tells R add redundant reflected lower set plots, diagonalFrom visual inspection scatter plots can see appears slight positive correlation pairs variables, although may weak case (Murder UrbanPop example).","code":"\npairs(USArrests, lower.panel = NULL)"},{"path":"correlation-coefficients.html","id":"implement-test-6","chapter":"18 Correlation coefficients","heading":"18.7 Implement test","text":"Let‚Äôs test possible correlations variables:first argument matrix data frameThe argument method tells R correlation coefficient use (pearson (default), kendall, spearman)","code":"\ncor(USArrests, method = \"pearson\")"},{"path":"correlation-coefficients.html","id":"interpret-output-and-report-results-6","chapter":"18 Correlation coefficients","heading":"18.8 Interpret output and report results","text":"give following output:matrix gives correlation coefficient pair variables data frame. matrix symmetric (?) diagonal values 1 (?). correlated variables Murder Assault r value 0.801. appears agree well set scatter plots produced earlier.","code":"##              Murder   Assault   UrbanPop   Robbery\n## Murder   1.00000000 0.8018733 0.06957262 0.5635788\n## Assault  0.80187331 1.0000000 0.25887170 0.6652412\n## UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\n## Robbery  0.56357883 0.6652412 0.41134124 1.0000000"},{"path":"correlation-coefficients.html","id":"exercise-9","chapter":"18 Correlation coefficients","heading":"18.9 Exercise","text":"Exercise 18.1  State data correlationWe use data file data/raw/CS3-statedata.csv dataset exercise. rather benign dataset contains information general properties US state, population (1975), per capita income (1974), illiteracy proportion (1970), life expectancy (1969), murder rate per 100,000 people (‚Äôs getting away ), percentage population high-school graduates, average number days minimum temperature freezing 1931 1960, state area square miles. dataset contains 50 rows 8 columns, column names: Population, Income, Illiteracy, Life.Exp, Murder, HS.Grad, Frost Area.Load data (remembering tell R first column CSV file used specify row names dataset) use pairs command visually identify 3 different pairs variables appear bethe positively correlatedthe negatively correlatednot correlated allCalculate Pearson‚Äôs r variable pairs see well able identify correlation visually.1. Read data2. Look pair-wise comparisons3. Create correlation matrixThe positively correlated variables Murder IlliteracyThe negatively correlated variables Murder LifeExpThe uncorrelated variables Area Population","code":"\nUSAstate <- read.csv(\"data/raw/CS3-statedata.csv\",\n                     row.names = 1)\n\n# have a look at the data\nhead(USAstate)##            Population Income Illiteracy LifeExp Murder HSGrad Frost   Area\n## Alabama          3615   3624        2.1   69.05   15.1   41.3    20  50708\n## Alaska            365   6315        1.5   69.31   11.3   66.7   152 566432\n## Arizona          2212   4530        1.8   70.55    7.8   58.1    15 113417\n## Arkansas         2110   3378        1.9   70.66   10.1   39.9    65  51945\n## California      21198   5114        1.1   71.71   10.3   62.6    20 156361\n## Colorado         2541   4884        0.7   72.06    6.8   63.9   166 103766\npairs(USAstate, lower.panel = NULL)\ncor(USAstate, method = \"pearson\")##             Population     Income  Illiteracy     LifeExp     Murder\n## Population  1.00000000  0.2082276  0.10762237 -0.06805195  0.3436428\n## Income      0.20822756  1.0000000 -0.43707519  0.34025534 -0.2300776\n## Illiteracy  0.10762237 -0.4370752  1.00000000 -0.58847793  0.7029752\n## LifeExp    -0.06805195  0.3402553 -0.58847793  1.00000000 -0.7808458\n## Murder      0.34364275 -0.2300776  0.70297520 -0.78084575  1.0000000\n## HSGrad     -0.09848975  0.6199323 -0.65718861  0.58221620 -0.4879710\n## Frost      -0.33215245  0.2262822 -0.67194697  0.26206801 -0.5388834\n## Area        0.02254384  0.3633154  0.07726113 -0.10733194  0.2283902\n##                 HSGrad      Frost        Area\n## Population -0.09848975 -0.3321525  0.02254384\n## Income      0.61993232  0.2262822  0.36331544\n## Illiteracy -0.65718861 -0.6719470  0.07726113\n## LifeExp     0.58221620  0.2620680 -0.10733194\n## Murder     -0.48797102 -0.5388834  0.22839021\n## HSGrad      1.00000000  0.3667797  0.33354187\n## Frost       0.36677970  1.0000000  0.05922910\n## Area        0.33354187  0.0592291  1.00000000"},{"path":"correlation-coefficients.html","id":"spearmans-rank-correlation-coefficient","chapter":"18 Correlation coefficients","heading":"18.10 Spearman‚Äôs rank correlation coefficient","text":"test first calculates rank numerical data (.e.¬†position smallest (negative) largest (positive)) two variables calculates Pearson‚Äôs product moment correlation coefficient using ranks. consequence, test less sensitive outliers distribution.","code":""},{"path":"correlation-coefficients.html","id":"implement-test-7","chapter":"18 Correlation coefficients","heading":"18.11 Implement test","text":"using USArrests data set , run command:first argument matrix data frameThe argument method tells R correlation coefficient use","code":"\ncor(USArrests, method = \"spearman\")"},{"path":"correlation-coefficients.html","id":"interpret-output-and-report-results-7","chapter":"18 Correlation coefficients","heading":"18.12 Interpret output and report results","text":"gives following output:matrix gives correlation coefficient pair variables data frame. , matrix symmetric, diagonal values 1 expected. values obtained similar correlation coefficients obtained using Pearson test.","code":"##             Murder   Assault  UrbanPop   Robbery\n## Murder   1.0000000 0.8172735 0.1067163 0.6794265\n## Assault  0.8172735 1.0000000 0.2752133 0.7143681\n## UrbanPop 0.1067163 0.2752133 1.0000000 0.4381068\n## Robbery  0.6794265 0.7143681 0.4381068 1.0000000"},{"path":"correlation-coefficients.html","id":"exercise-10","chapter":"18 Correlation coefficients","heading":"18.13 Exercise","text":"Exercise 18.2  Spearman‚Äôs correlation USA state dataCalculate Spearman‚Äôs correlation coefficient data/raw/CS3-statedata.csv dataset.variable‚Äôs correlations affected use Spearman‚Äôs rank compared Pearson‚Äôs r?reference scatter plot produced earlier, can explain might ?Remember use row.names = 1 argument load data matrixInstead eye-balling differences, think can determine difference two correlation matricesThe heatmap() function can useful visualise matricesIn order determine variables affected choice Spearman vs Pearson just plot matrices side side try spot going , one reasons ‚Äôre using R can bit programmatic things.Let‚Äôs calculate difference two correlation matrices:, now just look grid 64 numbers see can spot biggest differences, eyes aren‚Äôt good processing parsing sort information display. better way somehow visualise data. can using R plotting functions, heatmap() exact. heatmap() function lot features don‚Äôt need ‚Äôm going go detail . main reason ‚Äôm using displays matrices right way round (plotting functions display matrices rotated 90 degrees) automatically labels rows columns.abs() function calculates absolute value (.e.¬†just magnitude) matrix values. just care situations two correlation coefficients different don‚Äôt care larger. symm argument tells function symmetric matrix conjunction Rowv = NA argument stops plot reordering rows columns. Rowv = NA argument also stops function adding dendrograms margins plot.plot coloured yellow, indicating smallest values (case correspond difference correlation coefficients), orange dark red, indicating biggest values (case correspond variables biggest difference correlation coefficients).plot symmetric along leading diagonal (hopefully obvious reasons) can see majority squares light yellow colour, means isn‚Äôt much difference Spearman Pearson vast majority variables. squares appear darkest look along Area row/column suggesting ‚Äôs big difference correlation coefficients .can now revisit pairwise scatter plot see makes sense:can see clearly correspond plots noticeable outliers. example, Alaska twice big next biggest state, Texas. Big outliers data can large impact Pearson coefficient, whereas Spearman coefficient robust effects outliers. can see detail look Area vs Income graph coefficients. Pearson gives value 0.36, slight positive correlation, whereas Spearman gives value 0.057, basically uncorrelated. single outlier (Alaska) top-right scatter plot big effect Pearson practically ignored Spearman.Well done, Mr.¬†Spearman.","code":"\ncor(USAstate, method = \"spearman\")##            Population      Income Illiteracy    LifeExp     Murder     HSGrad\n## Population  1.0000000  0.12460984  0.3130496 -0.1040171  0.3457401 -0.3833649\n## Income      0.1246098  1.00000000 -0.3145948  0.3241050 -0.2174623  0.5104809\n## Illiteracy  0.3130496 -0.31459482  1.0000000 -0.5553735  0.6723592 -0.6545396\n## LifeExp    -0.1040171  0.32410498 -0.5553735  1.0000000 -0.7802406  0.5239410\n## Murder      0.3457401 -0.21746230  0.6723592 -0.7802406  1.0000000 -0.4367330\n## HSGrad     -0.3833649  0.51048095 -0.6545396  0.5239410 -0.4367330  1.0000000\n## Frost      -0.4588526  0.19686382 -0.6831936  0.2983910 -0.5438432  0.3985351\n## Area       -0.1206723  0.05709484 -0.2503721  0.1275002  0.1064259  0.4389752\n##                 Frost        Area\n## Population -0.4588526 -0.12067227\n## Income      0.1968638  0.05709484\n## Illiteracy -0.6831936 -0.25037208\n## LifeExp     0.2983910  0.12750018\n## Murder     -0.5438432  0.10642590\n## HSGrad      0.3985351  0.43897520\n## Frost       1.0000000  0.11228778\n## Area        0.1122878  1.00000000\ncorPear <- cor(USAstate, method = \"pearson\")\ncorSpea <- cor(USAstate, method = \"spearman\")\ncorDiff <- corPear - corSpea\nheatmap(abs(corDiff), symm = TRUE, Rowv = NA)\npairs(USAstate)"},{"path":"correlation-coefficients.html","id":"key-points-4","chapter":"18 Correlation coefficients","heading":"18.14 Key points","text":"Correlation degree two variables linearly relatedCorrelation imply causationWe can visualise correlations using pairs() functionUsing cor() function can calculate correlation matricesTwo main correlation coefficients Pearson‚Äôs r Spearman‚Äôs rank, Spearman‚Äôs rank less sensitive outliers","code":""},{},{"path":"linear-regression.html","id":"linear-regression","chapter":"19 Linear regression","heading":"19 Linear regression","text":"","code":""},{"path":"linear-regression.html","id":"objectives-8","chapter":"19 Linear regression","heading":"19.1 Objectives","text":"QuestionsWhen use linear regression?interpret results?ObjectivesBe able perform linear regression RUse ANOVA check slope regression differs zeroUnderstand underlying assumptions linear regression analysisUse diagnostic plots check assumptions","code":""},{"path":"linear-regression.html","id":"purpose-and-aim-5","chapter":"19 Linear regression","heading":"19.2 Purpose and aim","text":"Regression analysis tests association two variables, also allows one investigate quantitatively nature relationship present, thus determine whether one variable may used predict values another.\nSimple linear regression essentially models dependence scalar dependent variable (y) independent (explanatory) variable (x) according relationship:\\[\\begin{equation*} \ny = \\beta_0 + \\beta_1 x\n\\end{equation*}\\]\\(\\beta_0\\) value intercept \\(\\beta_1\\) slope fitted line. aim simple linear regression analysis assess whether coefficient slope, \\(\\beta_1\\), actually different zero. different zero can say \\(x\\) significant effect \\(y\\) (since changing \\(x\\) leads predicted change \\(y\\)), whereas isn‚Äôt significantly different zero, say isn‚Äôt sufficient evidence relationship. course, order assess whether slope significantly different zero first need calculate values \\(\\beta_0\\) \\(\\beta_1\\).","code":""},{"path":"linear-regression.html","id":"section-commands-9","chapter":"19 Linear regression","heading":"19.3 Section commands","text":"new commands used section.","code":""},{"path":"linear-regression.html","id":"data-and-hypotheses-8","chapter":"19 Linear regression","heading":"19.4 Data and hypotheses","text":"perform simple linear regression analysis two variables Murder Assault USArrests dataset. wish determine whether Assault variable significant predictor Murder variable. means need find coefficients \\(\\beta_0\\) \\(\\beta_1\\) best fit following macabre equation:\\[\\begin{equation*}\nMurder  = \\beta_0 + \\beta_1 Assault\n\\end{equation*}\\]testing following null alternative hypotheses:\\(H_0\\): Assault significant predictor Murder, \\(\\beta_1 = 0\\)\\(H_1\\): Assault significant predictor Murder, \\(\\beta_1 \\neq 0\\)","code":""},{"path":"linear-regression.html","id":"summarise-and-visualise-8","chapter":"19 Linear regression","heading":"19.5 Summarise and visualise","text":"can visualise data :appears relatively strong positive relationship two variables whilst reasonable scatter points around trend line, probably expect significant result case.","code":"\nplot(Murder ~ Assault, data = USArrests)"},{"path":"linear-regression.html","id":"implement-test-8","chapter":"19 Linear regression","heading":"19.6 Implement test","text":"Fit straight line data:first argument lm formula saying Murder depends Assaults. seen , syntax generally dependent variable ~ independent variable.second argument specifies dataset useThe function lm returns linear model (lm) object essentially list containing everything necessary understand analyse linear model. However, just type (2nd line) just prints screen actual coefficients model .e.¬†intercept slope line.found line best fit given :\\[\\begin{equation*}\nMurder = 0.63 + 0.042 Assault\n\\end{equation*}\\]Assess whether slope significantly different zero:, use anova() command assess significance. shouldn‚Äôt surprising stage introductory lectures made sense. mathematical perspective, one-way ANOVA simple linear regression exactly makes sense use command analyse R.","code":"\nlm_1 <- lm(Murder ~ Assault, data = USArrests)\n\n# show the linear model\nlm_1## \n## Call:\n## lm(formula = Murder ~ Assault, data = USArrests)\n## \n## Coefficients:\n## (Intercept)      Assault  \n##     0.63168      0.04191\nanova(lm_1)"},{"path":"linear-regression.html","id":"interpret-output-and-report-results-8","chapter":"19 Linear regression","heading":"19.7 Interpret output and report results","text":"exactly format table saw one-way ANOVA:1st line just tells ANOVA testThe 2nd line tells response variable (case Murder)3rd, 4th 5th lines ANOVA table contain useful values:\nDf column contains degrees freedom values row, 1 48 (‚Äôll need reporting)\nF value column contains F statistic, 86.454 (‚Äôll need reporting).\np-value 2.596e-12 number directly Pr(>F) 4th line.\nvalues table (Sum Sq Mean Sq) column used calculate F statistic don‚Äôt need know .\nDf column contains degrees freedom values row, 1 48 (‚Äôll need reporting)F value column contains F statistic, 86.454 (‚Äôll need reporting).p-value 2.596e-12 number directly Pr(>F) 4th line.values table (Sum Sq Mean Sq) column used calculate F statistic don‚Äôt need know ., p-value ‚Äôre interested shows us probability getting data null hypothesis actually true slope line actually zero.\nSince p-value excruciatingly tiny can reject null hypothesis state :simple linear regression showed assault rate US states significant predictor number murders (F = 86.45, df = 1,48, p = 2.59x10-12).Plotting regression lineIt can helpful plot regression line original data see far data predicted linear values. can :first command creates scatter plot dataThe second command uses results linear model fitting (object lm_1) add line best fit plot (colour red).","code":"## Analysis of Variance Table\n## \n## Response: Murder\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## Assault    1 597.70  597.70  86.454 2.596e-12 ***\n## Residuals 48 331.85    6.91                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# plot the data\nplot(Murder ~ Assault, data = USArrests)\n\n# add the regression line\nabline(lm_1, col = \"red\")"},{"path":"linear-regression.html","id":"assumptions-8","chapter":"19 Linear regression","heading":"19.8 Assumptions","text":"order linear regression analysis valid 4 key assumptions need met:data must linear (entirely possible calculate straight line data straight - doesn‚Äôt mean though!)residuals must normally distributedThe residuals must correlated fitted valuesThe fit depend overly much single point (point high leverage).Whether assumptions met can easily checked visually producing four key diagnostic plots.top left graph plots residuals fitted values. data best explained straight line uniform distribution points horizontal grey dotted line (sufficient points red line, moving average, top grey dotted line). plot pretty good.top right graph shows Q-Q plot allows visual inspection normality. residuals normally distributed, points lie diagonal dotted line. isn‚Äôt bad slight snaking towards upper end Georgia appears outlier .bottom left scale-location graph allows us investigate whether correlation residuals fitted values whether variance residuals changes significantly. , red line horizontal. correlation change variance red line horizontal. plot fine.last graph shows Cook‚Äôs distance tests one point unnecessarily large effect fit. important aspect see points lie beyond red dashed contour line top right corner plot. , point undue influence. plot good.Formally, concern looking diagnostic plots, linear regression valid. However, disappointingly, people ever check whether linear regression assumptions met quoting results.Let‚Äôs change leading example!","code":"\n# create a 2 x 2 output window\npar(mfrow = c(2,2))\n\n# and create the diagnostic plots for our model\nplot(lm_1)"},{"path":"linear-regression.html","id":"exercise-11","chapter":"19 Linear regression","heading":"19.9 Exercise","text":"Exercise 19.1  Linear regressionCalculate two simple linear regressions using data/raw/CS3-statedata.csv dataset, first variable LifeExp variable Murder variable HSGrad Frost.following cases:Find value slope intercept coefficients regressionsDetermine slope significantly different zero (.e.¬†relationship two variables)Produce scatter plot data line best fit superimposed top.Produce diagnostic plots discuss (virtual) neighbour carried simple linear regression caseMurder Life ExpectancyLet‚Äôs see Murder variable can used predict Life.Exp variable. Let‚Äôs plot first ., ‚Äôve fit linear model (second line) time plotting raw data (first line) just can add line best fit (third line). visualise reasons:check data aren‚Äôt obviously wrong. sensible values life expectancy (nothing massively large small), plausible values murder rates (‚Äôm au fait US murder rates 1976 small positive numbers seem plausible).check see expect statistical analysis. appear reasonable downward trend data. surprised didn‚Äôt get significant result given amount data spread data lineWe check assumptions (roughly though ‚Äôll properly minute). Nothing immediately gives cause concern; data appear linear, spread data around line appears homogeneous symmetrical. outliers either.Now, let‚Äôs check assumptions diagnostic plots.residuals vs fitted plot appears symmetric enough (similar distribution points horizontal grey dotted line) happy linearity. Similarly red line scale-location plot looks horizontal enough happy homogeneity variance. aren‚Äôt influential points residuals vs leverage. plot give bit concern Normal Q-Q graph. see clear evidence snaking, although degree snaking isn‚Äôt actually bad. just means can pretty certain distribution residuals isn‚Äôt normal, also isn‚Äôt non-normal. situation? Well, three possible options:Appeal Central Limit Theorem. states large enough sample size don‚Äôt worry whether distribution residuals normally distributed. Large enough bit moving target honest depends non-normal underlying data . data little bit non-normal can get away using smaller sample data massively skewed (example). exact science, anything 30 data points considered lot mild moderate non-normality (case). data skewed looking data points (50-100). , example can legitimately just carry analysis without worrying.Try transforming data. try applying mathematical functions response variable (LifeExp) hope repeating analysis transformed variable make things better. honest might work won‚Äôt know try. Dealing transformed variables legitimate approach can make interpreting model bit challenging. particular example none traditional transformations (log, square-root, reciprocal) anything fix slight lack normality (can take word try ; plot(lm(log(LifeExp ~ Murder, data = USAstate))) example.Go permutation methods / bootstrapping. approach definitely work. don‚Äôt time explain (‚Äôs subject entire practical). approach also requires us reasonably large sample size work well assume distribution sample good approximation distribution entire dataset.case, large enough sample size deviation normality isn‚Äôt bad, can just crack standard analysis., let‚Äôs actually analysis:find Murder rate statistically significant predictor life expectancy US states. Woohoo!High School Graduation Frosty DaysNow let‚Äôs investigate relationship proportion High School Graduates state (HSGrad) mean number days freezing (Frost) within state., look data.doesn‚Äôt appear ridiculous errors data; High School graduation proportions 0-100% range mean number sub-zero days state 0 365, numbers plausible.Whilst trend upwards, wouldn‚Äôt surprise came back significant, ‚Äôm bit concerned ‚Ä¶assumptions. ‚Äôm mainly concerned data aren‚Äôt linear. appears noticeable pattern data sort minimum around 50-60 Frost days. means ‚Äôs hard assess assumptions.Let‚Äôs check properlyNow, let‚Äôs check assumptions diagnostic plots.can see suspected backed residual vs fitted graph. data aren‚Äôt linear appears sort odd -pattern . Given lack linearity just isn‚Äôt worth worrying plots model misspecified: straight line just doesn‚Äôt represent data .Just reference, practice looking diagnostic plots, ignore lack linearity can say thatNormality pretty good Normal Q-Q plotHomogeneity variance isn‚Äôt good appears noticeable drop variance go left right (consideration Scale-Location plot)don‚Äôt appear influential points (looking residuals vs leverage graph)However, none relevant particular case since data aren‚Äôt linear straight line wrong model fit.situation?Well actually, bit tricky aren‚Äôt easy fixes . two broad solutions dealing misspecified model.common solution need predictor variables model. ‚Äôre trying explain/predict high school graduation using number frost days. Obviously many things affect proportion high school graduates just cold State (weird potential predictor think ) need statistical approach allows us look multiple predictor variables. ‚Äôll cover approach next two sessions.potential solution say high school graduation can fact predicted number frost days relationship isn‚Äôt linear. need specify relationship (curve basically) try fit data new, non-linear, curve. process called, unsurprisingly, non-linear regression don‚Äôt cover course. process best used already strong theoretical reason non-linear relationship two variables (sigmoidal dose-response curves pharmacology exponential relationships cell growth). case don‚Äôt preconceived notions wouldn‚Äôt really appropriate case.Neither solutions can tackled knowledge far course can definitely say based upon data set, isn‚Äôt linear relationship (significant otherwise) frosty days high school graduation rates.","code":"\n# plot the data\nplot(LifeExp ~ Murder, data = USAstate)\n\n# create a linear model\nlm1 <- lm(LifeExp ~ Murder, data = USAstate)\n\n# and add a regression line\nabline(lm1, col = \"red\")\npar(mfrow = c(2,2))\nplot(lm1)\nanova(lm1)## Analysis of Variance Table\n## \n## Response: LifeExp\n##           Df Sum Sq Mean Sq F value   Pr(>F)    \n## Murder     1 53.838  53.838  74.989 2.26e-11 ***\n## Residuals 48 34.461   0.718                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# plot the data\nplot(HSGrad ~ Frost, data = USAstate)\n\n# create a linear model\nlm2<-lm(HSGrad ~ Frost, data=USAstate)\n\n# and add a regression line\nabline(lm2, col = \"red\")\npar(mfrow = c(2,2))\nplot(lm2)"},{"path":"linear-regression.html","id":"key-points-5","chapter":"19 Linear regression","heading":"19.10 Key points","text":"Linear regression tests linear relationship exists two variablesIf , can use one variable predict anotherA linear model intercept slope test slope differs zeroWe create linear models R lm() function use anova() assess slope coefficientWe can use linear regression four assumptions met:\ndata linear\nResiduals normally distributed\nResiduals correlated fitted values\nsingle point large influence linear model\ndata linearResiduals normally distributedResiduals correlated fitted valuesNo single point large influence linear modelWe use plot(model_name) get four diagnostic plots R, help evaluate assumptions","code":""},{},{"path":"cs4-intro.html","id":"cs4-intro","chapter":"20 Introduction","heading":"20 Introduction","text":"","code":""},{"path":"cs4-intro.html","id":"objectives-9","chapter":"20 Introduction","heading":"20.1 Objectives","text":"Aim: introduce R commands carrying two-way ANOVA linear regression grouped data/ANCOVABy end practical participants able achieve following:Carry two-way ANOVA using R interpret outputAnalyse linear regression grouped data (ANCOVA)","code":""},{"path":"cs4-intro.html","id":"background-3","chapter":"20 Introduction","heading":"20.2 Background","text":"practical focuses implementation various statistical tests relating multiple predictor variables R. focus underlying theory tests (although demonstrators happy answer questions may ).test section explaining perform test, section explaining results output screen, exercise complete relating test .","code":""},{},{"path":"introduction-3.html","id":"introduction-3","chapter":"21 Introduction","heading":"21 Introduction","text":"","code":""},{"path":"introduction-3.html","id":"cs4-datasets","chapter":"21 Introduction","heading":"21.1 Datasets","text":"section uses various data sets. located data/raw/ folder working directory. Please see Datasets information.","code":""},{},{"path":"two-way-anova.html","id":"two-way-anova","chapter":"22 Two-way ANOVA","heading":"22 Two-way ANOVA","text":"","code":""},{"path":"two-way-anova.html","id":"objectives-10","chapter":"22 Two-way ANOVA","heading":"22.1 Objectives","text":"QuestionsHow ‚Ä¶‚Ä¶ObjectivesBe able ‚Ä¶Use‚Ä¶","code":""},{"path":"two-way-anova.html","id":"purpose-and-aim-6","chapter":"22 Two-way ANOVA","heading":"22.2 Purpose and aim","text":"two-way analysis variance used two categorical predictor variables (factors) single continuous response variable. example, looking body Weight (continuous response variable kilograms) affected gender (categorical variable, Male Female) exercise type (categorical variable, Control Runner).analysing type data two things want know:either predictor variables effect response variable .e.¬†gender affect body weight? runner affect body weight?interaction two predictor variables? interaction mean effect exercise weight depends whether male female rather independent gender. example male means runners weigh non-runners, female means runners weight less non-runners say interaction.first consider visualise data carrying appropriate statistical test.","code":""},{"path":"two-way-anova.html","id":"section-commands-10","chapter":"22 Two-way ANOVA","heading":"22.3 Section commands","text":"New commands used section:","code":""},{"path":"two-way-anova.html","id":"data-and-hypotheses-9","chapter":"22 Two-way ANOVA","heading":"22.4 Data and hypotheses","text":"recreate example analysis used lecture. data stored .csv file called CS4-exercise.csv.","code":""},{"path":"two-way-anova.html","id":"summarise-and-visualise-9","chapter":"22 Two-way ANOVA","heading":"22.5 Summarise and visualise","text":"Experiment dataframe three variables; Weight, Gender Exercise. Weight continuous response variable, whereas Gender Exercise categorical predictor variables.First,read data:visualise:produce basic box plots showing response variable (Weight) terms one predictor variables. values predictor variable case aren‚Äôt taken account. argument Weight ~ Gender (Weight ~ Exercise) key . tells R treat Weight function Gender (function Exercise .)\nalso basic plots just showing raw data using default arguments.(Optional) Add titles, axis labels information see fit plots make presentable.Visualise predictor variables together:produces box plots (four) combinations predictor variables. key argument Weight ~ Gender + Exercise. tells R treat Weight function Gender Exercise. + symbol mean add numbers together, Weight treated function Gender plus Exercise.\n, basic plot just shows raw data uses default arguments.(Optional) Add titles, axis labels information see fit plot make presentable.example four box plots relatively easy compare look interactions variables, two levels (groups) per categorical variable, become harder spot going . compare categorical variables easily just plot group means aids ability look interactions main effects predictor variable.Create interaction plot:first argument defines categorical variable used horizontal axis. must factor vector (comes data.frame automatically factor). function called x.factor.second argument defines categorical variable used different lines plotted. must factor vector. function called trace.factor.third argument defines response variable used vertical axis. must numerical vector. function argument called response.‚Äôs common get order arguments muddled . Remember ‚Äôs third argument defines variable goes vertical axis!default settings aren‚Äôt great displaying interaction plots. Try following (opinion) user-friendly display.choice categorical factor plotted horizontal axis plotted different lines completely arbitrary. Looking data ways shouldn‚Äôt add anything often ‚Äôll find prefer one plot another.Plot interaction plot way round:now good feeling data already provide guesses following three questions:appear interaction two categorical variables?:\nExercise effect Weight?\nGender effect Weight?\nExercise effect Weight?Gender effect Weight?can now attempt answer three questions formally using ANOVA test. ask R explicitly test three things: interaction, effect Exercise effect Gender. use following code:Gender:Exercise term R represents concept interaction two variables.produces following output:row table different effects ‚Äôve asked R consider. last column important one contains p-values (although also need F-values degrees freedom reporting purposes). need look interaction row first.Gender:Exercise p-value 0.028 (smaller 0.05) can conclude interaction Gender Exercise significant.must stop.top two lines (corresponding effects Gender Exercise) meaningless now p-values reported utterly redundant (particular way care p-values small).model significant interaction logically impossible meaningfully interpret main effects.report follows:two-way ANOVA test showed significant interaction effects Gender Exercise Weight (F = 5.8521, df = 1,16, p = 0.028). Exercise associated small loss weight males larger loss weight females.","code":"\nExperiment <- read.csv(\"data/raw/CS4-exercise.csv\")\nboxplot(Weight ~ Gender, data = Experiment)\nboxplot(Weight ~ Exercise, data = Experiment)\nboxplot(Weight ~ Gender + Exercise, data = Experiment)\ninteraction.plot(Experiment$Gender, Experiment$Exercise, Experiment$Weight)\ninteraction.plot(Experiment$Gender, Experiment$Exercise, Experiment$Weight,\n                 xlab = \"Gender\", ylab = \"Weight\", trace.label = \"Exercise\",\n                 type = \"b\", pch = 4, col = c(\"blue\", \"red\"))\ninteraction.plot(Experiment$Exercise, Experiment$Gender, Experiment$Weight,\n                 xlab = \"Gender\", ylab = \"Weight\", trace.label = \"Exercise\",\n                 type = \"b\", pch = 4, col = c(\"blue\", \"red\"))\n# define the linear model\nlm.exercise <- lm(Weight ~ Gender + Exercise + Gender:Exercise, data = Experiment)\n\n# perform the ANOVA\nanova(lm.exercise)## Analysis of Variance Table\n## \n## Response: Weight\n##                 Df Sum Sq Mean Sq F value    Pr(>F)    \n## Gender           1 607.20  607.20 43.1144 6.493e-06 ***\n## Exercise         1 184.83  184.83 13.1240  0.002287 ** \n## Gender:Exercise  1  82.42   82.42  5.8521  0.027839 *  \n## Residuals       16 225.34   14.08                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"two-way-anova.html","id":"assumptions-9","chapter":"22 Two-way ANOVA","heading":"22.6 Assumptions","text":"two-way ANOVA type linear model need satisfy pretty much assumptions simple linear regression one-way ANOVA:data must systematic pattern itThe residuals must normally distributedThe residuals must homogeneity varianceThe fit depend overly much single point (point high leverage)., check assumptions visually producing four key diagnostic plots.first command changes plotting parameters splits graphics window 2 rows 2 columns (won‚Äôt notice anything whilst run ).first command changes plotting parameters splits graphics window 2 rows 2 columns (won‚Äôt notice anything whilst run ).second command produces 3 plots graphics window one warning stating Residuals vs Factor Levels plot left . groups exactly number data points.second command produces 3 plots graphics window one warning stating Residuals vs Factor Levels plot left . groups exactly number data points.top left graph plots residuals fitted values. systematic pattern plot pretty good.top left graph plots residuals fitted values. systematic pattern plot pretty good.top right graph allows visual inspection normality. , looks ok (perfect ok).top right graph allows visual inspection normality. , looks ok (perfect ok).bottom left graph allows us investigate whether homogeneity variance. plot fine (perfect fine).bottom left graph allows us investigate whether homogeneity variance. plot fine (perfect fine).shorthand way writing:\nWeight ~ Gender + Exercise + Gender:ExerciseIf use following syntax:Weight ~ Gender*ExerciseThen R interprets exactly way writing three terms.\ncan see compare output following two commands:","code":"\npar(mfrow = c(2, 2))\n\nplot(lm.exercise)## hat values (leverages) are all = 0.2\n##  and there are no factor predictors; no plot no. 5\nanova(lm(Weight ~ Gender + Exercise + Gender:Exercise, data = Experiment))## Analysis of Variance Table\n## \n## Response: Weight\n##                 Df Sum Sq Mean Sq F value    Pr(>F)    \n## Gender           1 607.20  607.20 43.1144 6.493e-06 ***\n## Exercise         1 184.83  184.83 13.1240  0.002287 ** \n## Gender:Exercise  1  82.42   82.42  5.8521  0.027839 *  \n## Residuals       16 225.34   14.08                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(lm(Weight ~ Gender * Exercise, data= Experiment))## Analysis of Variance Table\n## \n## Response: Weight\n##                 Df Sum Sq Mean Sq F value    Pr(>F)    \n## Gender           1 607.20  607.20 43.1144 6.493e-06 ***\n## Exercise         1 184.83  184.83 13.1240  0.002287 ** \n## Gender:Exercise  1  82.42   82.42  5.8521  0.027839 *  \n## Residuals       16 225.34   14.08                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"two-way-anova.html","id":"exercise-cells","chapter":"22 Two-way ANOVA","heading":"22.7 Exercise: Cells","text":"Exercise 22.1  Cell growthThese data/examples/cs4-cells.csv data fictional experiment involves looking effect different concentrations substance growth rate two different cell types (annoyingly vague know ‚Äì suggestions context welcome !). two cell types three concentrations.cell type control experiment substance added (.e.¬†concentration none); low concentration substance high concentration substance. cells called B.\ncombination cell type substance concentration add substance individual cell petri dish 8 hours, count number cells dish (may well biologically weird/impossible ‚Äì suggestions welcome). experiment repeated three times.cell type control experiment substance added (.e.¬†concentration none); low concentration substance high concentration substance. cells called B.\ncombination cell type substance concentration add substance individual cell petri dish 8 hours, count number cells dish (may well biologically weird/impossible ‚Äì suggestions welcome). experiment repeated three times.Let‚Äôs first visualise data:Let‚Äôs look interaction plots:‚Äôre constructed box plots ‚Äôve also constructed two interaction plots. needed one interaction plot find can quite useful look data looks different angles. interaction plots suggest interaction lines plots aren‚Äôt parallel. Looking interaction plot concentration x-axis, appears non difference cell types concentration none, difference cell types concentration low high.Let‚Äôs carry two-way ANOVA:shows definitely significant interaction concentration cell_type.Let‚Äôs check assumptions:, actually look pretty good, although first glance might bit worried apparent heterogeneity variance. last group Residuals vs fitted graph appear spread 5 groups. echoed Scale-Location graph, red line kicks end. Whilst technically signify heterogeneity variance aren‚Äôt worried three data points per group. low number data points per group get one data point little bit extreme others (purely chance) large impact perception homogeneity variance. data points group certain observed heterogeneity variance true feature underlying parent population (therefore problem) rather just caused single random point (therefore problem).","code":"\n# read in the data\ncells <- read_csv(\"data/examples/cs4-cells.csv\")\n# read in the data\ncells <- read_csv(\"data/examples/cs4-cells.csv\")\n\n# let's have a peek at the data\ncells## # A tibble: 18 √ó 4\n##       id cell_type concentration cell_number\n##    <dbl> <chr>     <chr>               <dbl>\n##  1     1 A         none                    7\n##  2     2 A         none                    9\n##  3     3 A         none                    4\n##  4     4 B         none                    5\n##  5     5 B         none                    8\n##  6     6 B         none                    9\n##  7     7 A         low                    22\n##  8     8 A         low                    28\n##  9     9 A         low                    26\n## 10    10 B         low                    12\n## 11    11 B         low                    17\n## 12    12 B         low                    14\n## 13    13 A         high                   89\n## 14    14 A         high                   78\n## 15    15 A         high                   83\n## 16    16 B         high                   48\n## 17    17 B         high                   44\n## 18    18 B         high                   45\nboxplot(cell_number ~ concentration,\n        data = cells)\nboxplot(cell_number ~ cell_type,\n        data = cells)\n# by cell type\ninteraction.plot(cells$concentration, cells$cell_type, cells$cell_number)\n# by concentration\ninteraction.plot(cells$cell_type, cells$concentration, cells$cell_number)\n# define the linear model, with interaction term\nlm1 <- lm(cell_number ~ concentration * cell_type,\n          data = cells)\n\n# perform the ANOVA\nanova(lm1)## Analysis of Variance Table\n## \n## Response: cell_number\n##                         Df  Sum Sq Mean Sq F value    Pr(>F)    \n## concentration            2 10932.1  5466.1 537.645 1.807e-12 ***\n## cell_type                1  1152.0  1152.0 113.311 1.816e-07 ***\n## concentration:cell_type  2  1158.3   579.2  56.967 7.485e-07 ***\n## Residuals               12   122.0    10.2                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\npar(mfrow=c(2,2))\n\nplot(lm1)## hat values (leverages) are all = 0.3333333\n##  and there are no factor predictors; no plot no. 5"},{"path":"two-way-anova.html","id":"exercise-tulips","chapter":"22 Two-way ANOVA","heading":"22.8 Exercise: Tulips","text":"Exercise 22.2  Blooms growing conditionsThe data/raw/CS4-tulip.csv dataset contains information experiment determine best conditions growing tulips (well someone care sorts things!). average number flower heads (blooms) recorded 27 different plots. plot experienced one three different watering regimes one three different shade regimes.Investigate number blooms affected different growing conditions.dataset three variables; Blooms (response variable) Water Shade (two potential predictor variables). always ‚Äôll visualise data first:, interaction plots suggest might interaction . Digging little deeper descriptive perspective, looks though Water regime 1 behaving differently Water regimes 2 3 different shade conditions.Let‚Äôs carry two-way ANOVA check assumptions. ‚Äôs worth pointing order carry doesn‚Äôt really matter ‚Äôll making decision everything place. Technically, check assumptions first statistical test, long check ‚Äôm fairly relaxed order steps.appear significant interaction Water Shade expected.Let‚Äôs check assumptions:actually OK. Point number 8 messing homogeneity variance assumption little bit, since ‚Äôs one point won‚Äôt worry . 2-way ANOVA analysis stands.","code":"\n# read in the data\ntulip <- read.csv(\"data/raw/CS4-tulip.csv\")\nboxplot(Blooms ~ Water, data = tulip)\nboxplot(Blooms ~ Shade,data = tulip)\ninteraction.plot(tulip$Water, tulip$Shade, tulip$Blooms)\ninteraction.plot(tulip$Shade, tulip$Water, tulip$Blooms)\n# define the linear model\nlm.tulip <- lm(Blooms ~ Water * Shade,\n               data = tulip)\n\n# perform the ANOVA\nanova(lm.tulip)## Analysis of Variance Table\n## \n## Response: Blooms\n##             Df Sum Sq Mean Sq F value    Pr(>F)    \n## Water        1 103426  103426  43.057 1.075e-06 ***\n## Shade        1  31154   31154  12.970  0.001505 ** \n## Water:Shade  1  33520   33520  13.954  0.001082 ** \n## Residuals   23  55248    2402                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\npar(mfrow = c(2, 2))\nplot(lm.tulip)"},{"path":"two-way-anova.html","id":"key-points-6","chapter":"22 Two-way ANOVA","heading":"22.9 Key points","text":"Point 1Point 2Point 3","code":""}]
