
```{r, setup}
source(file = "setup.R")
```

# Correlation coefficients

## Objectives
:::objectives
**Questions**

- How do I...
- What do I...

**Objectives**

- Be able to...
- Use...
:::

## Purpose and aim
Correlation refers to the relationship of two variables (or datasets) to one another. Two datasets are said to be correlated if they are not independent from one another. Correlations can be useful because they can indicate if a predictive relationship may exist. However just because two datasets are correlated does not mean that they are causally related.

### Section commands
New commands used in this section:

| Function| Description|
|:- |:- |
|`cor()`| Calculates a correlation matrix |
|`pairs()`| Plots a matrix of scatter plots |

### Data and hypotheses
We will use the `USArrests` dataset for this example. This rather bleak dataset contains statistics in arrests per 100,000 residents for assault, murder and robbery in each of the 50 US states in 1973, alongside the proportion of the population who lived in urban areas at that time. `USArrests` is an unstacked data frame with 50 observations of four variables: `Murder`, `Assault`, `UrbanPop` and `Robbery`.

The data are stored in the file `data/raw/CS3-usarrests.csv`.

First we read in the data:

```{r cs3-corr-data}
USArrests <- read.csv("data/raw/CS3-usarrests.csv", row.names = 1)

# have a look at the data
head(USArrests)
```

The syntax for reading in this data frame is a little different. Here we want to use the first column of the `.csv` file to specify the names of the rows of the dataset rather than to include the information inside the dataset itself. We do this by using the `row.names = 1` argument which tells R to use the 1st column of the file for the row names. We need to do this because some of the functions will be using require a _matrix_ as input (basically a data frame containing only numbers).

## Pearson’s product moment correlation coefficient
Pearson's r (as this quantity is also known) is a measure of the linear correlation between two variables. It has a value between -1 and +1, where +1 means a perfect positive correlation, -1 means a perfect negative correlation and 0 means no correlation at all.

### Summarise and visualise
Run this command:

```{r}
pairs(USArrests, lower.panel = NULL)
```

*	The first argument is a matrix or a data frame
*	The argument `lower.panel` tells R not to add the redundant reflected lower set of plots, below the diagonal 

From visual inspection of the scatter plots we can see that there appears to be a slight positive correlation between all pairs of variables, although this may be very weak in some case (`Murder` and `UrbanPop` for example).

### Implement test
Let's test if there are any possible correlations between the variables:

```{r cs3-cor-tbl, results='hide'}
cor(USArrests, method = "pearson")
```

*	The first argument is a matrix or a data frame
*	The argument `method` tells R which correlation coefficient to use (`pearson` (default), `kendall`, or `spearman`)

### Interpret output and report results
This should give the following output:

```{r cs3-cor-tbl-results, echo=FALSE}
cor(USArrests, method = "pearson")
```

The matrix gives the correlation coefficient between each pair of variables in the data frame. The matrix is symmetric (_why?_) and the diagonal values are all 1 (_why?_). The most correlated variables are `Murder` and `Assault` with an `r` value of 0.801. This appears to agree well with the set of scatter plots that we produced earlier.

### Exercise
:::exercise
State data correlation

We will use the data from the file `data/raw/CS3-statedata.csv` dataset for this exercise. This rather more benign dataset contains information on more general properties of each US state, such as population (1975), per capita income (1974), illiteracy proportion (1970), life expectancy (1969), murder rate per 100,000 people (there's no getting away from it), percentage of the population who are high-school graduates, average number of days where the minimum temperature is below freezing between 1931 and 1960, and the state area in square miles. The dataset contains 50 rows and 8 columns, with column names: `Population`, `Income`, `Illiteracy`, `Life.Exp`, `Murder`, `HS.Grad`, `Frost` and `Area`.

Load in the data (remembering to tell R that the first column of the CSV file should be used to specify the row names of the dataset) and use the pairs command to visually identify 3 different pairs of variables that appear to be

1.	the most positively correlated
2.	the most negatively correlated
3.	not correlated at all

Calculate Pearson’s r for all variable pairs and see how well you were able to identify correlation visually.

<details><summary>Answer</summary>

**1. Read in the data**

```{r cs3-state-data}
USAstate <- read.csv("data/raw/CS3-statedata.csv",
                     row.names = 1)

# have a look at the data
head(USAstate)
```

**2. Look at the pair-wise comparisons**

```{r}
pairs(USAstate, lower.panel = NULL)
```

**3. Create a correlation matrix**

```{r cs3-state-tbl-results}
cor(USAstate, method = "pearson")
```

```{r echo=FALSE}
varNames <- colnames(USAstate)
nVars <- length(varNames)
corMat <- cor(USAstate)
corVals <- sort(corMat[lower.tri(corMat)])
indMax <- which(corMat==max(corVals))[1]
indMin <- which(corMat==min(corVals))[1]
ind0 <- which(abs(corMat)==min(abs(corVals)))[1]
```

1. The most **positively** correlated variables are  `r varNames[indMax%%nVars]` and `r varNames[indMax%/%nVars + 1]`
2. The most **negatively** correlated variables are `r varNames[indMin%%nVars]` and `r varNames[indMin%/%nVars + 1]`
3. The most **uncorrelated** variables are Area and Population

</details>
:::


## Spearman's rank correlation coefficient
### Summarise and visualise
### Assumptions
### Implement test
### Interpret output and report results
### Exercise
:::exercise
Exercise title

Exercise description

<details><summary>Answer</summary>

An elaborate answer

</details>
:::

## Key points

:::keypoints
- Point 1
- Point 2
- Point 3
:::
